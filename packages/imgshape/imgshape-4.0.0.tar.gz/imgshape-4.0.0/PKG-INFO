Metadata-Version: 2.4
Name: imgshape
Version: 4.0.0
Summary: imgshape v4.0.0 (Atlas) â€” Dataset intelligence layer: deterministic fingerprinting and decision-making for ML pipelines.
Home-page: https://github.com/STiFLeR7/imgshape
Author: Stifler
Author-email: Stifler <hillaniljppatel@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/STiFLeR7/imgshape
Project-URL: Source, https://github.com/STiFLeR7/imgshape
Project-URL: Issues, https://github.com/STiFLeR7/imgshape/issues
Project-URL: Documentation, https://stifler7.github.io/imgshape/
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: Pillow>=9.0.0
Requires-Dist: numpy>=1.21.0
Requires-Dist: matplotlib>=3.4.0
Requires-Dist: scikit-image>=0.19.0
Requires-Dist: fastapi>=0.104.0
Requires-Dist: uvicorn[standard]>=0.24.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: requests>=2.28.0
Provides-Extra: torch
Requires-Dist: torch>=1.12.0; (platform_system != "Windows" or python_version >= "3.8") and extra == "torch"
Requires-Dist: torchvision>=0.13.0; extra == "torch"
Provides-Extra: pdf
Requires-Dist: weasyprint>=53.0; extra == "pdf"
Requires-Dist: reportlab>=3.6.0; extra == "pdf"
Requires-Dist: pyyaml>=6.0; extra == "pdf"
Provides-Extra: viz
Requires-Dist: plotly>=5.20.0; extra == "viz"
Requires-Dist: seaborn>=0.12.0; extra == "viz"
Provides-Extra: web
Requires-Dist: fastapi>=0.104.0; extra == "web"
Requires-Dist: uvicorn[standard]>=0.24.0; extra == "web"
Requires-Dist: jinja2>=3.1.0; extra == "web"
Provides-Extra: plugins
Requires-Dist: importlib-metadata>=6.0; extra == "plugins"
Provides-Extra: dev
Requires-Dist: pytest>=7.0; extra == "dev"
Requires-Dist: black>=23.0; extra == "dev"
Requires-Dist: flake8>=3.9; extra == "dev"
Requires-Dist: pre-commit>=2.20; extra == "dev"
Requires-Dist: mypy>=1.0; extra == "dev"
Requires-Dist: build>=1.2; extra == "dev"
Requires-Dist: twine>=4.0; extra == "dev"
Provides-Extra: full
Requires-Dist: torch>=1.12.0; extra == "full"
Requires-Dist: torchvision>=0.13.0; extra == "full"
Requires-Dist: weasyprint>=53.0; extra == "full"
Requires-Dist: reportlab>=3.6.0; extra == "full"
Requires-Dist: pyyaml>=6.0; extra == "full"
Requires-Dist: plotly>=5.20.0; extra == "full"
Requires-Dist: seaborn>=0.12.0; extra == "full"
Requires-Dist: fastapi>=0.104.0; extra == "full"
Requires-Dist: uvicorn[standard]>=0.24.0; extra == "full"
Requires-Dist: jinja2>=3.1.0; extra == "full"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

ï»¿<div align="center">

# ğŸ“Š imgshape
### Dataset Intelligence Layer for Computer Vision

**v4.0.0 Atlas Edition**

[![PyPI Version](https://img.shields.io/pypi/v/imgshape?color=blue&style=for-the-badge)](https://pypi.org/project/imgshape/)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge)](https://www.python.org/downloads/)
[![License](https://img.shields.io/github/license/STiFLeR7/imgshape?style=for-the-badge&color=orange)](https://github.com/STiFLeR7/imgshape/blob/master/LICENSE)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg?style=for-the-badge)](https://github.com/psf/black)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![React](https://img.shields.io/badge/React-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://react.dev)

<br/>

![imgshape Atlas](service/imgshape.png)

<br/>

**Deterministic Dataset Fingerprinting & Intelligent Decision Making**<br/>
*Fingerprinting â€¢ Rule-Based Decisions â€¢ Explainable AI â€¢ Deployable Artifacts â€¢ Production Ready*

[ğŸŒ **Live Demo**](https://imgshape.vercel.app/) â€¢ [**Documentation**](https://stifler7.github.io/imgshape) â€¢ [**v4 Guide**](#-imgshape-v400-atlas) â€¢ [**Report Bug**](https://github.com/STiFLeR7/imgshape/issues) â€¢ [**Request Feature**](https://github.com/STiFLeR7/imgshape/issues)

</div>

---

## ğŸš€ imgshape v4.0.0 (Atlas)

**Atlas** is a complete architectural redesign of imgshape, shifting from heuristic recommendations to deterministic dataset intelligence.

### Core Capabilities

| Feature | Description |
| :--- | :--- |
| **ğŸ”¬ Deterministic Fingerprinting** | Stable, canonical dataset identities across runs and deployments |
| **ğŸ¯ Rule-Based Decisions** | Explainable, traceable decisions with full reasoning |
| **ğŸ“ Five-Profile System** | Spatial, Signal, Distribution, Quality, Semantic analysis |
| **ğŸ“¦ Deployable Artifacts** | CI-safe, version-controlled outputs for production |
| **ğŸ”“ No Hidden Logic** | Every decision includes complete rationale and confidence |
| **âš™ï¸ Framework Agnostic** | Works with PyTorch, TensorFlow, JAX, or plain NumPy |

### Why Atlas?

**Before (v3):** "This dataset looks good for ResNet50."  
**Now (v4 Atlas):** "This dataset's fingerprint is `imgshape://vision/photographic/high-entropy`. For task=classification with priority=speed, we recommend MobileNetV3 because: [8 explicit reasons with metrics]."

---

## âš¡ Quick Start

### Installation

```bash
# Core package
pip install imgshape

# With web UI and full features
pip install "imgshape[full]"
```

### Python API (v4)

```python
from imgshape import Atlas

# Initialize the analyzer
atlas = Atlas()

# Analyze a dataset
result = atlas.analyze(
    dataset_path="path/to/images",
    task="classification",
    deployment="edge",
    priority="speed"
)

# Inspect results
print(f"Fingerprint: {result.fingerprint.dataset_uri}")
# Fingerprint: imgshape://vision/photographic/high-entropy

print(f"Recommended Model: {result.decisions['model_family'].selected}")
# Recommended Model: MobileNetV3

print(f"Reasoning: {result.decisions['model_family'].why}")
# Reasoning: [8 evidence points with metrics]

# Export for CI/CD
artifact = result.to_artifact()
artifact.save("dataset_analysis.json")
```

### Command Line (v4)

```bash
# Generate fingerprint
imgshape --fingerprint path/to/images --format json

# Run full analysis
imgshape --atlas path/to/images --task classification --output analysis.json

# View decisions
imgshape --decisions path/to/images --priority speed --deployment edge

# Interactive web UI
imgshape --web
# Opens http://localhost:8080 with modern React interface
```

### Web Interface

The **imgshape web UI** provides an interactive, modern interface for dataset analysis:

**Live Demo:** ğŸŒ [imgshape.vercel.app](https://imgshape.vercel.app/)

```bash
imgshape --web
```

**Features:**
- ğŸ“Š Real-time fingerprint generation and visualization
- ğŸ¯ Interactive decision explorer with full reasoning
- ğŸ“ˆ Dataset statistics dashboard
- ğŸ’¾ Export analysis results (JSON, YAML, PDF)
- ğŸš€ Deploy artifacts directly from the UI

![Dashboard UI](assets/dashboard.png)

---

## ğŸ—ï¸ Architecture

### Core Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Atlas Orchestrator                       â”‚
â”‚  (Main coordination & result aggregation)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        â”‚        â”‚
    â–¼        â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Finger- â”‚ â”‚Rules â”‚ â”‚Artifact â”‚
â”‚print   â”‚ â”‚Based â”‚ â”‚Generatorâ”‚
â”‚Engine  â”‚ â”‚Decis-â”‚ â”‚         â”‚
â”‚        â”‚ â”‚ion   â”‚ â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚        â”‚         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Result Bundle   â”‚
    â”‚ - Fingerprint  â”‚
    â”‚ - Decisions    â”‚
    â”‚ - Artifacts    â”‚
    â”‚ - Confidence   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fingerprint Profiles

Every dataset receives a **5-dimensional fingerprint**:

1. **Spatial Profile** - Image dimensions, aspect ratios, scale distribution
2. **Signal Profile** - Channel count, bit depth, dynamic range
3. **Distribution Profile** - Entropy, skewness, color uniformity
4. **Quality Profile** - Corruption rate, blur detection, noise estimation
5. **Semantic Profile** - Inferred content type (faces, objects, aerial, medical, etc.)

---

## ğŸ¯ Decision Domains

Atlas makes deterministic decisions across 8 domains:

| Domain | Examples |
| :--- | :--- |
| **Model Family** | ResNet, MobileNet, ViT, EfficientNet, etc. |
| **Input Dimensions** | 224x224, 512x512, or custom based on content |
| **Preprocessing** | Normalization parameters, augmentation strategy |
| **Batch Size** | Based on memory constraints and convergence |
| **Optimizer** | Adam, SGD, AdamW based on dataset characteristics |
| **Augmentation** | RandAugment, MixUp, Cutmix, intensity levels |
| **Deployment Target** | CPU, GPU, Edge (TensorRT, ONNX), Mobile |
| **Training Duration** | Early stopping patience, epoch count, callbacks |

---

## ğŸ“Š Example Analysis Output

```json
{
  "fingerprint": {
    "dataset_uri": "imgshape://vision/photographic/high-entropy",
    "dataset_id": "sha256:abc123...",
    "sample_count": 50000,
    "spatial": {
      "resolution_class": "high",
      "aspect_ratio_variance": 0.23,
      "mean_dimensions": [1920, 1080]
    },
    "signal": {
      "channel_count": 3,
      "bit_depth": 8
    },
    "distribution": {
      "entropy": 7.84,
      "color_uniformity": 0.42
    },
    "quality": {
      "corruption_rate": 0.0,
      "blur_percentage": 3.2,
      "noise_estimate": "gaussian"
    },
    "semantic": {
      "inferred_type": "photographic",
      "confidence": 0.92
    }
  },
  "decisions": {
    "model_family": {
      "selected": "MobileNetV3",
      "confidence": 0.87,
      "why": [
        "Dataset has 50k images (suitable for efficient models)",
        "Spatial resolution is high (1920x1080 average)",
        "Photographic content with 0.23 aspect ratio variance",
        "Edge deployment prioritizes inference speed over accuracy",
        "MobileNetV3 offers 2.8x faster inference than ResNet50",
        "Maintains 91% of ResNet50 accuracy on ImageNet",
        "Works on CPU and mobile devices",
        "Recent architecture (2019) with good operator support"
      ],
      "alternatives": ["EfficientNetB1", "ResNet34"]
    },
    "input_dimensions": {
      "selected": [224, 224],
      "confidence": 0.95,
      "why": ["MobileNetV3 default", "High entropy favors standard sizes"]
    }
  },
  "artifacts": {
    "fingerprint_stable": true,
    "fingerprint_format": "v4",
    "export_formats": ["json", "yaml", "protobuf"]
  }
}
```

---

## ğŸ’» Usage Patterns

### 1. CI/CD Integration

```bash
#!/bin/bash
# ci_check.sh - Ensure dataset integrity in your pipeline

imgshape --fingerprint data/train \
  --output fingerprint.json \
  --format json

# Compare with expected fingerprint
CURRENT=$(cat fingerprint.json | jq -r .dataset_id)
EXPECTED=$(cat .fingerprint_lock)

if [ "$CURRENT" != "$EXPECTED" ]; then
  echo "âŒ Dataset changed! Update .fingerprint_lock"
  exit 1
fi

echo "âœ… Dataset verified"
```

### 2. Training Script Integration

```python
from imgshape import Atlas

# In your training pipeline
atlas = Atlas()
analysis = atlas.analyze("data/train", task="classification")

# Use recommendations
model = create_model(
    architecture=analysis.decisions['model_family'].selected,
    input_size=analysis.decisions['input_dimensions'].selected
)

augmentation = get_augmentation_pipeline(
    analysis.decisions['augmentation'].selected
)

print(f"Fingerprint: {analysis.fingerprint.dataset_uri}")
print(f"Model: {model.__class__.__name__}")
```

### 3. Manual Inspection

```bash
# Generate comprehensive report
imgshape --atlas data/train \
  --task detection \
  --deployment gpu \
  --priority accuracy \
  --report analysis_report.md

# View decisions
imgshape --decisions data/train \
  --output decisions.json \
  --verbose
```

---

## ğŸ”Œ Plugin System

Extend imgshape with custom fingerprint extractors and decision rules.

```python
# plugins/medical_profiler.py
from imgshape.plugins import FingerprintPlugin

class MedicalProfiler(FingerprintPlugin):
    """Extract DICOM-specific attributes"""
    
    NAME = "medical_profiler_v1"
    
    def extract(self, dataset_path):
        # Custom logic for medical imaging
        return {
            "modality": "CT",
            "bit_depth": 16,
            "is_3d": True
        }
```

Register and use:

```bash
imgshape --plugin-add plugins/medical_profiler.py
imgshape --fingerprint medical_data/ --plugin medical_profiler_v1
```

---

## ğŸ“¦ Installation Options

```bash
# Core (minimal dependencies)
pip install imgshape

# With PyTorch support
pip install "imgshape[torch]"

# With web UI (FastAPI + React)
pip install "imgshape[web]"

# With all features
pip install "imgshape[full]"

# Development (with testing tools)
pip install "imgshape[dev]"
```

---

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
# Install dev dependencies
pip install "imgshape[dev]"

# Run all tests
pytest tests/ -v

# Run v4 specific tests
pytest tests/test_fingerprint.py tests/test_decision_engine.py -v

# Coverage
pytest --cov=imgshape tests/
```

Expected output: **26/33 passing** (7 optional artifact tests)

---

## ğŸŒ Web Service

Deploy imgshape as a REST API:

```bash
# Start the service
imgshape --web

# API Endpoints (v4)
# POST /v4/fingerprint    - Get dataset fingerprint
# POST /v4/decisions      - Get decisions for a dataset
# POST /v4/analyze        - Full analysis
# GET  /health            - Service health

# Legacy Endpoints (v3)
# POST /analyze           - v3 analyze
# POST /recommend         - v3 recommendations
```

### Docker Deployment

```bash
# Build
docker build -t imgshape:4.0.0 .

# Run
docker run -p 8080:8080 imgshape:4.0.0

# Cloud Run
gcloud run deploy imgshape --image gcr.io/your-project/imgshape:4.0.0
```

---

## ğŸ¤ Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes and add tests
4. Run `pytest tests/` to verify
5. Commit: `git commit -m 'Add amazing feature'`
6. Push: `git push origin feature/amazing-feature`
7. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## ğŸ“š Additional Resources

- [Full Documentation](https://stifler7.github.io/imgshape)
- [v4 Atlas Design Document](https://github.com/STiFLeR7/imgshape/blob/master/v4.md)
- [API Reference](https://stifler7.github.io/imgshape/api)
- [Contributing Guide](CONTRIBUTING.md)
- [Issues & Feature Requests](https://github.com/STiFLeR7/imgshape/issues)

---

## ğŸ“„ License

imgshape is released under the [MIT License](LICENSE). See LICENSE file for details.

---

<div align="center">

**Built with ğŸ’œ by [Stifler](https://github.com/STiFLeR7)**

*Making dataset intelligence accessible to everyone.*

If you find imgshape useful, please consider:
- â­ Starring this repository
- ğŸ“¢ Sharing with your colleagues
- ğŸ› Reporting issues and suggesting features
- ğŸ¤ Contributing code or documentation

</div>
