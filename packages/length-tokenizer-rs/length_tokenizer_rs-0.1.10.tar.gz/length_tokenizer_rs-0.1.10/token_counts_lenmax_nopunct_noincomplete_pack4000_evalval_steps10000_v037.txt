[Length-MAX] vocab_size=32000
[Length-MAX] longest_tokens(top 20):
  #01 len= 47 id=  285 tok='1930ĠrenumberingĠofĠstateĠ...
  #02 len= 47 id= 1962 tok='CourseĠonĠtheĠRiverĠThames...
  #03 len= 47 id= 3398 tok='InternationalĠUnionĠforĠCo...
  #04 len= 46 id= 7388 tok='airedĠonĠtheĠFoxĠnetworkĠi...
  #05 len= 46 id=27149 tok='ĠwhichĠassignsĠaĠnormalize...
  #06 len= 44 id=27189 tok='ĠwhoĠworkĠonĠcasesĠlinkedĠ...
  #07 len= 43 id= 6305 tok='TheĠshowĠcentersĠonĠFBIĠsp...
  #08 len= 43 id= 7601 tok='amongĠadultsĠbetweenĠtheĠa...
  #09 len= 43 id=22760 tok='transitionedĠintoĠanĠextra...
  #10 len= 42 id= 5308 tok='RecordingĠIndustryĠAssocia...
  #11 len= 42 id=10451 tok='crewsĠfromĠtheĠUniversitie...
  #12 len= 41 id=23838 tok='wentĠintoĠtheĠraceĠasĠreig...
  #13 len= 40 id= 1983 tok='CreditsĠadaptedĠfromĠtheĠl...
  #14 len= 40 id=12319 tok='etterĠUpdatedĠUnofficialĠS...
  #15 len= 38 id=12179 tok='erĠofĠtheĠOrderĠofĠtheĠBri...
  #16 len= 37 id= 4527 tok='NationalĠRegisterĠofĠHisto...
  #17 len= 36 id= 5854 tok='SiteĠofĠSpecialĠScientific...
  #18 len= 35 id= 3425 tok='InĠitsĠoriginalĠAmericanĠb...
  #19 len= 34 id=25631 tok='ĠRobertĠShearmanĠandĠLarsĠ...
  #20 len= 34 id=26566 tok='ĠinĠtheirĠbookĠWantingĠtoĠ...

[BPE] vocab_size=32000
[BPE] longest_tokens(top 20):
  #01 len= 17 id=22946 tok='ĠIntercontinental'
  #02 len= 17 id=19840 tok='Ġautobiographical'
  #03 len= 17 id=21024 tok='Ġcharacterization'
  #04 len= 17 id=28098 tok='Ġdisqualification'
  #05 len= 17 id=25734 tok='Ġextraterrestrial'
  #06 len= 17 id=15227 tok='Ġresponsibilities'
  #07 len= 17 id=23429 tok='Ġunconstitutional'
  #08 len= 16 id=25484 tok='ĠCharacteristics'
  #09 len= 16 id=23399 tok='ĠGloucestershire'
  #10 len= 16 id=11190 tok='ĠRepresentatives'
  #11 len= 16 id=19476 tok='Ġaccomplishments'
  #12 len= 16 id= 7258 tok='Ġcharacteristics'
  #13 len= 16 id=23276 tok='Ġcinematographer'
  #14 len= 16 id=24037 tok='Ġclassifications'
  #15 len= 16 id=26563 tok='Ġdissatisfaction'
  #16 len= 16 id=21151 tok='Ġelectromagnetic'
  #17 len= 16 id=22722 tok='Ġexperimentation'
  #18 len= 16 id=13036 tok='Ġinstrumentation'
  #19 len= 16 id=17370 tok='Ġintensification'
  #20 len= 16 id=12616 tok='Ġinternationally'

[load] loading tokenizers ...
[load] done in 0.23s  len_rust_active=True


[done]
lines        = 1165029
chars        = 534799177
len_tokens   = 112103975  tpc=0.209619  chars/token=4.771
bpe_tokens   = 113327064  tpc=0.211906  chars/token=4.719
elapsed      = 88.3s
