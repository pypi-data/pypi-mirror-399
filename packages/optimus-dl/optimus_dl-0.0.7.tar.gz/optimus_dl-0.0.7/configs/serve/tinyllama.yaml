# @package @_global_
defaults:
  - _self_

serve:
  port: 8000
  host: "127.0.0.1"

common:
  checkpoint_path: null
  model:
    _name: preset_hfllama2
    hf_model_name: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  tokenizer:
    _name: transformers
    name: ${common.model.hf_model_name}
    add_eos: false
