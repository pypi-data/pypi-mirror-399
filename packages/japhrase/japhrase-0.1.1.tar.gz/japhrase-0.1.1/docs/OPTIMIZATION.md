# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚¬ã‚¤ãƒ‰

jphrase ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ã¦æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•çš„ã«è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

## ğŸ¯ æ¦‚è¦

### 2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

1. **æ•™å¸«ãªã—æœ€é©åŒ–ï¼ˆæ¨å¥¨ï¼‰** - æ­£è§£ãƒ‡ãƒ¼ã‚¿ä¸è¦
2. **æ•™å¸«ã‚ã‚Šæœ€é©åŒ–** - æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ

---

## ğŸ“š æ•™å¸«ãªã—æœ€é©åŒ–

æ­£è§£ãƒ‡ãƒ¼ã‚¿ãªã—ã§ã€å†…éƒ¨æŒ‡æ¨™ã‚’ä½¿ã£ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```python
from japhrase import PhraseExtracter, UnsupervisedOptimizer

# ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„
texts = [
    "æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®ä¸€åˆ†é‡ã§ã™ã€‚",
    "æ·±å±¤å­¦ç¿’ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸå­¦ç¿’æ–¹æ³•ã§ã™ã€‚",
    # ... more texts
]

# æœ€é©åŒ–å®Ÿè¡Œ
optimizer = UnsupervisedOptimizer(
    param_grid={
        'min_count': [3, 5, 10],
        'max_length': [10, 15, 20],
        'threshold_originality': [0.5, 0.7, 0.9]
    }
)

best_params, results = optimizer.optimize(texts)

print(f"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_params}")

# æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å®Ÿè¡Œ
df = PhraseExtracter(**best_params).get_dfphrase(texts)
```

### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¨ã®é€£æº

```python
from japhrase import UnsupervisedOptimizer
from japhrase.datasource import WikipediaSource

# Wikipediaã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
source = WikipediaSource()
texts = source.fetch_random(100)

# æœ€é©åŒ–
optimizer = UnsupervisedOptimizer()
best_params, results = optimizer.optimize(texts)
```

---

## ğŸ“ æ•™å¸«ã‚ã‚Šæœ€é©åŒ–

æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€ã‚ˆã‚Šæ­£ç¢ºãªæœ€é©åŒ–ãŒå¯èƒ½ã§ã™ã€‚

```python
from japhrase import SupervisedOptimizer

# æ­£è§£ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç”¨æ„
gold_phrases = [
    "æ©Ÿæ¢°å­¦ç¿’",
    "æ·±å±¤å­¦ç¿’",
    "è‡ªç„¶è¨€èªå‡¦ç†",
    "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"
]

# ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
texts = [...]

# æœ€é©åŒ–å®Ÿè¡Œ
optimizer = SupervisedOptimizer(
    gold_phrases=gold_phrases,
    metric='f1'  # 'precision', 'recall', 'f1' ã‹ã‚‰é¸æŠ
)

best_params, results = optimizer.optimize(texts)

print(f"F1ã‚¹ã‚³ã‚¢: {max(r['score'] for r in results):.4f}")
```

---

## âš™ï¸ æœ€é©åŒ–æ‰‹æ³•

### 1. ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰

å…¨ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’è©¦ã™ã€‚

```python
optimizer = UnsupervisedOptimizer(param_grid={...})
best_params, results = optimizer.optimize(texts, method='grid')
```

**ç‰¹å¾´:**
- âœ… ç¢ºå®Ÿã«æœ€é©è§£ã‚’è¦‹ã¤ã‘ã‚‹
- âš ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤šã„ã¨æ™‚é–“ãŒã‹ã‹ã‚‹

### 2. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ

ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é¸ã‚“ã§è©¦ã™ã€‚

```python
best_params, results = optimizer.optimize(
    texts,
    method='random',
    n_iterations=20  # è©¦è¡Œå›æ•°
)
```

**ç‰¹å¾´:**
- âœ… é«˜é€Ÿ
- âš ï¸ æœ€é©è§£ã®ä¿è¨¼ãªã—

---

## ğŸ“Š è©•ä¾¡æŒ‡æ¨™

### æ•™å¸«ãªã—è©•ä¾¡ã®æŒ‡æ¨™

| æŒ‡æ¨™ | èª¬æ˜ | ç†æƒ³å€¤ |
|------|------|--------|
| **diversity** | ãƒ•ãƒ¬ãƒ¼ã‚ºã®å¤šæ§˜æ€§ | é«˜ã„ã»ã©è‰¯ã„ |
| **coverage** | å…ƒãƒ†ã‚­ã‚¹ãƒˆã®ã‚«ãƒãƒ¼ç‡ | é©åº¦ãªå€¤ |
| **balance** | é »åº¦åˆ†å¸ƒã®ãƒãƒ©ãƒ³ã‚¹ | 0.5å‰å¾Œ |
| **length** | å¹³å‡æ–‡å­—é•·ã®é©åˆ‡ã• | 6æ–‡å­—å‰å¾Œ |

### è©³ç´°ã‚¹ã‚³ã‚¢ã®å–å¾—

```python
from japhrase.evaluation import UnsupervisedEvaluator

evaluator = UnsupervisedEvaluator()
scores = evaluator.get_detailed_scores(phrases, texts, df)

for metric, score in scores.items():
    print(f"{metric}: {score:.4f}")
```

---

## ğŸ¨ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

```python
optimizer = UnsupervisedOptimizer(
    param_grid={
        'min_count': [2, 5, 10, 20],           # æœ€å°å‡ºç¾å›æ•°
        'max_length': [8, 12, 16, 20],         # æœ€å¤§æ–‡å­—æ•°
        'min_length': [3, 4, 5],               # æœ€å°æ–‡å­—æ•°
        'threshold_originality': [0.3, 0.5, 0.7, 0.9]  # é¡ä¼¼åº¦é–¾å€¤
    }
)
```

### è©•ä¾¡å™¨ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

```python
from japhrase.evaluation import UnsupervisedEvaluator

# è©•ä¾¡æŒ‡æ¨™ã®é‡ã¿ã‚’èª¿æ•´
evaluator = UnsupervisedEvaluator(
    weight_diversity=2.0,    # å¤šæ§˜æ€§ã‚’é‡è¦–
    weight_coverage=1.0,
    weight_balance=1.0,
    weight_length=0.5
)

optimizer = UnsupervisedOptimizer(evaluator=evaluator)
```

---

## ğŸ’¾ çµæœã®ä¿å­˜ã¨å†åˆ©ç”¨

### æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¿å­˜

```python
import json

# æœ€é©åŒ–å®Ÿè¡Œ
best_params, results = optimizer.optimize(texts)

# JSONã§ä¿å­˜
with open('optimal_params.json', 'w') as f:
    json.dump(best_params, f, indent=2)

# å…¨çµæœã‚‚ä¿å­˜
with open('optimization_results.json', 'w') as f:
    json.dump(results, f, indent=2)
```

### ä¿å­˜ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

```python
import json
from japhrase import PhraseExtracter

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with open('optimal_params.json', 'r') as f:
    params = json.load(f)

# ä½¿ç”¨
extractor = PhraseExtracter(**params)
df = extractor.extract("new_data.txt")
```

---

## ğŸ“ˆ å®Ÿè·µä¾‹

### ä¾‹1: SNSãƒ†ã‚­ã‚¹ãƒˆå‘ã‘æœ€é©åŒ–

```python
from japhrase import UnsupervisedOptimizer
from japhrase.datasource import TextFileSource

# SNSæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—
source = TextFileSource(["tweets.txt"])
texts = source.fetch()

# SNSå‘ã‘ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æœ€é©åŒ–
optimizer = UnsupervisedOptimizer(
    param_grid={
        'min_count': [5, 10, 15],      # é »å‡ºãƒ•ãƒ¬ãƒ¼ã‚º
        'max_length': [10, 15, 20],    # çŸ­ã‚ã®ãƒ•ãƒ¬ãƒ¼ã‚º
        'threshold_originality': [0.7, 0.9]  # é¡ä¼¼èªã‚’å³ã—ãé™¤å»
    }
)

best_params, _ = optimizer.optimize(texts)

# ãƒ—ãƒªã‚»ãƒƒãƒˆã¨ã—ã¦ä¿å­˜
with open('sns_preset.json', 'w') as f:
    json.dump(best_params, f)
```

### ä¾‹2: å­¦è¡“è«–æ–‡å‘ã‘æœ€é©åŒ–

```python
optimizer = UnsupervisedOptimizer(
    param_grid={
        'min_count': [3, 5, 8],        # å°‚é–€ç”¨èªã¯å°‘ãªã„
        'max_length': [15, 20, 30],    # é•·ã‚ã®ç”¨èª
        'threshold_originality': [0.5, 0.7]
    }
)

best_params, _ = optimizer.optimize(academic_texts)
```

### ä¾‹3: è¤‡æ•°ãƒ‰ãƒ¡ã‚¤ãƒ³ã§æœ€é©åŒ–

```python
domains = {
    'sns': sns_texts,
    'news': news_texts,
    'academic': academic_texts
}

optimal_params = {}

for domain, texts in domains.items():
    print(f"\n{domain} æœ€é©åŒ–ä¸­...")
    optimizer = UnsupervisedOptimizer()
    best_params, _ = optimizer.optimize(texts)
    optimal_params[domain] = best_params

# å…¨ãƒ‰ãƒ¡ã‚¤ãƒ³ã®çµæœã‚’ä¿å­˜
with open('all_domain_params.json', 'w') as f:
    json.dump(optimal_params, f, indent=2)
```

---

## ğŸš€ ãƒ‡ãƒ¢ã®å®Ÿè¡Œ

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¢ã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ï¼š

```bash
# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§æœ€é©åŒ–ãƒ‡ãƒ¢
python examples/optimization_demo.py local

# Wikipediaãƒ‡ãƒ¼ã‚¿ã§æœ€é©åŒ–ãƒ‡ãƒ¢
python examples/optimization_demo.py wikipedia

# è©•ä¾¡å™¨ã®ãƒ‡ãƒ¢
python examples/optimization_demo.py eval
```

---

## â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒ’ãƒ³ãƒˆ

### 1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æ¸›ã‚‰ã™

```python
# æ‚ªã„ä¾‹ï¼š81é€šã‚Šï¼ˆ3Ã—3Ã—3Ã—3ï¼‰
param_grid = {
    'min_count': [3, 5, 10],
    'max_length': [10, 15, 20],
    'min_length': [3, 4, 5],
    'threshold_originality': [0.5, 0.7, 0.9]
}

# è‰¯ã„ä¾‹ï¼š8é€šã‚Šï¼ˆ2Ã—2Ã—2ï¼‰
param_grid = {
    'min_count': [5, 10],
    'max_length': [10, 20],
    'threshold_originality': [0.5, 0.9]
}
```

### 2. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã‚’ä½¿ã†

```python
# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚ˆã‚Šé«˜é€Ÿ
best_params, _ = optimizer.optimize(
    texts,
    method='random',
    n_iterations=20
)
```

### 3. ãƒ†ã‚­ã‚¹ãƒˆé‡ã‚’èª¿æ•´

```python
# å¤§é‡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
import random
sampled_texts = random.sample(texts, min(1000, len(texts)))

optimizer.optimize(sampled_texts)
```

---

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼: No valid results found

**åŸå› :** ã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã§æŠ½å‡ºã«å¤±æ•—

**è§£æ±ºç­–:**
```python
# min_count ã‚’å°ã•ãã™ã‚‹
param_grid = {
    'min_count': [2, 3, 5],  # ã‚ˆã‚Šå°ã•ã„å€¤ã‚’è©¦ã™
    ...
}
```

### æœ€é©åŒ–ã«æ™‚é–“ãŒã‹ã‹ã‚‹

**è§£æ±ºç­–:**
1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰ã‚’å°ã•ãã™ã‚‹
2. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã‚’ä½¿ã†
3. ãƒ†ã‚­ã‚¹ãƒˆé‡ã‚’æ¸›ã‚‰ã™
4. `verbose=0` ã§é€²æ—è¡¨ç¤ºã‚’ç„¡åŠ¹åŒ–

---

## ğŸ“š é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [USAGE.md](USAGE.md) - åŸºæœ¬çš„ãªä½¿ã„æ–¹
- [DATA_SOURCES.md](DATA_SOURCES.md) - ãƒ‡ãƒ¼ã‚¿å–å¾—æ–¹æ³•
- [README.md](README.md) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
