"""
Autograd: Node/Tape plus op wrappers.
"""

from .engine import Node, Tape, apply_op, no_grad, set_current_tape, get_current_tape
from .debug import debug_tape
from .ops import (
    tensor,
    add,
    relu,
    bias_add,
    matmul_op,
    sub,
    mse_loss,
    sigmoid,
    tanh,
    leaky_relu,
    gelu,
    swish,
    elu,
    softplus,
    hard_sigmoid,
    hard_swish,
    clamp,
    hard_tanh,
    prelu,
    hinge_loss,
    l1_loss,
    l2_loss,
    depthwise_conv2d,
    batch_norm2d,
    layer_norm,
    pad2d,
    group_norm,
    global_avg_pool2d,
    cross_entropy,
    conv2d,
    flatten,
    max_pool2d,
    dropout,
    avg_pool2d,
)

__all__ = [
    "Node",
    "Tape",
    "apply_op",
    "no_grad",
    "tensor",
    "add",
    "relu",
    "bias_add",
    "matmul_op",
    "sub",
    "mse_loss",
    "sigmoid",
    "tanh",
    "leaky_relu",
    "gelu",
    "swish",
    "elu",
    "softplus",
    "hard_sigmoid",
    "hard_swish",
    "clamp",
    "hard_tanh",
    "prelu",
    "hinge_loss",
    "l1_loss",
    "l2_loss",
    "depthwise_conv2d",
    "batch_norm2d",
    "layer_norm",
    "pad2d",
    "group_norm",
    "global_avg_pool2d",
    "cross_entropy",
    "conv2d",
    "flatten",
    "max_pool2d",
    "dropout",
    "avg_pool2d",
    "debug_tape",
    "set_current_tape",
    "get_current_tape",
]
