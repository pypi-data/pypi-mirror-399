"""
é™æ€æ£€æŸ¥å‘½ä»¤å®ç°
"""

from pathlib import Path

from rich.panel import Panel
from rich.table import Table

from mpdt.utils.color_printer import console, print_error, print_info, print_success, print_warning
from mpdt.validators import (
    AutoFixValidator,
    ComponentValidator,
    ConfigValidator,
    MetadataValidator,
    StructureValidator,
    StyleValidator,
    TypeValidator,
    ValidationLevel,
    ValidationResult,
)


def check_plugin(
    plugin_path: str,
    level: str = "warning",
    auto_fix: bool = False,
    report_format: str = "console",
    output_path: str | None = None,
    skip_structure: bool = False,
    skip_metadata: bool = False,
    skip_component: bool = False,
    skip_type: bool = False,
    skip_style: bool = False,
    verbose: bool = False,
) -> None:
    """
    æ£€æŸ¥æ’ä»¶

    Args:
        plugin_path: æ’ä»¶è·¯å¾„
        level: æ˜¾ç¤ºçº§åˆ« (error, warning, info)
        auto_fix: è‡ªåŠ¨ä¿®å¤
        report_format: æŠ¥å‘Šæ ¼å¼ (console, markdown)
        output_path: è¾“å‡ºè·¯å¾„
        skip_structure: è·³è¿‡ç»“æ„æ£€æŸ¥
        skip_metadata: è·³è¿‡å…ƒæ•°æ®æ£€æŸ¥
        skip_component: è·³è¿‡ç»„ä»¶æ£€æŸ¥
        skip_type: è·³è¿‡ç±»å‹æ£€æŸ¥
        skip_style: è·³è¿‡ä»£ç é£æ ¼æ£€æŸ¥
        skip_security: è·³è¿‡å®‰å…¨æ£€æŸ¥
        verbose: è¯¦ç»†è¾“å‡º
    """
    path = Path(plugin_path).resolve()

    if not path.exists():
        print_error(f"æ’ä»¶è·¯å¾„ä¸å­˜åœ¨: {plugin_path}")
        return

    if not path.is_dir():
        print_error(f"æ’ä»¶è·¯å¾„ä¸æ˜¯ç›®å½•: {plugin_path}")
        return

    console.print(Panel.fit(f"ğŸ” æ£€æŸ¥æ’ä»¶: [cyan]{path.name}[/cyan]", border_style="blue"))

    # æ”¶é›†æ‰€æœ‰éªŒè¯ç»“æœ
    all_results: list[ValidationResult] = []

    # ç»“æ„éªŒè¯
    if not skip_structure:
        print_info("æ­£åœ¨æ£€æŸ¥æ’ä»¶ç»“æ„...")
        validator = StructureValidator(path)
        result = validator.validate()
        all_results.append(result)
        _print_validation_summary(result, verbose)

    # å…ƒæ•°æ®éªŒè¯
    if not skip_metadata:
        print_info("æ­£åœ¨æ£€æŸ¥æ’ä»¶å…ƒæ•°æ®...")
        validator = MetadataValidator(path)
        result = validator.validate()
        all_results.append(result)
        _print_validation_summary(result, verbose)

    # ç»„ä»¶éªŒè¯
    if not skip_component:
        print_info("æ­£åœ¨æ£€æŸ¥ç»„ä»¶å…ƒæ•°æ®...")
        validator = ComponentValidator(path)
        result = validator.validate()
        all_results.append(result)
        _print_validation_summary(result, verbose)

    # é…ç½®éªŒè¯
    print_info("æ­£åœ¨æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    validator = ConfigValidator(path)
    result = validator.validate()
    all_results.append(result)
    _print_validation_summary(result, verbose)

    # ç±»å‹æ£€æŸ¥
    if not skip_type:
        print_info("æ­£åœ¨è¿›è¡Œç±»å‹æ£€æŸ¥...")
        validator = TypeValidator(path)
        result = validator.validate()
        all_results.append(result)
        _print_validation_summary(result, verbose)

    # ä»£ç é£æ ¼æ£€æŸ¥
    if not skip_style:
        print_info("æ­£åœ¨æ£€æŸ¥ä»£ç é£æ ¼...")
        validator = StyleValidator(path)
        result = validator.validate()
        all_results.append(result)
        _print_validation_summary(result, verbose)

    # è‡ªåŠ¨ä¿®å¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    auto_fixer = None
    if auto_fix:
        print_info("æ­£åœ¨åº”ç”¨è‡ªåŠ¨ä¿®å¤...")
        auto_fixer = AutoFixValidator(path)
        fix_result = auto_fixer.fix_issues(all_results)

        # ä»åŸå§‹ç»“æœä¸­ç§»é™¤å·²ä¿®å¤çš„é—®é¢˜ï¼ˆä½¿ç”¨å¯¹è±¡ id æ¯”è¾ƒï¼‰
        fixed_issue_ids = {id(issue) for issue in auto_fixer.fixed_issues}
        for result in all_results:
            result.issues = [issue for issue in result.issues if id(issue) not in fixed_issue_ids]
            # æ›´æ–°è®¡æ•°
            result._update_counts()

        # å¦‚æœåº”ç”¨äº† ruff ä¿®å¤ï¼Œç§»é™¤æ‰€æœ‰å¯ä»¥è¢« ruff ä¿®å¤çš„é—®é¢˜
        if any("ruff" in fix for fix in auto_fixer.fixes_applied):
            import re
            ruff_fixed_count = 0
            for result in all_results:
                original_count = len(result.issues)
                # ç§»é™¤æ‰€æœ‰ ruff é”™è¯¯æ ¼å¼çš„é—®é¢˜ï¼ˆå¦‚æœå»ºè®®åŒ…å«"å¯è‡ªåŠ¨ä¿®å¤"æˆ–é—®é¢˜æœ¬èº«å°±æ˜¯ ruff æ ¼å¼ï¼‰
                result.issues = [
                    issue for issue in result.issues
                    if not (
                        re.match(r'^[A-Z]\d+:', issue.message) and
                        (issue.suggestion is None or "å¯è‡ªåŠ¨ä¿®å¤" in issue.suggestion or "--fix" in issue.suggestion)
                    )
                ]
                ruff_fixed_count += original_count - len(result.issues)
                # æ›´æ–°è®¡æ•°
                result._update_counts()

        # æ˜¾ç¤ºä¿®å¤æ‘˜è¦
        if auto_fixer.fixes_applied:
            print_success(f"  âœ“ æˆåŠŸä¿®å¤ {len(auto_fixer.fixes_applied)} ä¸ªé—®é¢˜")
            if verbose:
                for fix in auto_fixer.fixes_applied:
                    console.print(f"    [green]âœ“[/green] {fix}")

        if auto_fixer.fixes_failed:
            print_warning(f"  âš  {len(auto_fixer.fixes_failed)} ä¸ªé—®é¢˜ä¿®å¤å¤±è´¥")
            if verbose:
                for fail in auto_fixer.fixes_failed:
                    console.print(f"    [yellow]âœ—[/yellow] {fail}")

        if not auto_fixer.fixes_applied and not auto_fixer.fixes_failed:
            print_info("  â„¹ æœªå‘ç°å¯è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜")

    # ç”Ÿæˆæ€»ä½“æŠ¥å‘Š
    _print_overall_report(all_results, level, auto_fixer)

    # ä¿å­˜æŠ¥å‘Šï¼ˆå¦‚æœéœ€è¦ï¼‰
    if output_path:
        _save_report(all_results, output_path, report_format, auto_fixer)


def _print_validation_summary(result: ValidationResult, verbose: bool = False) -> None:
    """æ‰“å°éªŒè¯æ‘˜è¦

    Args:
        result: éªŒè¯ç»“æœ
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
    """
    if result.success:
        print_success(f"  âœ“ {result.validator_name}: é€šè¿‡")
    else:
        print_error(f"  âœ— {result.validator_name}: å‘ç° {result.error_count} ä¸ªé”™è¯¯")

    if verbose and result.issues:
        for issue in result.issues:
            _print_issue(issue)


def _print_issue(issue) -> None:
    """æ‰“å°å•ä¸ªé—®é¢˜

    Args:
        issue: éªŒè¯é—®é¢˜
    """
    level_colors = {
        ValidationLevel.ERROR: "red",
        ValidationLevel.WARNING: "yellow",
        ValidationLevel.INFO: "blue",
    }

    level_icons = {
        ValidationLevel.ERROR: "âœ—",
        ValidationLevel.WARNING: "âš ",
        ValidationLevel.INFO: "â„¹",
    }

    color = level_colors.get(issue.level, "white")
    icon = level_icons.get(issue.level, "â€¢")

    message = f"    [{color}]{icon}[/{color}] {issue.message}"

    if issue.file_path:
        message += f" ([dim]{issue.file_path}"
        if issue.line_number:
            message += f":{issue.line_number}"
        message += "[/dim])"

    console.print(message)

    if issue.suggestion:
        console.print(f"      [dim]ğŸ’¡ {issue.suggestion}[/dim]")


def _print_overall_report(
    results: list[ValidationResult], level: str, auto_fixer: AutoFixValidator | None = None
) -> None:
    """æ‰“å°æ€»ä½“æŠ¥å‘Š

    Args:
        results: æ‰€æœ‰éªŒè¯ç»“æœ
        level: æ˜¾ç¤ºçº§åˆ«
        auto_fixer: è‡ªåŠ¨ä¿®å¤å™¨å¯¹è±¡ï¼ˆå¦‚æœå¯ç”¨äº†è‡ªåŠ¨ä¿®å¤ï¼‰
    """
    console.print()
    console.print("=" * 60)
    console.print()

    # ç»Ÿè®¡æ€»æ•°
    total_errors = sum(r.error_count for r in results)
    total_warnings = sum(r.warning_count for r in results)

    # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
    table = Table(title="æ£€æŸ¥ç»“æœæ±‡æ€»", show_header=True, header_style="bold")
    table.add_column("éªŒè¯å™¨", style="cyan")
    table.add_column("é”™è¯¯", style="red")
    table.add_column("è­¦å‘Š", style="yellow")
    table.add_column("ä¿¡æ¯", style="blue")
    table.add_column("çŠ¶æ€", style="green")

    for result in results:
        status = "âœ“ é€šè¿‡" if result.success else "âœ— å¤±è´¥"
        status_style = "green" if result.success else "red"
        table.add_row(
            result.validator_name,
            str(result.error_count),
            str(result.warning_count),
            str(result.info_count),
            f"[{status_style}]{status}[/{status_style}]",
        )

    console.print(table)
    console.print()

    # æ‰“å°è¯¦ç»†é—®é¢˜åˆ—è¡¨
    level_filter = ValidationLevel(level)
    for result in results:
        filtered_issues = [
            issue
            for issue in result.issues
            if (issue.level == ValidationLevel.ERROR)
            or (
                issue.level == ValidationLevel.WARNING
                and level_filter in [ValidationLevel.WARNING, ValidationLevel.INFO]
            )
            or (issue.level == ValidationLevel.INFO and level_filter == ValidationLevel.INFO)
        ]

        if filtered_issues:
            console.print(f"\n[bold]{result.validator_name}:[/bold]")
            for issue in filtered_issues:
                _print_issue(issue)

    # æ€»ç»“
    console.print()
    if auto_fixer:
        console.print("[bold cyan]â•â•â• ä¿®å¤ç»Ÿè®¡ â•â•â•[/bold cyan]")
        console.print()

        if auto_fixer.fixes_applied:
            console.print(f"[green]âœ“ æˆåŠŸä¿®å¤: {len(auto_fixer.fixes_applied)} ä¸ª[/green]")
            for fix in auto_fixer.fixes_applied:
                console.print(f"  [green]â€¢[/green] {fix}")
            console.print()

        if auto_fixer.fixes_failed:
            console.print(f"[yellow]âœ— ä¿®å¤å¤±è´¥: {len(auto_fixer.fixes_failed)} ä¸ª[/yellow]")
            for fail in auto_fixer.fixes_failed:
                console.print(f"  [yellow]â€¢[/yellow] {fail}")
            console.print()

        if not auto_fixer.fixes_applied and not auto_fixer.fixes_failed:
            console.print("[blue]â„¹ æœªå‘ç°å¯è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜[/blue]")
            console.print()

    console.print("[bold cyan]â•â•â• æœ€ç»ˆç»“æœ â•â•â•[/bold cyan]")
    console.print()
    if total_errors > 0:
        print_error(f"å‰©ä½™ {total_errors} ä¸ªé”™è¯¯ï¼Œ{total_warnings} ä¸ªè­¦å‘Š")
    elif total_warnings > 0:
        print_warning(f"å‰©ä½™ {total_warnings} ä¸ªè­¦å‘Š")
    else:
        print_success("æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")


def _save_report(
    results: list[ValidationResult], output_path: str, report_format: str, auto_fixer: AutoFixValidator | None = None
) -> None:
    """ä¿å­˜æ£€æŸ¥æŠ¥å‘Š

    Args:
        results: éªŒè¯ç»“æœåˆ—è¡¨
        output_path: è¾“å‡ºè·¯å¾„
        report_format: æŠ¥å‘Šæ ¼å¼
        auto_fixer: è‡ªåŠ¨ä¿®å¤å™¨å¯¹è±¡ï¼ˆå¦‚æœå¯ç”¨äº†è‡ªåŠ¨ä¿®å¤ï¼‰
    """
    if report_format == "markdown":
        _save_markdown_report(results, output_path, auto_fixer)
    elif report_format == "json":
        _save_json_report(results, output_path, auto_fixer)
    else:
        print_warning(f"ä¸æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼: {report_format}")


def _save_markdown_report(
    results: list[ValidationResult], output_path: str, auto_fixer: AutoFixValidator | None = None
) -> None:
    """ä¿å­˜ Markdown æ ¼å¼çš„æŠ¥å‘Š

    Args:
        results: éªŒè¯ç»“æœåˆ—è¡¨
        output_path: è¾“å‡ºè·¯å¾„
        auto_fixer: è‡ªåŠ¨ä¿®å¤å™¨å¯¹è±¡ï¼ˆå¦‚æœå¯ç”¨äº†è‡ªåŠ¨ä¿®å¤ï¼‰
    """
    lines = ["# æ’ä»¶æ£€æŸ¥æŠ¥å‘Š\n\n"]

    # ç»Ÿè®¡
    total_errors = sum(r.error_count for r in results)
    total_warnings = sum(r.warning_count for r in results)
    total_info = sum(r.info_count for r in results)

    lines.append("## æ‘˜è¦\n\n")
    lines.append(f"- é”™è¯¯: {total_errors}\n")
    lines.append(f"- è­¦å‘Š: {total_warnings}\n")
    lines.append(f"- ä¿¡æ¯: {total_info}\n")

    # ä¿®å¤ç»Ÿè®¡
    if auto_fixer:
        lines.append("\n### è‡ªåŠ¨ä¿®å¤ç»Ÿè®¡\n\n")
        if auto_fixer.fixes_applied:
            lines.append(f"- âœ… æˆåŠŸä¿®å¤: {len(auto_fixer.fixes_applied)} ä¸ª\n")
            for fix in auto_fixer.fixes_applied:
                lines.append(f"  - {fix}\n")
        if auto_fixer.fixes_failed:
            lines.append(f"- âŒ ä¿®å¤å¤±è´¥: {len(auto_fixer.fixes_failed)} ä¸ª\n")
            for fail in auto_fixer.fixes_failed:
                lines.append(f"  - {fail}\n")
        if not auto_fixer.fixes_applied and not auto_fixer.fixes_failed:
            lines.append("- â„¹ï¸ æœªå‘ç°å¯è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜\n")

    lines.append("\n")

    # è¯¦ç»†ç»“æœ
    for result in results:
        lines.append(f"## {result.validator_name}\n")

        if result.success:
            lines.append("âœ“ é€šè¿‡\n\n")
        else:
            lines.append(f"âœ— å‘ç° {result.error_count} ä¸ªé”™è¯¯\n\n")

        if result.issues:
            lines.append("### é—®é¢˜åˆ—è¡¨\n\n")
            for issue in result.issues:
                level_icons = {
                    ValidationLevel.ERROR: "âŒ",
                    ValidationLevel.WARNING: "âš ï¸",
                    ValidationLevel.INFO: "â„¹ï¸",
                }
                icon = level_icons.get(issue.level, "â€¢")
                lines.append(f"- {icon} **{issue.level.value.upper()}**: {issue.message}\n")

                if issue.file_path:
                    lines.append(f"  - æ–‡ä»¶: `{issue.file_path}`")
                    if issue.line_number:
                        lines.append(f":{issue.line_number}")
                    lines.append("\n")

                if issue.suggestion:
                    lines.append(f"  - å»ºè®®: {issue.suggestion}\n")

            lines.append("\n")

    # æ€»ç»“
    lines.append("## æ€»ç»“\n\n")
    if auto_fixer and auto_fixer.fixes_applied:
        lines.append(f"âœ… æˆåŠŸä¿®å¤ {len(auto_fixer.fixes_applied)} ä¸ªé—®é¢˜\n\n")
        if auto_fixer.fixes_failed:
            lines.append(f"âš ï¸ {len(auto_fixer.fixes_failed)} ä¸ªé—®é¢˜ä¿®å¤å¤±è´¥\n\n")

    if total_errors > 0:
        lines.append(f"âŒ å‰©ä½™ {total_errors} ä¸ªé”™è¯¯ï¼Œ{total_warnings} ä¸ªè­¦å‘Š\n")
    elif total_warnings > 0:
        lines.append(f"âš ï¸ å‰©ä½™ {total_warnings} ä¸ªè­¦å‘Š\n")
    else:
        lines.append("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼\n")

    # å†™å…¥æ–‡ä»¶
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            f.writelines(lines)
        print_success(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print_error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


def _save_json_report(
    results: list[ValidationResult], output_path: str, auto_fixer: AutoFixValidator | None = None
) -> None:
    """ä¿å­˜ JSON æ ¼å¼çš„æŠ¥å‘Š

    Args:
        results: éªŒè¯ç»“æœåˆ—è¡¨
        output_path: è¾“å‡ºè·¯å¾„
        auto_fixer: è‡ªåŠ¨ä¿®å¤å™¨å¯¹è±¡ï¼ˆå¦‚æœå¯ç”¨äº†è‡ªåŠ¨ä¿®å¤ï¼‰
    """
    import json
    from datetime import datetime

    # ç»Ÿè®¡æ€»æ•°
    total_errors = sum(r.error_count for r in results)
    total_warnings = sum(r.warning_count for r in results)
    total_info = sum(r.info_count for r in results)

    # æ„å»ºæŠ¥å‘Šæ•°æ®ç»“æ„
    report = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "total_errors": total_errors,
            "total_warnings": total_warnings,
            "total_info": total_info,
            "success": total_errors == 0,
        },
        "validators": [],
        "issues": [],
    }

    # æ·»åŠ è‡ªåŠ¨ä¿®å¤ç»Ÿè®¡
    if auto_fixer:
        report["auto_fix"] = {
            "enabled": True,
            "fixes_applied": len(auto_fixer.fixes_applied),
            "fixes_failed": len(auto_fixer.fixes_failed),
            "applied_fixes": auto_fixer.fixes_applied,
            "failed_fixes": auto_fixer.fixes_failed,
        }
    else:
        report["auto_fix"] = {"enabled": False}

    # æ·»åŠ æ¯ä¸ªéªŒè¯å™¨çš„ç»“æœ
    for result in results:
        validator_data = {
            "name": result.validator_name,
            "success": result.success,
            "error_count": result.error_count,
            "warning_count": result.warning_count,
            "info_count": result.info_count,
        }
        report["validators"].append(validator_data)

        # æ·»åŠ é—®é¢˜è¯¦æƒ…
        for issue in result.issues:
            issue_data = {
                "validator": result.validator_name,
                "level": issue.level.value,
                "message": issue.message,
                "file_path": issue.file_path,
                "line_number": issue.line_number,
                "suggestion": issue.suggestion,
            }
            report["issues"].append(issue_data)

    # å†™å…¥æ–‡ä»¶
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print_success(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print_error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
