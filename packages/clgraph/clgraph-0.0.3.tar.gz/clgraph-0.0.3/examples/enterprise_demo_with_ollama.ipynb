{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Enterprise Demo with Ollama\n",
    "\n",
    "This notebook demonstrates clgraph's full capabilities using the enterprise-demo SQL pipeline with Ollama for LLM-powered features:\n",
    "\n",
    "1. Load enterprise-demo SQL files (4-layer pipeline: raw â†’ staging â†’ analytics â†’ marts)\n",
    "2. Generate column descriptions using Ollama\n",
    "3. Use the LineageAgent to answer natural language questions\n",
    "4. Demonstrate text-to-SQL capabilities\n",
    "\n",
    "**Requirements:**\n",
    "- Install Ollama: `brew install ollama` (or see https://ollama.ai)\n",
    "- Pull model: `ollama pull llama3.2`\n",
    "- Start Ollama: `ollama serve`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-md",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Set the Ollama model and demo options here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:04.393549Z",
     "iopub.status.busy": "2025-12-30T20:10:04.393312Z",
     "iopub.status.idle": "2025-12-30T20:10:04.398556Z",
     "shell.execute_reply": "2025-12-30T20:10:04.397851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration - modify these as needed\n",
    "OLLAMA_MODEL = \"gpt-oss:20b\"  # Or try: llama3.2, qwen2.5-coder:7b\n",
    "SKIP_DESCRIPTIONS = False  # Set True to skip LLM description generation\n",
    "SKIP_AGENT = False  # Set True to skip LineageAgent demo\n",
    "SKIP_TEXT_TO_SQL = False  # Set True to skip text-to-SQL demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-md",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:04.400400Z",
     "iopub.status.busy": "2025-12-30T20:10:04.400221Z",
     "iopub.status.idle": "2025-12-30T20:10:04.458312Z",
     "shell.execute_reply": "2025-12-30T20:10:04.457922Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from clgraph import Pipeline\n",
    "from clgraph.agent import LineageAgent\n",
    "from clgraph.column import generate_description\n",
    "from clgraph.export import JSONExporter\n",
    "from clgraph.tools import (\n",
    "    ListTablesTool,\n",
    "    SearchColumnsTool,\n",
    "    TraceBackwardTool,\n",
    "    TraceForwardTool,\n",
    ")\n",
    "\n",
    "# Path to ClickHouse example SQL files\n",
    "CLICKHOUSE_EXAMPLE_SQL_PATH = Path(\".\") / \"clickhouse_example\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-pipeline-md",
   "metadata": {},
   "source": [
    "### Load Enterprise Pipeline\n",
    "\n",
    "Load the ClickHouse example SQL pipeline from the `clickhouse_example/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-pipeline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:04.459741Z",
     "iopub.status.busy": "2025-12-30T20:10:04.459668Z",
     "iopub.status.idle": "2025-12-30T20:10:04.531620Z",
     "shell.execute_reply": "2025-12-30T20:10:04.531286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Enterprise Demo with Ollama\n",
      "\n",
      "ğŸ“‚ Loading SQL files:\n",
      "   âœ“ 01_raw_orders.sql\n",
      "   âœ“ 02_raw_customers.sql\n",
      "   âœ“ 03_raw_products.sql\n",
      "   âœ“ 04_raw_order_items.sql\n",
      "   âœ“ 10_staging_orders.sql\n",
      "   âœ“ 11_staging_customers.sql\n",
      "   âœ“ 12_staging_products.sql\n",
      "   âœ“ 20_analytics_customer_metrics.sql\n",
      "   âœ“ 21_analytics_product_metrics.sql\n",
      "   âœ“ 22_analytics_daily_sales.sql\n",
      "   âœ“ 30_marts_customer_360.sql\n",
      "   âœ“ 31_marts_sales_dashboard.sql\n",
      "\n",
      "ğŸ”§ Creating pipeline with template_context={'env': 'dev'}...\n",
      "Info: Skipping lineage for 01_raw_orders (no SELECT statement)\n",
      "Info: Skipping lineage for 02_raw_customers (no SELECT statement)\n",
      "Info: Skipping lineage for 03_raw_products (no SELECT statement)\n",
      "Info: Skipping lineage for 04_raw_order_items (no SELECT statement)\n",
      "âœ… Pipeline created: 12 tables, 132 columns\n"
     ]
    }
   ],
   "source": [
    "def load_enterprise_pipeline() -> Pipeline:\n",
    "    \"\"\"Load the ClickHouse example SQL pipeline.\"\"\"\n",
    "    if not CLICKHOUSE_EXAMPLE_SQL_PATH.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"ClickHouse example SQL files not found at: {CLICKHOUSE_EXAMPLE_SQL_PATH}\\n\"\n",
    "            \"Make sure you're running from the examples/ directory.\"\n",
    "        )\n",
    "\n",
    "    sql_files = sorted(CLICKHOUSE_EXAMPLE_SQL_PATH.glob(\"*.sql\"))\n",
    "    queries = []\n",
    "\n",
    "    print(\"ğŸ“‚ Loading SQL files:\")\n",
    "    for sql_file in sql_files:\n",
    "        if sql_file.name.startswith(\"00_\"):\n",
    "            continue\n",
    "        content = sql_file.read_text()\n",
    "        query_id = sql_file.stem\n",
    "        queries.append((query_id, content))\n",
    "        print(f\"   âœ“ {sql_file.name}\")\n",
    "\n",
    "    print()\n",
    "    print(\"ğŸ”§ Creating pipeline with template_context={'env': 'dev'}...\")\n",
    "\n",
    "    pipeline = Pipeline.from_tuples(\n",
    "        queries,\n",
    "        dialect=\"clickhouse\",\n",
    "        template_context={\"env\": \"dev\"},\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"âœ… Pipeline created: {len(pipeline.table_graph.tables)} tables, {len(pipeline.columns)} columns\"\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# Load the pipeline\n",
    "print(\"ğŸš€ Enterprise Demo with Ollama\")\n",
    "print()\n",
    "pipeline = load_enterprise_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-llm-md",
   "metadata": {},
   "source": [
    "### Setup Ollama LLM\n",
    "\n",
    "Connect to Ollama for LLM-powered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "setup-llm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:04.532737Z",
     "iopub.status.busy": "2025-12-30T20:10:04.532640Z",
     "iopub.status.idle": "2025-12-30T20:10:11.124275Z",
     "shell.execute_reply": "2025-12-30T20:10:11.123769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ Testing Ollama connection (model: gpt-oss:20b)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ollama connected: OK...\n"
     ]
    }
   ],
   "source": [
    "def setup_ollama_llm(model: str = \"llama3.2\"):\n",
    "    \"\"\"Setup Ollama LLM for description generation.\"\"\"\n",
    "    try:\n",
    "        from langchain_ollama import ChatOllama\n",
    "\n",
    "        llm = ChatOllama(model=model, temperature=0.3)\n",
    "\n",
    "        print(f\"ğŸ”Œ Testing Ollama connection (model: {model})...\")\n",
    "        response = llm.invoke(\"Say 'OK' if you can hear me.\")\n",
    "        print(f\"âœ… Ollama connected: {response.content[:50]}...\")\n",
    "        return llm\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"âŒ langchain-ollama not installed. Install with: uv pip install langchain-ollama\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to connect to Ollama: {e}\")\n",
    "        print(\"   Make sure Ollama is running: ollama serve\")\n",
    "        print(f\"   And the model is pulled: ollama pull {model}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Setup LLM if needed\n",
    "llm = None\n",
    "if not (SKIP_DESCRIPTIONS and SKIP_AGENT and SKIP_TEXT_TO_SQL):\n",
    "    llm = setup_ollama_llm(OLLAMA_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-md",
   "metadata": {},
   "source": [
    "### Direct Tool Usage (No LLM Required)\n",
    "\n",
    "Demonstrate using lineage tools directly without an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tools",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:11.125897Z",
     "iopub.status.busy": "2025-12-30T20:10:11.125777Z",
     "iopub.status.idle": "2025-12-30T20:10:11.129601Z",
     "shell.execute_reply": "2025-12-30T20:10:11.129164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ”§ DIRECT TOOL USAGE (No LLM Required)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ ListTablesTool:\n",
      "------------------------------------------------------------\n",
      "Found 12 tables:\n",
      "  â€¢ analytics_dev.customer_metrics (12 columns)\n",
      "  â€¢ analytics_dev.daily_sales (15 columns)\n",
      "  â€¢ analytics_dev.product_metrics (15 columns)\n",
      "  â€¢ marts_dev.customer_360 (21 columns)\n",
      "  â€¢ marts_dev.sales_dashboard (18 columns)\n",
      "\n",
      "ğŸ”™ TraceBackwardTool:\n",
      "------------------------------------------------------------\n",
      "Sources for staging_dev.orders.amount:\n",
      "Column staging_dev.orders.amount is derived from: raw_dev.orders.total_amount\n",
      "\n",
      "ğŸ”œ TraceForwardTool:\n",
      "------------------------------------------------------------\n",
      "Dependents of raw_dev.orders.customer_id:\n",
      "Column raw_dev.orders.customer_id impacts: analytics_dev.customer_metrics.customer_id, marts_dev.sales_dashboard.daily_customers, marts_dev.sales_dashboard.mtd_customers, marts_dev.sales_dashboard.completion_rate, marts_dev.customer_360.valid_orders\n",
      "\n",
      "ğŸ” SearchColumnsTool:\n",
      "------------------------------------------------------------\n",
      "Columns matching 'revenue':\n",
      "Found 6 columns matching 'revenue'\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ğŸ”§ DIRECT TOOL USAGE (No LLM Required)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# List tables\n",
    "print(\"ğŸ“‹ ListTablesTool:\")\n",
    "print(\"-\" * 60)\n",
    "tool = ListTablesTool(pipeline)\n",
    "result = tool.run()\n",
    "print(f\"Found {len(result.data)} tables:\")\n",
    "for table in result.data[:5]:\n",
    "    print(f\"  â€¢ {table['name']} ({table['column_count']} columns)\")\n",
    "print()\n",
    "\n",
    "# Trace backward\n",
    "print(\"ğŸ”™ TraceBackwardTool:\")\n",
    "print(\"-\" * 60)\n",
    "tool = TraceBackwardTool(pipeline)\n",
    "result = tool.run(table=\"staging_dev.orders\", column=\"amount\")\n",
    "print(\"Sources for staging_dev.orders.amount:\")\n",
    "print(result.message)\n",
    "print()\n",
    "\n",
    "# Trace forward\n",
    "print(\"ğŸ”œ TraceForwardTool:\")\n",
    "print(\"-\" * 60)\n",
    "tool = TraceForwardTool(pipeline)\n",
    "result = tool.run(table=\"raw_dev.orders\", column=\"customer_id\")\n",
    "print(\"Dependents of raw_dev.orders.customer_id:\")\n",
    "print(result.message)\n",
    "print()\n",
    "\n",
    "# Search columns\n",
    "print(\"ğŸ” SearchColumnsTool:\")\n",
    "print(\"-\" * 60)\n",
    "tool = SearchColumnsTool(pipeline)\n",
    "result = tool.run(pattern=\"revenue\")\n",
    "print(\"Columns matching 'revenue':\")\n",
    "print(result.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descriptions-md",
   "metadata": {},
   "source": [
    "### LLM Description Generation\n",
    "\n",
    "Generate descriptions for columns that don't have them using Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "descriptions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:11.130647Z",
     "iopub.status.busy": "2025-12-30T20:10:11.130567Z",
     "iopub.status.idle": "2025-12-30T20:10:32.010264Z",
     "shell.execute_reply": "2025-12-30T20:10:32.009088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¤– DESCRIPTION GENERATION\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Pipeline Statistics:\n",
      "   â€¢ Tables: 12\n",
      "   â€¢ Total columns: 132\n",
      "   â€¢ With descriptions: 91\n",
      "   â€¢ Need generation: 41\n",
      "\n",
      "ğŸ“ Generating descriptions for first 5 columns without descriptions...\n",
      "   â€¢ raw_dev.orders.order_id... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“\n",
      "   â€¢ raw_dev.orders.customer_id... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“\n",
      "   â€¢ raw_dev.orders.order_date... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“\n",
      "   â€¢ staging_dev.orders.order_month... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“\n",
      "   â€¢ raw_dev.orders.total_amount... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“\n",
      "\n",
      "âœ… Generated 5 descriptions\n"
     ]
    }
   ],
   "source": [
    "if llm and not SKIP_DESCRIPTIONS:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ¤– DESCRIPTION GENERATION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    pipeline.llm = llm\n",
    "    all_tables = sorted(pipeline.table_graph.tables.keys())\n",
    "\n",
    "    # Count columns\n",
    "    columns_with_desc = sum(1 for col in pipeline.columns.values() if col.description)\n",
    "    columns_without_desc = len(pipeline.columns) - columns_with_desc\n",
    "\n",
    "    print(\"ğŸ“Š Pipeline Statistics:\")\n",
    "    print(f\"   â€¢ Tables: {len(all_tables)}\")\n",
    "    print(f\"   â€¢ Total columns: {len(pipeline.columns)}\")\n",
    "    print(f\"   â€¢ With descriptions: {columns_with_desc}\")\n",
    "    print(f\"   â€¢ Need generation: {columns_without_desc}\")\n",
    "    print()\n",
    "\n",
    "    if columns_without_desc > 0:\n",
    "        print(\"ğŸ“ Generating descriptions for first 5 columns without descriptions...\")\n",
    "        generated = 0\n",
    "        for col in list(pipeline.columns.values())[:20]:\n",
    "            if col.description is None and generated < 5:\n",
    "                print(f\"   â€¢ {col.table_name}.{col.column_name}...\", end=\" \", flush=True)\n",
    "                try:\n",
    "                    generate_description(col, llm, pipeline)\n",
    "                    print(\"âœ“\" if col.description else \"âœ—\")\n",
    "                    generated += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"âœ— {str(e)[:30]}\")\n",
    "        print(f\"\\nâœ… Generated {generated} descriptions\")\n",
    "else:\n",
    "    print(\"â­ï¸ Skipping description generation (SKIP_DESCRIPTIONS=True or no LLM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-md",
   "metadata": {},
   "source": [
    "### LineageAgent Demo\n",
    "\n",
    "Use natural language to query the lineage graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "agent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:32.011633Z",
     "iopub.status.busy": "2025-12-30T20:10:32.011524Z",
     "iopub.status.idle": "2025-12-30T20:10:32.015681Z",
     "shell.execute_reply": "2025-12-30T20:10:32.015274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¤– LINEAGE AGENT (Natural Language Interface)\n",
      "================================================================================\n",
      "\n",
      "Available tools:\n",
      "    1. trace_backward\n",
      "    2. trace_forward\n",
      "    3. get_lineage_path\n",
      "    4. get_table_lineage\n",
      "    5. list_tables\n",
      "    6. get_table_schema\n",
      "    7. get_relationships\n",
      "    8. search_columns\n",
      "    9. get_execution_order\n",
      "   10. find_pii_columns\n",
      "   11. get_owners\n",
      "   12. get_columns_by_tag\n",
      "   13. list_tags\n",
      "   14. check_data_quality\n",
      "   15. generate_sql\n",
      "   16. explain_query\n",
      "\n",
      "ğŸ“‹ Schema â“ What tables are available?\n",
      "----------------------------------------------------------------------\n",
      "Question type: QuestionType.SCHEMA_TABLES\n",
      "   ğŸ”§ Tool: list_tables\n",
      "   ğŸ“ Answer: Found 12 tables (0 source, 12 derived)\n",
      "\n",
      "ğŸ”™ Backward â“ Where does analytics_dev.customer_metrics.lifetime_value come from?\n",
      "----------------------------------------------------------------------\n",
      "Question type: QuestionType.LINEAGE_BACKWARD\n",
      "   ğŸ”§ Tool: trace_backward\n",
      "   ğŸ“ Answer: Column analytics_dev.customer_metrics.lifetime_value is derived from: raw_dev.orders.total_amount\n",
      "\n",
      "ğŸ” Search â“ Find columns containing 'customer'\n",
      "----------------------------------------------------------------------\n",
      "Question type: QuestionType.SCHEMA_SEARCH\n",
      "   ğŸ”§ Tool: search_columns\n",
      "   ğŸ“ Answer: Found 12 columns matching 'customer'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if llm and not SKIP_AGENT:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ¤– LINEAGE AGENT (Natural Language Interface)\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    agent = LineageAgent(pipeline, llm=llm, verbose=True)\n",
    "\n",
    "    print(\"Available tools:\")\n",
    "    for i, tool in enumerate(agent.list_tools(), 1):\n",
    "        print(f\"   {i:2}. {tool}\")\n",
    "    print()\n",
    "\n",
    "    questions = [\n",
    "        (\"ğŸ“‹ Schema\", \"What tables are available?\"),\n",
    "        (\"ğŸ”™ Backward\", \"Where does analytics_dev.customer_metrics.lifetime_value come from?\"),\n",
    "        (\"ğŸ” Search\", \"Find columns containing 'customer'\"),\n",
    "    ]\n",
    "\n",
    "    for category, question in questions:\n",
    "        print(f\"{category} â“ {question}\")\n",
    "        print(\"-\" * 70)\n",
    "        result = agent.query(question)\n",
    "        print(f\"   ğŸ”§ Tool: {result.tool_used}\")\n",
    "        answer = result.answer[:200] + \"...\" if len(result.answer) > 200 else result.answer\n",
    "        print(f\"   ğŸ“ Answer: {answer}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"â­ï¸ Skipping LineageAgent demo (SKIP_AGENT=True or no LLM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-md",
   "metadata": {},
   "source": [
    "### JSON Export\n",
    "\n",
    "Export the pipeline to JSON for persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "export",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:32.016781Z",
     "iopub.status.busy": "2025-12-30T20:10:32.016696Z",
     "iopub.status.idle": "2025-12-30T20:10:32.087562Z",
     "shell.execute_reply": "2025-12-30T20:10:32.087211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ’¾ JSON EXPORT\n",
      "================================================================================\n",
      "\n",
      "Exported pipeline:\n",
      "  â€¢ Dialect: clickhouse\n",
      "  â€¢ Queries: 12\n",
      "  â€¢ Tables: 12\n",
      "  â€¢ Columns: 132\n",
      "  â€¢ Edges: 147\n",
      "\n",
      "ğŸ’¾ Saved to: enterprise_pipeline.json\n",
      "\n",
      "ğŸ”„ Testing round-trip...\n",
      "Info: Skipping lineage for 01_raw_orders (no SELECT statement)\n",
      "Info: Skipping lineage for 02_raw_customers (no SELECT statement)\n",
      "Info: Skipping lineage for 03_raw_products (no SELECT statement)\n",
      "Info: Skipping lineage for 04_raw_order_items (no SELECT statement)\n",
      "âœ… Restored: 12 tables, 132 columns\n",
      "\n",
      "âœ… Demo Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ğŸ’¾ JSON EXPORT\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "data = JSONExporter.export(pipeline, include_metadata=True, include_queries=True)\n",
    "\n",
    "print(\"Exported pipeline:\")\n",
    "print(f\"  â€¢ Dialect: {data['dialect']}\")\n",
    "print(f\"  â€¢ Queries: {len(data['queries'])}\")\n",
    "print(f\"  â€¢ Tables: {len(data['tables'])}\")\n",
    "print(f\"  â€¢ Columns: {len(data['columns'])}\")\n",
    "print(f\"  â€¢ Edges: {len(data['edges'])}\")\n",
    "print()\n",
    "\n",
    "output_path = Path(\".\") / \"enterprise_pipeline.json\"\n",
    "JSONExporter.export_to_file(pipeline, str(output_path), include_queries=True)\n",
    "print(f\"ğŸ’¾ Saved to: {output_path}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ”„ Testing round-trip...\")\n",
    "restored = Pipeline.from_json_file(str(output_path))\n",
    "print(f\"âœ… Restored: {len(restored.table_graph.tables)} tables, {len(restored.columns)} columns\")\n",
    "\n",
    "print()\n",
    "print(\"âœ… Demo Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
