{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daee4c98",
   "metadata": {},
   "source": [
    "# Run Metadata\n",
    "\n",
    "**E-Commerce Pipeline Metadata Management**\n",
    "\n",
    "\n",
    "This script demonstrates how to use clgraph's metadata capabilities:\n",
    "1. Parse inline SQL comment metadata\n",
    "2. Manually assign metadata (PII, owner, tags)\n",
    "3. Propagate metadata through lineage\n",
    "4. Generate descriptions (with LLM or fallback)\n",
    "5. Query columns by metadata\n",
    "6. Trace PII through lineage\n",
    "7. Export metadata to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149fe0f9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702b6d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:54.434032Z",
     "iopub.status.busy": "2025-12-30T20:10:54.433807Z",
     "iopub.status.idle": "2025-12-30T20:10:54.496979Z",
     "shell.execute_reply": "2025-12-30T20:10:54.496520Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from clgraph import Pipeline\n",
    "\n",
    "\n",
    "def load_sql_queries(sql_dir: Path) -> list[tuple[str, str]]:\n",
    "    \"\"\"Load all SQL files from a directory in sorted order.\"\"\"\n",
    "    queries = []\n",
    "    for sql_file in sorted(sql_dir.glob(\"*.sql\")):\n",
    "        with open(sql_file) as f:\n",
    "            sql = f.read()\n",
    "        query_name = sql_file.stem\n",
    "        queries.append((query_name, sql))\n",
    "        print(f\"  Loaded: {query_name}\")\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99eb33b",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8cd313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:54.498327Z",
     "iopub.status.busy": "2025-12-30T20:10:54.498238Z",
     "iopub.status.idle": "2025-12-30T20:10:54.574268Z",
     "shell.execute_reply": "2025-12-30T20:10:54.573937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-Commerce Pipeline Metadata Management\n",
      "\n",
      "  Loaded: 01_raw_orders\n",
      "  Loaded: 02_raw_customers\n",
      "  Loaded: 03_raw_products\n",
      "  Loaded: 04_raw_order_items\n",
      "  Loaded: 05_stg_orders_enriched\n",
      "  Loaded: 06_int_daily_metrics\n",
      "  Loaded: 07_mart_customer_ltv\n",
      "  Loaded: 08_mart_product_perf\n",
      "\n",
      "Loaded 8 SQL files\n",
      "\n",
      "Building pipeline...\n",
      "  Built pipeline with 8 queries\n",
      "  Found 326 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"E-Commerce Pipeline Metadata Management\")\n",
    "print()\n",
    "\n",
    "# Load SQL files from current directory\n",
    "sql_dir = Path(\".\")\n",
    "queries = load_sql_queries(sql_dir)\n",
    "\n",
    "print(f\"\\nLoaded {len(queries)} SQL files\")\n",
    "print()\n",
    "\n",
    "# Build the pipeline\n",
    "print(\"Building pipeline...\")\n",
    "pipeline = Pipeline(queries, dialect=\"duckdb\")\n",
    "print(f\"  Built pipeline with {len(pipeline.table_graph.queries)} queries\")\n",
    "print(f\"  Found {len(pipeline.columns)} columns\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec7db4",
   "metadata": {},
   "source": [
    "### Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f6336f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:54.575302Z",
     "iopub.status.busy": "2025-12-30T20:10:54.575232Z",
     "iopub.status.idle": "2025-12-30T20:10:54.578622Z",
     "shell.execute_reply": "2025-12-30T20:10:54.578318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. INLINE SQL COMMENT METADATA\n",
      "\n",
      "graph can parse structured metadata from SQL comments in the format:\n",
      "<description> [key: value, key2: value2, ...]\n",
      "\n",
      "ample SQL:\n",
      "SELECT\n",
      "    email,           -- User email address [pii: true, owner: data-team]\n",
      "    SUM(amount) as total  /* Total revenue [tags: metric finance] */\n",
      "FROM ...\n",
      "\n",
      "pported metadata keys:\n",
      "- description: Free-text description (before brackets)\n",
      "- pii: Boolean flag (true/false)\n",
      "- owner: String identifying data owner\n",
      "- tags: Space-separated tags\n",
      "- Any custom key-value pairs\n",
      "\n",
      "  Found 49 columns with inline metadata:\n",
      "    raw_orders.order_id:\n",
      "      description: Unique order identifier\n",
      "      owner: data-platform\n",
      "    raw_orders.customer_id:\n",
      "      description: Reference to customer\n",
      "      owner: data-platform\n",
      "    raw_orders.order_date:\n",
      "      description: Date order was placed\n",
      "      owner: finance\n",
      "      tags: {'time'}\n",
      "    raw_orders.order_timestamp:\n",
      "      description: Timestamp order was placed\n",
      "      owner: finance\n",
      "      tags: {'time'}\n",
      "    raw_orders.status:\n",
      "      description: Order status\n",
      "      owner: operations\n",
      "      tags: {'status'}\n",
      "    raw_orders.shipping_address:\n",
      "      description: Customer shipping address\n",
      "      pii: True\n",
      "      owner: data-governance\n",
      "      tags: {'contact'}\n",
      "    raw_orders.payment_method:\n",
      "      description: Payment method used\n",
      "      owner: finance\n",
      "      tags: {'payment'}\n",
      "    raw_orders.subtotal_amount:\n",
      "      description: Order subtotal before tax/shipping\n",
      "      owner: finance\n",
      "      tags: {'revenue', 'metric'}\n",
      "    raw_orders.tax_amount:\n",
      "      description: Tax amount\n",
      "      owner: finance\n",
      "      tags: {'revenue', 'metric'}\n",
      "    raw_orders.shipping_amount:\n",
      "      description: Shipping cost\n",
      "      owner: finance\n",
      "      tags: {'cost', 'metric'}\n",
      "    raw_orders.discount_amount:\n",
      "      description: Discount applied\n",
      "      owner: finance\n",
      "      tags: {'metric'}\n",
      "    raw_orders.total_amount:\n",
      "      description: Total order amount\n",
      "      owner: finance\n",
      "      tags: {'revenue', 'metric'}\n",
      "    raw_orders.channel:\n",
      "      description: Sales channel\n",
      "      owner: marketing\n",
      "      tags: {'attribution'}\n",
      "    raw_orders.device_type:\n",
      "      description: Device type used\n",
      "      owner: marketing\n",
      "      tags: {'attribution'}\n",
      "    raw_orders.ip_address:\n",
      "      description: Customer IP address\n",
      "      pii: True\n",
      "      owner: security\n",
      "      tags: {'sensitive'}\n",
      "    ... and 34 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"1. INLINE SQL COMMENT METADATA\")\n",
    "print(\"\"\"\n",
    "graph can parse structured metadata from SQL comments in the format:\n",
    "<description> [key: value, key2: value2, ...]\n",
    "\n",
    "ample SQL:\n",
    "SELECT\n",
    "    email,           -- User email address [pii: true, owner: data-team]\n",
    "    SUM(amount) as total  /* Total revenue [tags: metric finance] */\n",
    "FROM ...\n",
    "\n",
    "pported metadata keys:\n",
    "- description: Free-text description (before brackets)\n",
    "- pii: Boolean flag (true/false)\n",
    "- owner: String identifying data owner\n",
    "- tags: Space-separated tags\n",
    "- Any custom key-value pairs\n",
    "\"\"\")\n",
    "\n",
    "# Show columns that have inline metadata (from SQL comments)\n",
    "# Metadata is extracted and stored directly on column properties\n",
    "cols_with_inline_metadata = [\n",
    "    col\n",
    "    for col in pipeline.columns.values()\n",
    "    if col.description_source and col.description_source.value == \"source\"\n",
    "]\n",
    "\n",
    "# Deduplicate by (table_name, column_name)\n",
    "seen = set()\n",
    "unique_cols = []\n",
    "for col in cols_with_inline_metadata:\n",
    "    key = (col.table_name, col.column_name)\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        unique_cols.append(col)\n",
    "\n",
    "if unique_cols:\n",
    "    print(f\"  Found {len(unique_cols)} columns with inline metadata:\")\n",
    "    for col in unique_cols[:15]:\n",
    "        print(f\"    {col.table_name}.{col.column_name}:\")\n",
    "        if col.description:\n",
    "            print(f\"      description: {col.description}\")\n",
    "        if col.pii:\n",
    "            print(f\"      pii: {col.pii}\")\n",
    "        if col.owner:\n",
    "            print(f\"      owner: {col.owner}\")\n",
    "        if col.tags:\n",
    "            print(f\"      tags: {col.tags}\")\n",
    "    if len(unique_cols) > 15:\n",
    "        print(f\"    ... and {len(unique_cols) - 15} more\")\n",
    "else:\n",
    "    print(\"  No columns with inline metadata found in these SQL files.\")\n",
    "    print(\"  (Add comments like '-- Description [pii: true]' to columns)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba135d",
   "metadata": {},
   "source": [
    "### Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a28ce98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:54.579594Z",
     "iopub.status.busy": "2025-12-30T20:10:54.579527Z",
     "iopub.status.idle": "2025-12-30T20:10:54.582470Z",
     "shell.execute_reply": "2025-12-30T20:10:54.582203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. MANUAL METADATA ASSIGNMENT\n",
      "\n",
      "r columns without inline metadata, you can assign metadata programmatically:\n",
      "col.pii = True\n",
      "col.owner = \"data-team\"\n",
      "col.tags.add(\"metric\")\n",
      "col.description = \"Custom description\"\n",
      "col.custom_metadata[\"sensitivity\"] = \"high\"\n",
      "\n",
      "te: Columns in raw_orders, raw_customers, raw_products already have metadata\n",
      "om inline SQL comments. Here we add metadata to order_items (which has none).\n",
      "\n",
      "  Adding metadata to raw_order_items:\n",
      "    raw_order_items.order_item_id [owner: data-platform]\n",
      "    raw_order_items.order_id [owner: data-platform]\n",
      "    raw_order_items.product_id [owner: data-platform]\n",
      "    raw_order_items.quantity [owner: operations, tags: {'metric'}, desc: Number of units ordered...]\n",
      "    raw_order_items.unit_price [owner: finance, tags: {'revenue', 'metric'}, desc: Price per unit...]\n",
      "    raw_order_items.line_total [owner: finance, tags: {'revenue', 'metric'}, desc: Total line item amount...]\n",
      "\n",
      "  Added metadata to 6 columns programmatically\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"2. MANUAL METADATA ASSIGNMENT\")\n",
    "print(\"\"\"\n",
    "r columns without inline metadata, you can assign metadata programmatically:\n",
    "col.pii = True\n",
    "col.owner = \"data-team\"\n",
    "col.tags.add(\"metric\")\n",
    "col.description = \"Custom description\"\n",
    "col.custom_metadata[\"sensitivity\"] = \"high\"\n",
    "\n",
    "te: Columns in raw_orders, raw_customers, raw_products already have metadata\n",
    "om inline SQL comments. Here we add metadata to order_items (which has none).\n",
    "\"\"\")\n",
    "\n",
    "# Add metadata to raw_order_items (which doesn't have inline comments)\n",
    "order_item_metadata = [\n",
    "    (\"raw_order_items\", \"order_item_id\", \"data-platform\", None, set()),\n",
    "    (\"raw_order_items\", \"order_id\", \"data-platform\", None, set()),\n",
    "    (\"raw_order_items\", \"product_id\", \"data-platform\", None, set()),\n",
    "    (\"raw_order_items\", \"quantity\", \"operations\", \"Number of units ordered\", {\"metric\"}),\n",
    "    (\"raw_order_items\", \"unit_price\", \"finance\", \"Price per unit\", {\"metric\", \"revenue\"}),\n",
    "    (\n",
    "        \"raw_order_items\",\n",
    "        \"line_total\",\n",
    "        \"finance\",\n",
    "        \"Total line item amount\",\n",
    "        {\"metric\", \"revenue\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"  Adding metadata to raw_order_items:\")\n",
    "marked_count = 0\n",
    "for table, column, owner, description, tags in order_item_metadata:\n",
    "    for col in pipeline.columns.values():\n",
    "        if col.table_name == table and col.column_name == column and not col.owner:\n",
    "            col.owner = owner\n",
    "            if description:\n",
    "                col.description = description\n",
    "            col.tags.update(tags)\n",
    "            marked_count += 1\n",
    "            tag_str = f\", tags: {tags}\" if tags else \"\"\n",
    "            desc_str = f\", desc: {description[:30]}...\" if description else \"\"\n",
    "            print(f\"    {table}.{column} [owner: {owner}{tag_str}{desc_str}]\")\n",
    "\n",
    "print(f\"\\n  Added metadata to {marked_count} columns programmatically\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9bf63",
   "metadata": {},
   "source": [
    "### Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b392d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:54.583561Z",
     "iopub.status.busy": "2025-12-30T20:10:54.583494Z",
     "iopub.status.idle": "2025-12-30T20:10:54.591797Z",
     "shell.execute_reply": "2025-12-30T20:10:54.591505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. METADATA PROPAGATION\n",
      "\n",
      "tadata propagates through lineage automatically:\n",
      "- PII: If any source column is PII, derived column is PII\n",
      "- Owner: First owner found in sources wins\n",
      "- Tags: Union of all source tags\n",
      "\n",
      "is ensures data governance follows the data through transformations.\n",
      "\n",
      "  PII columns before propagation: 6\n",
      "ðŸ“Š Pass 1: Propagating metadata backward from 172 output columns...\n",
      "ðŸ“Š Pass 2: Propagating metadata forward for 172 columns...\n",
      "âœ… Done! Propagated metadata for 172 columns\n",
      "  PII columns after propagation:  16\n",
      "  New PII columns discovered:     10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"3. METADATA PROPAGATION\")\n",
    "print(\"\"\"\n",
    "tadata propagates through lineage automatically:\n",
    "- PII: If any source column is PII, derived column is PII\n",
    "- Owner: First owner found in sources wins\n",
    "- Tags: Union of all source tags\n",
    "\n",
    "is ensures data governance follows the data through transformations.\n",
    "\"\"\")\n",
    "\n",
    "# Check PII before propagation\n",
    "pii_before = len(pipeline.get_pii_columns())\n",
    "print(f\"  PII columns before propagation: {pii_before}\")\n",
    "\n",
    "# Propagate metadata\n",
    "pipeline.propagate_all_metadata()\n",
    "\n",
    "# Check PII after propagation\n",
    "pii_after = len(pipeline.get_pii_columns())\n",
    "print(f\"  PII columns after propagation:  {pii_after}\")\n",
    "print(f\"  New PII columns discovered:     {pii_after - pii_before}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc1fa3",
   "metadata": {},
   "source": [
    "### Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13456c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:54.592814Z",
     "iopub.status.busy": "2025-12-30T20:10:54.592749Z",
     "iopub.status.idle": "2025-12-30T20:10:58.704412Z",
     "shell.execute_reply": "2025-12-30T20:10:58.703138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. DESCRIPTION GENERATION\n",
      "\n",
      "graph can generate descriptions for columns that don't have them.\n",
      "\n",
      "pported LLM backends:\n",
      "- Ollama (local, free): ollama pull llama3.2\n",
      "- OpenAI: requires OPENAI_API_KEY\n",
      "\n",
      "age:\n",
      "pipeline.llm = llm_instance\n",
      "pipeline.generate_all_descriptions()\n",
      "\n",
      "  Columns in derived tables without descriptions: 119\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting to connect to Ollama...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Connected to Ollama (model: qwen3-coder:30b)\n",
      "\n",
      "  Generating descriptions for sample columns...\n",
      "  (Generating for 5 columns to save time)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stg_orders_enriched.customer_id:\n",
      "      -> Customer identifier referencing raw_orders table, per order record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stg_orders_enriched.order_date:\n",
      "      -> Order date when customers placed their purchases per day.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stg_orders_enriched.order_timestamp:\n",
      "      -> Order timestamp from raw data, per order record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stg_orders_enriched.status:\n",
      "      -> Order status indicator per raw_orders source table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stg_orders_enriched.channel:\n",
      "      -> Sales channel per order, derived from raw_orders table.\n",
      "\n",
      "  To generate all descriptions, run: pipeline.generate_all_descriptions()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"4. DESCRIPTION GENERATION\")\n",
    "print(\"\"\"\n",
    "graph can generate descriptions for columns that don't have them.\n",
    "\n",
    "pported LLM backends:\n",
    "- Ollama (local, free): ollama pull llama3.2\n",
    "- OpenAI: requires OPENAI_API_KEY\n",
    "\n",
    "age:\n",
    "pipeline.llm = llm_instance\n",
    "pipeline.generate_all_descriptions()\n",
    "\"\"\")\n",
    "\n",
    "# Count columns without descriptions in derived tables\n",
    "cols_without_desc = [\n",
    "    col\n",
    "    for col in pipeline.columns.values()\n",
    "    if not col.description and col.table_name.startswith((\"int_\", \"mart_\", \"stg_\"))\n",
    "]\n",
    "\n",
    "# Deduplicate\n",
    "seen = set()\n",
    "unique_without_desc = []\n",
    "for col in cols_without_desc:\n",
    "    key = (col.table_name, col.column_name)\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        unique_without_desc.append(col)\n",
    "\n",
    "print(f\"  Columns in derived tables without descriptions: {len(unique_without_desc)}\")\n",
    "print()\n",
    "\n",
    "# Try to use Ollama for description generation\n",
    "llm_available = False\n",
    "ollama_models = [\"llama3:latest\", \"llama3.2\", \"qwen3-coder:30b\"]  # Try these in order\n",
    "\n",
    "try:\n",
    "    from langchain_ollama import ChatOllama\n",
    "\n",
    "    print(\"  Attempting to connect to Ollama...\")\n",
    "    for model_name in ollama_models:\n",
    "        try:\n",
    "            llm = ChatOllama(\n",
    "                model=model_name,\n",
    "                temperature=0.3,\n",
    "            )\n",
    "            # Test connection with a simple call\n",
    "            llm.invoke(\"test\")\n",
    "            pipeline.llm = llm\n",
    "            llm_available = True\n",
    "            print(f\"  Connected to Ollama (model: {model_name})\")\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not llm_available:\n",
    "        raise Exception(\"No working Ollama model found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  Ollama not available: {type(e).__name__}\")\n",
    "    print(\"  To enable LLM descriptions:\")\n",
    "    print(\"    1. Install Ollama: brew install ollama\")\n",
    "    print(\"    2. Pull model: ollama pull llama3:latest\")\n",
    "    print(\"    3. Start server: ollama serve\")\n",
    "print()\n",
    "\n",
    "if llm_available:\n",
    "    # Generate descriptions for a few sample columns to demonstrate\n",
    "    print(\"  Generating descriptions for sample columns...\")\n",
    "    print(\"  (Generating for 5 columns to save time)\")\n",
    "    print()\n",
    "\n",
    "    sample_cols = unique_without_desc[:5]\n",
    "    for col in sample_cols:\n",
    "        try:\n",
    "            # Import the generate function\n",
    "            from clgraph.column import generate_description\n",
    "\n",
    "            generate_description(col, pipeline.llm, pipeline)\n",
    "            print(f\"    {col.table_name}.{col.column_name}:\")\n",
    "            print(f\"      -> {col.description}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    {col.table_name}.{col.column_name}: Error - {e}\")\n",
    "    print()\n",
    "    print(\"  To generate all descriptions, run: pipeline.generate_all_descriptions()\")\n",
    "else:\n",
    "    print(\"  Sample columns that would get descriptions:\")\n",
    "    for col in unique_without_desc[:5]:\n",
    "        print(f\"    - {col.table_name}.{col.column_name}\")\n",
    "    if len(unique_without_desc) > 5:\n",
    "        print(f\"    ... and {len(unique_without_desc) - 5} more\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e192d5",
   "metadata": {},
   "source": [
    "### Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d050d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:58.705590Z",
     "iopub.status.busy": "2025-12-30T20:10:58.705465Z",
     "iopub.status.idle": "2025-12-30T20:10:58.709543Z",
     "shell.execute_reply": "2025-12-30T20:10:58.709196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. QUERYING COLUMNS BY METADATA\n",
      "  5a. PII Columns (get_pii_columns)\n",
      "  Found 16 PII columns:\n",
      "    raw_customers:\n",
      "      - email\n",
      "      - first_name\n",
      "      - last_name\n",
      "      - phone_number\n",
      "    raw_orders:\n",
      "      - ip_address\n",
      "      - shipping_address\n",
      "    source_customers:\n",
      "      - email\n",
      "      - first_name\n",
      "      - last_name\n",
      "      - phone_number\n",
      "    source_orders:\n",
      "      - ip_address\n",
      "      - shipping_address\n",
      "    stg_orders_enriched:\n",
      "      - customer_email\n",
      "      - customer_first_name\n",
      "      - customer_full_name\n",
      "      - customer_last_name\n",
      "\n",
      "  5b. Columns by Owner (get_columns_by_owner)\n",
      "    data-governance: 14 unique columns\n",
      "    data-platform: 22 unique columns\n",
      "    finance: 33 unique columns\n",
      "    inventory: 2 unique columns\n",
      "    marketing: 18 unique columns\n",
      "    operations: 5 unique columns\n",
      "    product: 8 unique columns\n",
      "    security: 2 unique columns\n",
      "\n",
      "  5c. Columns by Tag (get_columns_by_tag)\n",
      "    'attribution': 6 unique columns\n",
      "    'category': 2 unique columns\n",
      "    'confidential': 2 unique columns\n",
      "    'contact': 7 unique columns\n",
      "    'cost': 5 unique columns\n",
      "    'geo': 6 unique columns\n",
      "    'loyalty': 3 unique columns\n",
      "    'metric': 26 unique columns\n",
      "    'payment': 3 unique columns\n",
      "    'product': 8 unique columns\n",
      "    'revenue': 15 unique columns\n",
      "    'sensitive': 2 unique columns\n",
      "    'status': 5 unique columns\n",
      "    'time': 7 unique columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"5. QUERYING COLUMNS BY METADATA\")\n",
    "\n",
    "# 5a. Get PII columns\n",
    "print(\"  5a. PII Columns (get_pii_columns)\")\n",
    "pii_columns = pipeline.get_pii_columns()\n",
    "print(f\"  Found {len(pii_columns)} PII columns:\")\n",
    "\n",
    "# Group by table for cleaner output\n",
    "pii_by_table = {}\n",
    "for col in pii_columns:\n",
    "    if col.table_name not in pii_by_table:\n",
    "        pii_by_table[col.table_name] = []\n",
    "    pii_by_table[col.table_name].append(col.column_name)\n",
    "\n",
    "for table in sorted(pii_by_table.keys()):\n",
    "    cols = sorted(set(pii_by_table[table]))  # dedupe\n",
    "    print(f\"    {table}:\")\n",
    "    for col_name in cols[:5]:\n",
    "        print(f\"      - {col_name}\")\n",
    "    if len(cols) > 5:\n",
    "        print(f\"      ... and {len(cols) - 5} more\")\n",
    "print()\n",
    "\n",
    "# 5b. Get columns by owner\n",
    "print(\"  5b. Columns by Owner (get_columns_by_owner)\")\n",
    "\n",
    "owners = set()\n",
    "for col in pipeline.columns.values():\n",
    "    if col.owner:\n",
    "        owners.add(col.owner)\n",
    "\n",
    "for owner in sorted(owners):\n",
    "    cols = pipeline.get_columns_by_owner(owner)\n",
    "    unique_cols = {(c.table_name, c.column_name) for c in cols}\n",
    "    print(f\"    {owner}: {len(unique_cols)} unique columns\")\n",
    "print()\n",
    "\n",
    "# 5c. Get columns by tag\n",
    "print(\"  5c. Columns by Tag (get_columns_by_tag)\")\n",
    "\n",
    "all_tags = set()\n",
    "for col in pipeline.columns.values():\n",
    "    all_tags.update(col.tags)\n",
    "\n",
    "for tag in sorted(all_tags):\n",
    "    cols = pipeline.get_columns_by_tag(tag)\n",
    "    unique_cols = {(c.table_name, c.column_name) for c in cols}\n",
    "    print(f\"    '{tag}': {len(unique_cols)} unique columns\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d3283",
   "metadata": {},
   "source": [
    "### Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab1e2f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:58.710622Z",
     "iopub.status.busy": "2025-12-30T20:10:58.710525Z",
     "iopub.status.idle": "2025-12-30T20:10:58.713925Z",
     "shell.execute_reply": "2025-12-30T20:10:58.713399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. TRACING PII THROUGH LINEAGE\n",
      "\n",
      "mbine metadata with lineage to understand PII data flow:\n",
      "- Forward trace: Where does PII data go?\n",
      "- Backward trace: Where did PII originate?\n",
      "\n",
      "  Example: stg_orders_enriched.customer_email\n",
      "\n",
      "  Backward trace (where did PII originate?):\n",
      "    <- source_customers.email [PII SOURCE]\n",
      "\n",
      "  Forward trace (where does raw_customers.email go?):\n",
      "    -> mart_customer_ltv.customer_email\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"6. TRACING PII THROUGH LINEAGE\")\n",
    "print(\"\"\"\n",
    "mbine metadata with lineage to understand PII data flow:\n",
    "- Forward trace: Where does PII data go?\n",
    "- Backward trace: Where did PII originate?\n",
    "\"\"\")\n",
    "\n",
    "# Find a PII column in a derived table (not raw_)\n",
    "pii_derived_cols = [\n",
    "    col\n",
    "    for col in pipeline.get_pii_columns()\n",
    "    if not col.table_name.startswith(\"raw_\") and not col.table_name.startswith(\"source_\")\n",
    "]\n",
    "\n",
    "if pii_derived_cols:\n",
    "    # Pick one example\n",
    "    example_col = pii_derived_cols[0]\n",
    "    print(f\"  Example: {example_col.table_name}.{example_col.column_name}\")\n",
    "    print()\n",
    "\n",
    "    # Trace backward to find PII source\n",
    "    print(\"  Backward trace (where did PII originate?):\")\n",
    "    try:\n",
    "        sources = pipeline.trace_column_backward(example_col.table_name, example_col.column_name)\n",
    "        for source in sources:\n",
    "            pii_flag = \" [PII SOURCE]\" if source.pii else \"\"\n",
    "            print(f\"    <- {source.table_name}.{source.column_name}{pii_flag}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {e}\")\n",
    "else:\n",
    "    print(\"  No PII columns found in derived tables.\")\n",
    "\n",
    "# Forward trace from a source PII column\n",
    "print()\n",
    "print(\"  Forward trace (where does raw_customers.email go?):\")\n",
    "try:\n",
    "    impacts = pipeline.trace_column_forward(\"raw_customers\", \"email\")\n",
    "    if impacts:\n",
    "        for impact in impacts[:8]:\n",
    "            print(f\"    -> {impact.table_name}.{impact.column_name}\")\n",
    "        if len(impacts) > 8:\n",
    "            print(f\"    ... and {len(impacts) - 8} more\")\n",
    "    else:\n",
    "        print(\"    (no downstream impacts found)\")\n",
    "except Exception as e:\n",
    "    print(f\"    Error: {e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01788c35",
   "metadata": {},
   "source": [
    "### Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a647d2f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:58.715225Z",
     "iopub.status.busy": "2025-12-30T20:10:58.715126Z",
     "iopub.status.idle": "2025-12-30T20:10:58.719147Z",
     "shell.execute_reply": "2025-12-30T20:10:58.718770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. EXPORT TO JSON\n",
      "\n",
      "port pipeline with metadata to JSON for external tools:\n",
      "data = pipeline.to_json(include_metadata=True)\n",
      "\n",
      "  JSON export contains:\n",
      "    - columns: 326 entries\n",
      "    - edges: 350 entries\n",
      "    - tables: 22 entries\n",
      "\n",
      "  Sample column entry:\n",
      "    {\n",
      "      \"column_name\": \"order_id\",\n",
      "      \"table_name\": \"raw_orders\",\n",
      "      \"description\": \"Unique order identifier\",\n",
      "      \"owner\": \"data-platform\",\n",
      "      \"pii\": false,\n",
      "      \"tags\": []\n",
      "}\n",
      "\n",
      "  To save to file:\n",
      "    with open(\"lineage.json\", \"w\") as f:\n",
      "        json.dump(pipeline.to_json(), f, indent=2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"7. EXPORT TO JSON\")\n",
    "print(\"\"\"\n",
    "port pipeline with metadata to JSON for external tools:\n",
    "data = pipeline.to_json(include_metadata=True)\n",
    "\"\"\")\n",
    "\n",
    "json_data = pipeline.to_json(include_metadata=True)\n",
    "\n",
    "print(\"  JSON export contains:\")\n",
    "print(f\"    - columns: {len(json_data.get('columns', []))} entries\")\n",
    "print(f\"    - edges: {len(json_data.get('edges', []))} entries\")\n",
    "print(f\"    - tables: {len(json_data.get('tables', []))} entries\")\n",
    "\n",
    "# Show sample column with metadata\n",
    "print(\"\\n  Sample column entry:\")\n",
    "sample_col = None\n",
    "for col_data in json_data.get(\"columns\", []):\n",
    "    if col_data.get(\"pii\") or col_data.get(\"owner\"):\n",
    "        sample_col = col_data\n",
    "        break\n",
    "\n",
    "if sample_col:\n",
    "    # Pretty print with limited fields\n",
    "    display_data = {\n",
    "        k: v\n",
    "        for k, v in sample_col.items()\n",
    "        if k in [\"table_name\", \"column_name\", \"pii\", \"owner\", \"tags\", \"description\"]\n",
    "    }\n",
    "    print(f\"    {json.dumps(display_data, indent=6)}\")\n",
    "\n",
    "# Export to file example\n",
    "print(\"\\n  To save to file:\")\n",
    "print('    with open(\"lineage.json\", \"w\") as f:')\n",
    "print(\"        json.dump(pipeline.to_json(), f, indent=2)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4904ae1",
   "metadata": {},
   "source": [
    "### Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680bd9dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:10:58.720153Z",
     "iopub.status.busy": "2025-12-30T20:10:58.720082Z",
     "iopub.status.idle": "2025-12-30T20:10:58.724504Z",
     "shell.execute_reply": "2025-12-30T20:10:58.723926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METADATA SUMMARY\n",
      "  Total columns:     326\n",
      "  PII columns:       16 unique\n",
      "  Owned columns:     104 unique\n",
      "  Tagged columns:    97 unique\n",
      "\n",
      "  Owners:\n",
      "    - data-governance: 14 columns\n",
      "    - data-platform: 22 columns\n",
      "    - finance: 33 columns\n",
      "    - inventory: 2 columns\n",
      "    - marketing: 18 columns\n",
      "    - operations: 5 columns\n",
      "    - product: 8 columns\n",
      "    - security: 2 columns\n",
      "\n",
      "  Tags:\n",
      "    - attribution: 6 columns\n",
      "    - category: 2 columns\n",
      "    - confidential: 2 columns\n",
      "    - contact: 7 columns\n",
      "    - cost: 5 columns\n",
      "    - geo: 6 columns\n",
      "    - loyalty: 3 columns\n",
      "    - metric: 26 columns\n",
      "    - payment: 3 columns\n",
      "    - product: 8 columns\n",
      "    - revenue: 15 columns\n",
      "    - sensitive: 2 columns\n",
      "    - status: 5 columns\n",
      "    - time: 7 columns\n",
      "\n",
      "Metadata management complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"METADATA SUMMARY\")\n",
    "\n",
    "# Count unique columns with each type of metadata\n",
    "unique_pii = set()\n",
    "unique_owners = {}\n",
    "unique_tags = {}\n",
    "\n",
    "for col in pipeline.columns.values():\n",
    "    key = (col.table_name, col.column_name)\n",
    "    if col.pii:\n",
    "        unique_pii.add(key)\n",
    "    if col.owner:\n",
    "        if col.owner not in unique_owners:\n",
    "            unique_owners[col.owner] = set()\n",
    "        unique_owners[col.owner].add(key)\n",
    "    for tag in col.tags:\n",
    "        if tag not in unique_tags:\n",
    "            unique_tags[tag] = set()\n",
    "        unique_tags[tag].add(key)\n",
    "\n",
    "print(f\"  Total columns:     {len(pipeline.columns)}\")\n",
    "print(f\"  PII columns:       {len(unique_pii)} unique\")\n",
    "print(f\"  Owned columns:     {sum(len(v) for v in unique_owners.values())} unique\")\n",
    "print(f\"  Tagged columns:    {sum(len(v) for v in unique_tags.values())} unique\")\n",
    "print()\n",
    "print(\"  Owners:\")\n",
    "for owner in sorted(unique_owners.keys()):\n",
    "    print(f\"    - {owner}: {len(unique_owners[owner])} columns\")\n",
    "print()\n",
    "print(\"  Tags:\")\n",
    "for tag in sorted(unique_tags.keys()):\n",
    "    print(f\"    - {tag}: {len(unique_tags[tag])} columns\")\n",
    "print()\n",
    "print(\"Metadata management complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
