from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
import os

class ChatTranslateLLM(ChatOpenAI):
    """
    åŸºäº LangChain OpenAI æ¥å£çš„ç¿»è¯‘ä¸å…³é”®è¯æŠ½å–ç±»ã€‚
    æ”¯æŒä¸­æ–‡ç¿»è¯‘ä¸å…³é”®è¯æå–ä»»åŠ¡ã€‚
    """

    def __init__(
        self,
        model_name: str = "deepseek-v3:671b",
        openai_api_base: str = "https://uni-api.cstcloud.cn/v1",
        **kwargs
    ):
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("Environment variable OPENAI_API_KEY is not set.")
        super().__init__(
            model_name=model_name,
            openai_api_base=openai_api_base,
            openai_api_key=openai_api_key,
            **kwargs
        )

    def translate(self, content: str) -> str:
        prompt = "è¯·åªç¿»è¯‘ä¸‹é¢çš„è‹±æ–‡ä¸ºä¸­æ–‡ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Šï¼š\n"
        response = self.invoke([HumanMessage(content=prompt + content)])
        return response.content.strip()

    def extract_key_words(self, content: str) -> str:
        prompt = (
            "ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼Œè¦æ±‚è¿”å›å…³é”®è¯åˆ—è¡¨ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ï¼Œä¸é™„å¸¦å¤šä½™è¯´æ˜ã€‚"
        )
        response = self.invoke([HumanMessage(content=prompt + content)])
        return response.content.strip()
    
    def extract_key_words(self, content: str) -> str:
        prompt = (
            "ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼Œè¦æ±‚è¿”å›å…³é”®è¯åˆ—è¡¨ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ï¼Œä¸é™„å¸¦å¤šä½™è¯´æ˜ã€‚"
        )
        response = self.invoke([HumanMessage(content=prompt + content)])
        return response.content.strip()
    
    def interpretation(self, title: str, content: str) -> str:
        prompt = (
            f"è¯·å¯¹ä»¥ä¸‹è®ºæ–‡è¿›è¡Œæ·±å…¥è§£è¯»ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šç ”ç©¶ç›®çš„ã€ç ”ç©¶æ–¹æ³•ã€æ ¸å¿ƒè§‚ç‚¹ã€åˆ›æ–°ç‚¹å’Œæ½œåœ¨å½±å“ã€‚"
            f"è¦æ±‚è¯­è¨€ç®€æ´ã€é€»è¾‘æ¸…æ™°ã€æ¡ç†æ˜ç¡®ï¼Œä¸æ·»åŠ ä¸å†…å®¹æ— å…³çš„è¯„ä»·ã€‚\n\n"
            f"ã€è®ºæ–‡æ ‡é¢˜ã€‘\n{title}\n\n"
            f"ã€è®ºæ–‡å†…å®¹ã€‘\n{content}\n"
        )
        response = self.invoke([HumanMessage(content=prompt)])
        return response.content.strip()
    

def main():
    # å®ä¾‹åŒ–æ¨¡å‹
    llm = ChatTranslateLLM()

    # æµ‹è¯•è‹±æ–‡ç¿»è¯‘
    english_text = "Large language models are transforming the way we interact with knowledge."
    translated = llm.translate(english_text)
    print("ğŸ” ç¿»è¯‘ç»“æœ:")
    print(translated)
    print("\n")

    # æµ‹è¯•å…³é”®è¯æå–
    abstract_text = (
        "This paper proposes a new multi-agent reinforcement learning algorithm "
        "that achieves higher sample efficiency in dynamic environments."
    )
    keywords = llm.extract_key_words(abstract_text)
    print("ğŸ” å…³é”®è¯æå–ç»“æœ:")
    print(keywords)

if __name__ == "__main__":
    main()