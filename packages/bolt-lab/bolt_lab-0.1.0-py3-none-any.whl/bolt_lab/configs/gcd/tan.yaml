seed: 0
gpu_id: "0"

data_dir: "./data"
bert_model: "./pretrained_models/bert-base-uncased"
output_dir: "./outputs/gcd/tan"
save_results_path: "./results/gcd/tan"

dataset: "banking"
known_cls_ratio: 0.75
labeled_ratio: 0.1
fold_num: 5
feat_dim: 768

num_train_epochs: 100
train_batch_size: 256
eval_batch_size: 64
lr: 1e-5
warmup_proportion: 0.1
wait_patient: 20       
es_metric: sum         
es_patience: 8         
es_min_delta: 0.1      
save_best: true
beta: 100
topk: 5.0
alpha: 0.8
temperature: 0.07
cluster_num_factor: 1.0

num_pretrain_epochs: 100
pretrain_batch_size: 32
lr_pre: 1e-5

dataset_specific_configs:
  clinc:
    max_seq_length: 30
    num_train_epochs: 20
  stackoverflow:
    max_seq_length: 45
    num_train_epochs: 10
  banking:
    max_seq_length: 55
    num_train_epochs: 20
  hwu:
    max_seq_length: 55
    num_train_epochs: 20
  mcid:
    max_seq_length: 55
    num_train_epochs: 20
  ecdt:
    max_seq_length: 55
    num_train_epochs: 20
  AGNews:
    max_seq_length: 128
    num_train_epochs: 20
  DBPedia:
    max_seq_length: 256
    num_train_epochs: 20
    train_batch_size: 16
    eval_batch_size: 32
    pretrain_batch_size: 16
  20NG: 
    max_seq_length: 512
    num_train_epochs: 20
    train_batch_size: 16
    eval_batch_size: 32
    pretrain_batch_size: 16
  TREC:
    max_seq_length: 40
    num_train_epochs: 20
  Yahoo: 
    max_seq_length: 128
    num_train_epochs: 20
    train_batch_size: 16
    eval_batch_size: 32
  ele:
    max_seq_length: 200
    num_train_epochs: 20
    train_batch_size: 16
    eval_batch_size: 32
  news:
    max_seq_length: 500
    num_train_epochs: 20
    train_batch_size: 8
    eval_batch_size: 32
    pretrain_batch_size: 16
  thucnews:
    max_seq_length: 500
    num_train_epochs: 20
    train_batch_size: 16
    eval_batch_size: 32
    pretrain_batch_size: 16
  medical:
    max_seq_length: 256
    num_train_epochs: 20
  XTopic:
    max_seq_length: 128
    train_batch_size: 16
    eval_batch_size: 32
    pretrain_batch_size: 16