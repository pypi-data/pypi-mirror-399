Metadata-Version: 2.4
Name: entari_plugin_hyw
Version: 3.3.7
Summary: Use large language models to interpret chat messages
Author-email: kumoSleeping <zjr2992@outlook.com>
License: MIT
Project-URL: Homepage, https://github.com/kumoSleeping/entari-plugin-hyw
Project-URL: Repository, https://github.com/kumoSleeping/entari-plugin-hyw
Project-URL: Issue Tracker, https://github.com/kumoSleeping/entari-plugin-hyw/issues
Keywords: entari,llm,ai,bot,chat
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: arclet-entari[full]>=0.16.5
Requires-Dist: openai
Requires-Dist: httpx
Requires-Dist: markdown>=3.10
Requires-Dist: crawl4ai>=0.7.8
Requires-Dist: jinja2>=3.0
Requires-Dist: ddgs>=9.10.0
Provides-Extra: dev
Requires-Dist: entari-plugin-server>=0.5.0; extra == "dev"
Requires-Dist: satori-python-adapter-onebot11>=0.2.5; extra == "dev"


# Entari Plugin HYW


[![PyPI version](https://badge.fury.io/py/entari-plugin-hyw.svg)](https://badge.fury.io/py/entari-plugin-hyw)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Versions](https://img.shields.io/pypi/pyversions/entari-plugin-hyw.svg)](https://pypi.org/project/entari-plugin-hyw/)

**Entari Plugin HYW** is an advanced agentic chat plugin for the [Entari](https://github.com/entari-org/entari) framework. It leverages Large Language Models (LLMs) to provide intelligent, context-aware, and multi-modal responses within instant messaging environments (OneBot 11, Satori).

**Entari Plugin HYW** æ˜¯ Entari æ¡†æ¶çš„é«˜çº§æ™ºèƒ½ä½“èŠå¤©æ’ä»¶ã€‚å®ƒåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å³æ—¶é€šè®¯ç¯å¢ƒï¼ˆOneBot 11, Satoriï¼‰ä¸­æä¾›æ™ºèƒ½ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥å’Œå¤šæ¨¡æ€çš„å›å¤ä½“éªŒã€‚

The plugin implements a three-stage pipeline (**Vision**, **Instruct**, **Agent**) to autonomously decide when to search the web, crawl pages, or analyze images to answer user queries effectively.

æ’ä»¶å®ç°äº†ä¸‰é˜¶æ®µæµæ°´çº¿ï¼ˆ**è§†è§‰**ã€**æŒ‡ä»¤**ã€**ä»£ç†**ï¼‰ï¼Œèƒ½å¤Ÿè‡ªä¸»å†³å®šä½•æ—¶æœç´¢ç½‘ç»œã€æŠ“å–ç½‘é¡µæˆ–åˆ†æå›¾ç‰‡ï¼Œä»è€Œé«˜æ•ˆåœ°å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

<img src="demo.jpg" width="300" />

## Features / åŠŸèƒ½ç‰¹æ€§

- ğŸ“– **Agentic Workflow (æ™ºèƒ½å·¥ä½œæµ)**  
  Autonomous decision-making process to search, browse, and reason.  
  å…·å¤‡è‡ªä¸»å†³ç­–èƒ½åŠ›ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¿›è¡Œæœç´¢ã€ç½‘é¡µæµè§ˆå’Œé€»è¾‘æ¨ç†ã€‚

- ğŸ‘ **Multi-Modal Support (å¤šæ¨¡æ€æ”¯æŒ)**  
  Native support for image analysis using Vision Language Models (VLMs).  
  åŸç”Ÿæ”¯æŒå›¾ç‰‡åˆ†æï¼Œåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ç†è§£å›¾åƒå†…å®¹ã€‚

- ğŸ” **Web Search & Crawling (æœç´¢ä¸æŠ“å–)**  
  Integrated **DuckDuckGo** and **Crawl4AI** for real-time information retrieval.  
  é›†æˆ DuckDuckGo æœç´¢ä¸ Crawl4AI ç½‘é¡µæŠ“å–ï¼Œå®æ—¶è·å–äº’è”ç½‘ä¿¡æ¯ã€‚

- ğŸ¨ **Rich Rendering (å¯Œåª’ä½“æ¸²æŸ“)**  
  Responses are rendered as images containing Markdown, syntax-highlighted code, LaTeX math, and citation badges.  
  å›ç­”å°†æ¸²æŸ“ä¸ºåŒ…å« Markdownã€ä»£ç é«˜äº®ã€LaTeX å…¬å¼åŠå¼•ç”¨è§’æ ‡çš„ç²¾ç¾å›¾ç‰‡ã€‚

- ğŸ”Œ **Protocol Support (å¤šåè®®é€‚é…)**  
  Deep integration with OneBot 11 and Satori protocols.  
  æ·±åº¦é€‚é… OneBot 11 å’Œ Satori åè®®ï¼Œå®Œç¾å¤„ç†å›å¤ä¸Šä¸‹æ–‡ä¸ JSON å¡ç‰‡ã€‚

## Installation / å®‰è£…

```bash
pip install entari-plugin-hyw
```

## Configuration / é…ç½®

Configure the plugin in your `entari.yml`.  
åœ¨ `entari.yml` ä¸­è¿›è¡Œé…ç½®ã€‚

### Minimal Configuration / æœ€å°é…ç½®

```yaml
plugins:
  entari_plugin_hyw:
    # Trigger command / è§¦å‘æŒ‡ä»¤
    question_command: ".q"
    
    # Main Model (Required) / ä¸»æ¨¡å‹ï¼ˆå¿…éœ€ï¼‰
    model_name: "google/gemini-2.0-flash-exp"
    api_key: "your-api-key-here"
    base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
```

### Configuration Reference / é…ç½®è¯¦è§£

| Option (é€‰é¡¹) | Type | Default | Description (è¯´æ˜) |
| :--- | :--- | :--- | :--- |
| **Basic** | | | |
| `question_command` | `str` | `/q` | The command to trigger the bot. <br> è§¦å‘æœºå™¨äººçš„æŒ‡ä»¤å‰ç¼€ã€‚ |
| `reaction` | `bool` | `true` | React with emoji on start(now only lagrange ob extension). <br> æ”¶åˆ°æŒ‡ä»¤æ—¶æ˜¯å¦å›åº”è¡¨æƒ…(ç›®å‰åªæ”¯æŒæ‹‰æ ¼å…°obæ‰©å±•)ã€‚ |
| `quote` | `bool` | `true` | Quote the user's message in reply. <br> å›å¤æ—¶æ˜¯å¦å¼•ç”¨åŸæ¶ˆæ¯ã€‚ |
| **Models** | | | |
| `model_name` | `str` | *None* | **Required.** Main Agent model ID. <br> **å¿…éœ€ã€‚** ä¸»ä»£ç†æ¨¡å‹ IDã€‚ |
| `api_key` | `str` | *None* | **Required.** API key. <br> **å¿…éœ€ã€‚** API å¯†é’¥ã€‚ |
| `base_url` | `str` | `...` | OpenAI-compatible API base URL. <br> å…¼å®¹ OpenAI çš„ API åœ°å€ã€‚ |
| `extra_body` | `dict` | `null` | Extra parameters (e.g. `reasoning_effort`). <br> ä¼ é€’ç»™ LLM çš„é¢å¤–å‚æ•°ã€‚ |
| **Specialized** | | | |
| `vision_model_name`| `str` | *None* | Model for images. Defaults to `model_name`. <br> å¤„ç†å›¾ç‰‡çš„æ¨¡å‹ï¼Œé»˜è®¤åŒä¸»æ¨¡å‹ã€‚ |
| `intruct_model_name`| `str` | *None* | Model for intent. Defaults to `model_name`. <br> æ„å›¾è¯†åˆ«æ¨¡å‹ï¼Œé»˜è®¤åŒä¸»æ¨¡å‹ã€‚ |
| **Tools** | | | |
| `search_provider` | `str` | `ddgs`| `ddgs` (DuckDuckGo), `crawl4ai`, `httpx`. <br> æœç´¢åç«¯æä¾›å•†ã€‚ |
| `search_limit` | `int` | `8` | Max search results. <br> æœç´¢ç»“æœæ•°é‡é™åˆ¶ã€‚ |
| `headless` | `bool` | `true` | Browser headless mode. <br> æµè§ˆå™¨æ— å¤´æ¨¡å¼ã€‚ |

## Usage / ä½¿ç”¨æ–¹æ³•

### Commands / æŒ‡ä»¤

- **Text Query (æ–‡æœ¬é—®ç­”)**
  ```text
  .q What's the latest news on Rust 1.83?
  .q Rust 1.83 æœ‰ä»€ä¹ˆæ–°ç‰¹æ€§ï¼Ÿ
  ```

- **Image Analysis (å›¾ç‰‡åˆ†æ)**
  *(Send an image with command, or reply to an image)*  
  *(å‘é€å¸¦å›¾ç‰‡çš„æŒ‡ä»¤ï¼Œæˆ–å›å¤ä¸€å¼ å›¾ç‰‡)*
  ```text
  .q [Image] Explain this error.
  .q [å›¾ç‰‡] è§£é‡Šä¸€ä¸‹è¿™ä¸ªæŠ¥é”™ã€‚
  ```

- **Follow-up (è¿½é—®)**
  *Reply to the bot's message to continue the conversation.*  
  *ç›´æ¥å›å¤æœºå™¨äººçš„æ¶ˆæ¯å³å¯è¿›è¡Œè¿ç»­å¯¹è¯ã€‚*

-----

## License

This project is licensed under the MIT License.
