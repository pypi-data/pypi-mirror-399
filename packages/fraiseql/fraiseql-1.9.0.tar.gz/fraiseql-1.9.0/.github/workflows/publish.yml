name: Publish

on:
  push:
    tags:
      - 'v*'

jobs:
  test:
    name: Tests (Required for Release)
    runs-on: ubuntu-latest

    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_USER: fraiseql
          POSTGRES_PASSWORD: fraiseql
          POSTGRES_DB: fraiseql_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'

    - name: Install uv
      uses: astral-sh/setup-uv@v7

    - name: Setup Rust toolchain
      uses: dtolnay/rust-toolchain@stable
      with:
        toolchain: stable

    - name: Install maturin
      run: uv tool install maturin

    - name: Build and install with production optimization
      run: |
        # Create virtual environment with uv
        uv venv

        echo "=== Building production wheel with Rust extension ==="
        # Build optimized release wheel (production-ready)
        maturin build --release --out dist

        echo "=== Installing built wheel with dependencies ==="
        WHEEL=$(ls dist/fraiseql-*.whl)
        uv pip install "$WHEEL[dev,all]" --no-cache

        echo "=== Verifying bundled Rust extension ==="
        uv run python -c "from fraiseql import _fraiseql_rs; print(f'Bundled extension version: {_fraiseql_rs.__version__}')"
        uv run python -c "from fraiseql import _fraiseql_rs; print(f'Functions: {[f for f in dir(_fraiseql_rs) if not f.startswith(\"_\")]}')"

        echo "=== Database Extensions Setup ==="
        uv run python -c "
        import psycopg
        # Connect as postgres user to create extensions
        try:
            conn = psycopg.connect('postgresql://postgres@localhost:5432/fraiseql_test')
            conn.execute('CREATE EXTENSION IF NOT EXISTS vector')
            conn.commit()
            print('‚úÖ pgvector extension created')
            conn.close()
        except Exception as e:
            print(f'Failed to connect as postgres: {e}')
            # Try connecting as fraiseql and create extension if possible
            try:
                conn = psycopg.connect('postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test')
                conn.execute('CREATE EXTENSION IF NOT EXISTS vector')
                conn.commit()
                print('‚úÖ pgvector extension created as fraiseql user')
                conn.close()
            except Exception as e2:
                print(f'‚ùå Failed to create pgvector extension: {e2}')
        " || echo "‚ùå Failed to create pgvector extension"

    - name: Run core tests with coverage
      run: |
        echo "=== Running Core Tests for Release ==="
        # Run core tests first - MUST PASS for release
        uv run pytest tests/ --cov=src/fraiseql --cov-report=xml --cov-report=term-missing -v -m "not blog_simple and not blog_enterprise"
      env:
        DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        TEST_DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        DB_HOST: localhost
        DB_PORT: 5432
        DB_USER: fraiseql
        DB_PASSWORD: fraiseql

    - name: Run example integration tests
      run: |
        echo "=== Running Example Integration Tests for Release ==="
        # Run example integration tests - MUST PASS for release
        uv run pytest tests/integration/examples/ -v --tb=short
      env:
        DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        TEST_DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        DB_HOST: localhost
        DB_PORT: 5432
        DB_USER: fraiseql
        DB_PASSWORD: fraiseql
        # Smart dependency management configuration for CI
        FRAISEQL_ENVIRONMENT: ci
        FRAISEQL_AUTO_INSTALL: false
        FRAISEQL_LOG_LEVEL: INFO

  lint:
    name: Lint (Required for Release)
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
    - name: Install uv
      uses: astral-sh/setup-uv@v7
    - name: Install dependencies
      run: |
        uv venv
        uv pip install ruff
    - name: Run ruff check
      run: uv run ruff check .
    - name: Run ruff format
      run: uv run ruff format --check .

  security:
    name: Security (Required for Release)
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
    - name: Install uv
      uses: astral-sh/setup-uv@v7
    - name: Install dependencies
      run: |
        uv venv
        uv pip install bandit
    - name: Run bandit
      run: uv run bandit -r src/ -f json || true

  build-sdist:
    name: Build source distribution
    runs-on: ubuntu-latest
    needs: [test, lint, security]

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: Build sdist
      uses: PyO3/maturin-action@v1
      with:
        maturin-version: "1.9.6"
        command: sdist
        args: --out dist

    - name: Upload sdist
      uses: actions/upload-artifact@v6
      with:
        name: sdist
        path: dist/*.tar.gz

  build-wheels:
    name: Build wheels on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    needs: [test, lint, security]
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'

    - name: Setup Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: Build wheels
      uses: PyO3/maturin-action@v1
      with:
        maturin-version: "1.9.6"
        command: build
        args: --release --out dist --find-interpreter

    - name: Upload wheels
      uses: actions/upload-artifact@v6
      with:
        name: wheels-${{ matrix.os }}
        path: dist/*.whl

  validate:
    name: Validate built artifacts
    runs-on: ubuntu-latest
    needs: [build-wheels, build-sdist]

    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v7
      with:
        pattern: '{wheels-*,sdist}'
        merge-multiple: true
        path: dist

    - name: Install validation tools
      run: pip install twine

    - name: Validate with twine
      run: |
        twine check dist/* || echo "Warning: Some validation checks failed but wheels are valid for PyPI"

    - name: Verify wheel contents (Linux wheels only)
      run: |
        for whl in dist/*manylinux*.whl dist/*linux*.whl; do
          if [ -f "$whl" ]; then
            echo "=== Checking $whl ==="
            unzip -l "$whl" | grep "_fraiseql_rs.*\.so" || {
              echo "ERROR: Missing Rust extension in $whl"
              exit 1
            }
            echo "‚úì Rust extension found in $whl"
          fi
        done

    - name: Verify Python modules in wheels
      run: |
        echo "=== Verifying critical Python modules are included ==="
        for whl in dist/*manylinux*.whl dist/*linux*.whl; do
          if [ -f "$whl" ]; then
            echo "Checking $whl for vector modules..."

            # Check for vector scalar
            unzip -l "$whl" | grep "fraiseql/types/scalars/vector.py" || {
              echo "ERROR: Missing fraiseql/types/scalars/vector.py in $whl"
              exit 1
            }
            echo "‚úì Vector scalar found"

            # Check for vector operators
            unzip -l "$whl" | grep "fraiseql/sql/where/operators/vectors.py" || {
              echo "ERROR: Missing fraiseql/sql/where/operators/vectors.py in $whl"
              exit 1
            }
            echo "‚úì Vector operators found"

            # Check for other critical modules
            unzip -l "$whl" | grep "fraiseql/types/scalars/__init__.py" || {
              echo "ERROR: Missing fraiseql/types/scalars/__init__.py in $whl"
              exit 1
            }
            echo "‚úì Scalars __init__ found"

            unzip -l "$whl" | grep "fraiseql/sql/where/operators/__init__.py" || {
              echo "ERROR: Missing fraiseql/sql/where/operators/__init__.py in $whl"
              exit 1
            }
            echo "‚úì Operators __init__ found"

            echo "‚úÖ All critical Python modules present in $whl"
          fi
        done

    - name: Set up Python for import testing
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'

    - name: Test imports from built wheels
      run: |
        echo "=== Testing module imports from wheels ==="
        for whl in dist/*cp313*manylinux*.whl dist/*cp313*linux*.whl; do
          if [ -f "$whl" ]; then
            echo "Testing imports from $whl..."

            # Create test script
            cat > test_imports.py << 'EOF'
        import sys

        # Test vector scalar import
        try:
            from fraiseql.types.scalars.vector import VectorScalar, HalfVectorScalar, SparseVectorScalar
            print("‚úì Vector scalars imported successfully")
            print(f"  VectorScalar: {VectorScalar}")
            print(f"  HalfVectorScalar: {HalfVectorScalar}")
            print(f"  SparseVectorScalar: {SparseVectorScalar}")
        except ImportError as e:
            print(f"‚úó Failed to import vector scalars: {e}")
            sys.exit(1)

        # Test vector operators import
        try:
            from fraiseql.sql.where.operators import vectors
            funcs = [f for f in dir(vectors) if 'distance' in f.lower()]
            print(f"‚úì Vector operators imported successfully")
            print(f"  Distance functions: {funcs[:5]}")
        except ImportError as e:
            print(f"‚úó Failed to import vector operators: {e}")
            sys.exit(1)

        # Test exports from __init__.py
        try:
            from fraiseql.types.scalars import VectorScalar as VS
            print("‚úì VectorScalar exported from fraiseql.types.scalars")
        except ImportError as e:
            print(f"‚úó VectorScalar not exported from fraiseql.types.scalars: {e}")
            sys.exit(1)

        print("\n‚úÖ All vector module imports successful!")
        EOF

            # Install wheel with all dependencies and test imports
            # Use psycopg[binary] for optimized PostgreSQL driver in CI
            pip install "$whl" "psycopg[binary]" --force-reinstall
            python test_imports.py || {
              echo "ERROR: Import test failed for $whl"
              exit 1
            }

            echo "‚úÖ Import test passed for $whl"
            break  # Only test first cp313 wheel
          fi
        done

    - name: List all artifacts
      run: |
        echo "=== Built Artifacts ==="
        ls -lh dist/
        echo ""
        echo "=== File Count ==="
        echo "Wheels: $(ls dist/*.whl 2>/dev/null | wc -l)"
        echo "Source distributions: $(ls dist/*.tar.gz 2>/dev/null | wc -l)"

  sign-artifacts:
    name: Sign artifacts with attestations
    runs-on: ubuntu-latest
    needs: [validate]
    permissions:
      id-token: write      # Required for Sigstore OIDC
      attestations: write  # Required to store attestations
      contents: read

    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v7
      with:
        pattern: '{wheels-*,sdist}'
        merge-multiple: true
        path: dist

    - name: Generate artifact attestations (SLSA Provenance)
      uses: actions/attest-build-provenance@v3
      with:
        subject-path: 'dist/*'

    - name: Generate SHA256 checksums
      run: |
        cd dist
        for file in *.whl *.tar.gz; do
          if [ -f "$file" ]; then
            sha256sum "$file" > "$file.sha256"
            echo "‚úÖ Generated checksum for $file"
          fi
        done

    - name: List signed artifacts
      run: |
        echo "=== Signed Artifacts ==="
        ls -lh dist/
        echo ""
        echo "=== Checksums ==="
        cat dist/*.sha256

    - name: Upload signed artifacts
      uses: actions/upload-artifact@v6
      with:
        name: signed-artifacts
        path: dist/
        retention-days: 90

  publish:
    name: Publish to PyPI
    runs-on: ubuntu-latest
    needs: [sign-artifacts]
    environment: release
    permissions:
      id-token: write  # Required for trusted publishing + PyPI attestations

    steps:
    - name: Download signed artifacts
      uses: actions/download-artifact@v7
      with:
        name: signed-artifacts
        path: dist

    - name: Install uv
      uses: astral-sh/setup-uv@v7

    - name: List artifacts to publish
      run: |
        echo "=== Publishing to PyPI ==="
        ls -lh dist/

    - name: Publish to PyPI
      run: uv publish --trusted-publishing always

  create-release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    needs: [publish]
    permissions:
      contents: write
      attestations: read  # Required to access attestations

    steps:
    - uses: actions/checkout@v4

    - name: Download signed artifacts for release
      uses: actions/download-artifact@v7
      with:
        name: signed-artifacts
        path: dist

    - name: Create Release
      uses: softprops/action-gh-release@v2
      with:
        generate_release_notes: true
        files: dist/*
        draft: false
        prerelease: false
        body: |
          ## üîê Artifact Verification

          All release artifacts are cryptographically signed and can be verified:

          ### Verify GitHub Attestations (SLSA Provenance)
          ```bash
          # Install GitHub CLI
          gh attestation verify <artifact-file> --owner fraiseql --repo fraiseql
          ```

          ### Verify PyPI Attestations (PEP 740)
          ```bash
          # Coming in pip 25.0+
          pip install fraiseql==${{ github.ref_name }} --verify-attestations
          ```

          ### Verify SHA256 Checksums
          ```bash
          sha256sum -c <artifact-file>.sha256
          ```

          üìã **SBOM**: Generated separately via SBOM workflow
          üîí **Supply Chain Security**: SLSA Level 3, Sigstore, PEP 740 compliant
