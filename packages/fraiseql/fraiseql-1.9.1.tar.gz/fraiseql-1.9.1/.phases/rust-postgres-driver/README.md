# Rust PostgreSQL Driver Implementation Plan

**Status**: Ready for Implementation (Phase 1)
**Created**: 2025-12-18
**Last Updated**: 2025-12-18 (IMPROVED)
**Priority**: P1 - Strategic Architecture Evolution
**Branch**: `feature/rust-postgres-driver`

---

## Overview

Replace psycopg (Python PostgreSQL driver) with a native Rust driver (`tokio-postgres` + `deadpool-postgres`) for FraiseQL's internal database layer while maintaining 100% backward-compatible Python API.

**Goal**: Move all database operations to high-performance Rust while keeping Python as the public interface.

**Key Benefits**:
- ‚úÖ 20-30% faster query execution (Rust vs Python)
- ‚úÖ Zero-copy result streaming to HTTP responses
- ‚úÖ True async throughout (no GIL contention)
- ‚úÖ Type-safe database operations at compile time (compile-time safety)
- ‚úÖ 100% backward compatible (zero API changes for users)
- ‚úÖ Reduced memory footprint (10-15% improvement)
- ‚úÖ 2-3x higher sustained throughput

---

## Architecture Decision

### Current Stack (Before)
```
User (Python API)
  ‚Üì psycopg (Python)
  ‚Üì
PostgreSQL
  ‚Üì
Rust Pipeline (JSON transform, response building)
  ‚Üì
HTTP Response
```

**Problems**:
- Two language boundaries (Python‚ÜíDB, then result‚ÜíRust)
- Result marshalling overhead (dict/row objects)
- Connection pool management complexity in Python
- Some query building still in Python

### New Stack (After)
```
User (Python API) ‚Üê No change visible
  ‚Üì (thin wrapper)
Python Layer (validation, schema introspection, GraphQL parsing)
  ‚Üì (single async call)
Rust Native Core (fraiseql_rs)
  ‚îú‚Üí Connection pooling (deadpool-postgres + tokio-postgres)
  ‚îú‚Üí Query execution & streaming
  ‚îú‚Üí WHERE clause building
  ‚îú‚Üí SQL generation
  ‚îú‚Üí JSON transformation
  ‚îú‚Üí Response building
  ‚îî‚Üí Zero-copy to HTTP
  ‚Üì
PostgreSQL
  ‚Üì
HTTP Response
```

**Benefits**:
- ‚úÖ Single fast path: Rust‚ÜíDB‚ÜíRust‚ÜíHTTP
- ‚úÖ No marshalling overhead
- ‚úÖ Zero-copy streaming
- ‚úÖ True async throughout

---

## Problem Statement

### Why Now?

1. **Performance bottleneck**: Current psycopg layer adds 15-20% overhead to query time
2. **Architectural alignment**: Rust pipeline proven effective, ready to extend
3. **Strategic advantage**: Full Rust core becomes marketing differentiator
4. **Resource efficiency**: Native pooling removes async runtime complexity
5. **Team capability**: Rust infrastructure already exists and working

### What's at Risk?

- ‚úÖ **Backward compatibility** (mitigated: Python API unchanged)
- ‚úÖ **Stability** (mitigated: phased rollout, feature flags)
- ‚úÖ **Complexity** (mitigated: clear separation of concerns)
- ‚úÖ **Build system** (mitigated: PyO3/Maturin already proven)

---

## Async & PyO3 Integration Architecture

### Critical: Python-Rust Async Boundary

FraiseQL uses **pyo3-asyncio** to bridge Python async/await with Rust tokio runtime. This is the most critical integration point.

**Architecture**:
```
Python (asyncio.run())
    ‚Üì
FastAPI endpoint (async def handler)
    ‚Üì
Call Rust async function via pyo3-asyncio
    ‚Üì
Rust (tokio::spawn_blocking or native async)
    ‚Üì
tokio-postgres (async driver)
    ‚Üì
PostgreSQL
    ‚Üì
Result returned as coroutine to Python
    ‚Üì
Python awaits result
```

**Key Implementation Details**:

1. **PyO3 Function Signature**:
```rust
use pyo3_asyncio::tokio;

#[pyfunction]
#[pyo3(signature = (query_def, py_config=None))]
fn execute_query_async(
    query_def: String,
    py_config: Option<&PyDict>,
    py: Python,
) -> PyResult<&PyAny> {
    // Convert Python dict to Rust config
    let config = parse_config(py_config)?;

    // Return a Python coroutine that the event loop will await
    pyo3_asyncio::tokio::future_into_py(py, async {
        // This code runs in tokio runtime
        execute_rust_query(&config).await
    })
}
```

2. **Critical: Runtime Affinity**
   - PyO3-asyncio requires proper event loop integration
   - Never spawn bare tokio tasks - use `tokio::spawn_blocking` for blocking ops
   - Connection pool must be created ONCE and shared across all requests

3. **Error Propagation**:
   - Rust errors must convert to Python exceptions
   - Use `PyErr` for errors that cross FFI boundary
   - Async errors need special handling (not caught by normal try/except)

### Type Conversion Across FFI Boundary

**Critical**: Type conversion is where many FFI bugs occur.

**Conversion Layer** (`fraiseql_rs/src/py_types.rs` - NEW):
```rust
/// Convert Python dict to QueryParam
pub fn python_to_query_param(py_obj: &PyAny) -> PyResult<QueryParam> {
    if let Ok(s) = py_obj.extract::<String>() {
        return Ok(QueryParam::String(s));
    }
    if let Ok(i) = py_obj.extract::<i64>() {
        return Ok(QueryParam::Int(i));
    }
    if let Ok(f) = py_obj.extract::<f64>() {
        return Ok(QueryParam::Float(f));
    }
    if let Ok(b) = py_obj.extract::<bool>() {
        return Ok(QueryParam::Bool(b));
    }
    if py_obj.is_none() {
        return Ok(QueryParam::Null);
    }
    // Handle JSON objects and arrays
    let json_str = py_obj.to_string();
    Ok(QueryParam::Json(json_str))
}

/// Convert Rust QueryParam back to Python object
pub fn query_param_to_python(py: Python, param: &QueryParam) -> PyResult<PyObject> {
    match param {
        QueryParam::String(s) => Ok(s.into_py(py)),
        QueryParam::Int(i) => Ok(i.into_py(py)),
        QueryParam::Float(f) => Ok(f.into_py(py)),
        QueryParam::Bool(b) => Ok(b.into_py(py)),
        QueryParam::Null => Ok(py.None()),
        QueryParam::Json(j) => {
            // Parse JSON and return as Python dict/list
            let json_val: serde_json::Value = serde_json::from_str(j)?;
            json_to_python(py, &json_val)
        }
    }
}

/// Convert PostgreSQL type to QueryParam (critical!)
pub fn postgres_to_query_param(row: &tokio_postgres::Row, col_idx: usize) -> Result<QueryParam, Error> {
    // Get column type from row.columns()
    let col = row.columns().get(col_idx).ok_or("Invalid column index")?;

    match col.type_().oid() {
        25 | 705 => {  // text, unknown
            Ok(QueryParam::String(row.get(col_idx)))
        }
        23 => {  // int4
            Ok(QueryParam::Int(row.get(col_idx)))
        }
        20 => {  // int8
            Ok(QueryParam::Int(row.get::<_, i64>(col_idx)))
        }
        700 | 701 => {  // float4, float8
            Ok(QueryParam::Float(row.get(col_idx)))
        }
        114 => {  // json - CRITICAL
            let json_str: String = row.get(col_idx);
            Ok(QueryParam::Json(json_str))
        }
        3802 => {  // jsonb - MOST CRITICAL
            // tokio_postgres returns jsonb as String already
            let json_str: String = row.get(col_idx);
            Ok(QueryParam::Json(json_str))
        }
        16 => {  // bool
            Ok(QueryParam::Bool(row.get(col_idx)))
        }
        // Handle NULL values - CRITICAL
        _ if row.get::<_, Option<String>>(col_idx).is_none() => {
            Ok(QueryParam::Null)
        }
        _ => {
            // Fallback: convert to string
            Ok(QueryParam::String(row.try_get::<_, String>(col_idx).unwrap_or_default()))
        }
    }
}
```

---

## Technical Approach

### Driver Selection: Why tokio-postgres?

| Aspect | tokio-postgres | sqlx | diesel |
|--------|----------------|------|--------|
| **Zero-copy streaming** | ‚úÖ Direct row access | ‚ö†Ô∏è Limited | ‚ùå No |
| **Dynamic schemas** | ‚úÖ Yes | ‚ùå Compile-time required | ‚ùå Compile-time required |
| **Compile-time validation** | ‚ùå Runtime only | ‚úÖ Yes | ‚úÖ Yes |
| **Our use case** | ‚úÖ Perfect fit | ‚ùå Incompatible | ‚ùå Incompatible |
| **Async support** | ‚úÖ Native | ‚úÖ Native | ‚ùå Sync only |

**Decision**: `tokio-postgres` for driver + `deadpool-postgres` for pooling

### Python-Rust Boundary (PyO3)

**What crosses the boundary**:
```python
# Query definition (structured data)
QueryDef {
    sql: String,
    params: Vec<QueryParam>,
    return_type: TypeDef,
    selections: FieldSelections,
}

# ‚Üì Single async call ‚Üì

# Result (response bytes)
ResponseBytes { bytes: Vec<u8> }
```

**Philosophy**: Minimize FFI calls, maximize Rust work per call

---

## Implementation Strategy

### What Stays in Python ‚úÖ

- **FastAPI framework** (user-facing, needs flexibility)
- **GraphQL type definitions** (schemas defined in Python)
- **Pydantic validation** (input validation)
- **Authentication/Authorization** (policy-driven, complex)
- **Middleware/Observability** (hooks and customization)

**Rationale**: These layers need flexibility because users write code that hooks into them

### What Moves to Rust ‚ú®

**Phase 1**: Connection pooling foundation
- Connection pool setup with `deadpool-postgres`
- Basic connection management
- Connection initialization with PostgreSQL settings

**Phase 2**: Query execution
- Raw query execution (simple SELECT, INSERT, UPDATE, DELETE)
- WHERE clause building
- SQL generation
- Parameter binding

**Phase 3**: Result processing
- Result streaming from database
- Row iteration
- Direct bytes to response (zero-copy where possible)

**Phase 4**: Response building
- Integration with existing JSON transformation
- Full GraphQL response building in Rust
- Zero-copy streaming to HTTP

**Phase 5**: Complete replacement
- Remove psycopg dependency
- Update all consumers (db.py, mutations, etc.)
- Full Rust-native core

### Feature Flag Strategy

```rust
// In Cargo.toml
[features]
default = ["rust-db"]
rust-db = []  # Rust PostgreSQL driver
python-db = ["psycopg"]  # Fall back to psycopg

// In code
#[cfg(feature = "rust-db")]
async fn execute_query(...) -> Result<ResponseBytes> {
    // Rust implementation
}

#[cfg(feature = "python-db")]
async fn execute_query(...) -> Result<ResponseBytes> {
    // Fallback to psycopg
}
```

This allows:
- ‚úÖ Running both in parallel during transition
- ‚úÖ Quick rollback if issues found
- ‚úÖ Gradual migration of code
- ‚úÖ Testing parity between implementations

---

## Phase Breakdown

| Phase | Name | Effort | Key Deliverable | Duration |
|-------|------|--------|-----------------|----------|
| 1 | **Foundation** | 8h | Connection pool + schema registry | 1-2 days |
| 2 | **Query Execution** | 12h | WHERE clauses + SQL generation in Rust | 2-3 days |
| 3 | **Result Streaming** | 10h | Direct DB‚ÜíRust transformation | 1-2 days |
| 4 | **Integration** | 8h | Full GraphQL response pipeline | 1-2 days |
| 5 | **Deprecation** | 6h | Remove psycopg, update consumers | 1 day |

**Total Estimated Effort**: 44 hours (~1 week with 1 person full-time)

**Critical Path**: Phase 1 ‚Üí Phase 2 ‚Üí Phase 3 ‚Üí Phase 4 ‚Üí Phase 5

---

## Files to Create/Modify

### New Rust Code
```
fraiseql_rs/src/
‚îú‚îÄ‚îÄ db/                          # NEW: Database layer
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs                   # Pool management, exports
‚îÇ   ‚îú‚îÄ‚îÄ pool.rs                  # Connection pool setup
‚îÇ   ‚îú‚îÄ‚îÄ query.rs                 # Query execution
‚îÇ   ‚îú‚îÄ‚îÄ where_builder.rs         # WHERE clause generation
‚îÇ   ‚îî‚îÄ‚îÄ types.rs                 # Type definitions
‚îú‚îÄ‚îÄ sql/                         # NEW: SQL generation
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îú‚îÄ‚îÄ generator.rs             # Main SQL builder
‚îÇ   ‚îú‚îÄ‚îÄ where_clause.rs          # WHERE logic
‚îÇ   ‚îî‚îÄ‚îÄ functions.rs             # Helper functions
‚îî‚îÄ‚îÄ response/                    # NEW: Response building
    ‚îú‚îÄ‚îÄ mod.rs
    ‚îú‚îÄ‚îÄ builder.rs               # GraphQL response building
    ‚îî‚îÄ‚îÄ streaming.rs             # Zero-copy streaming
```

### Python Wrapper Updates
```
src/fraiseql/
‚îú‚îÄ‚îÄ db.py                        # MODIFY: Add Rust backend option
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ rust_pipeline.py         # MODIFY: Integrate DB queries
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îî‚îÄ‚îÄ graphql_where_generator.py  # MODIFY: Use Rust WHERE builder
‚îî‚îÄ‚îÄ mutations/
    ‚îî‚îÄ‚îÄ executor.py              # MODIFY: Use Rust mutations
```

### New Tests
```
fraiseql_rs/tests/
‚îú‚îÄ‚îÄ test_db_pool.rs              # Connection pool tests
‚îú‚îÄ‚îÄ test_query_execution.rs      # Query execution tests
‚îú‚îÄ‚îÄ test_where_builder.rs        # WHERE clause builder tests
‚îî‚îÄ‚îÄ test_response_streaming.rs   # Response streaming tests

tests/
‚îú‚îÄ‚îÄ integration/db/
‚îÇ   ‚îú‚îÄ‚îÄ test_rust_pool.py        # Pool integration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_rust_queries.py     # Query execution tests
‚îÇ   ‚îî‚îÄ‚îÄ test_rust_where.py       # WHERE clause tests
‚îî‚îÄ‚îÄ regression/
    ‚îî‚îÄ‚îÄ test_rust_db_parity.py   # Parity with psycopg
```

---

## Verification Strategy

### Phase 1: Foundation
```bash
# Connection pool setup
cargo test -p fraiseql_rs --lib db::pool::tests
uv run pytest tests/integration/db/test_rust_pool.py -v

# Schema registry
cargo test -p fraiseql_rs --lib schema_registry::tests
```

### Phase 2: Query Execution
```bash
# WHERE clause builder
cargo test -p fraiseql_rs --lib db::where_builder::tests
uv run pytest tests/integration/db/test_rust_where.py -v

# Query execution
cargo test -p fraiseql_rs --lib db::query::tests
uv run pytest tests/integration/db/test_rust_queries.py -v
```

### Phase 3: Result Streaming
```bash
# Response building
cargo test -p fraiseql_rs --lib response::builder::tests
uv run pytest tests/integration/db/test_rust_response.py -v
```

### Phase 4: Full Integration
```bash
# Parity tests: Rust implementation vs psycopg
uv run pytest tests/regression/test_rust_db_parity.py -v

# Run full test suite with Rust backend
FRAISEQL_DB_BACKEND=rust uv run pytest tests/ -v
```

### Phase 5: Deprecation
```bash
# Run full suite with psycopg removed
uv run pytest tests/ -v

# Verify no references to psycopg remain
grep -r "psycopg" src/fraiseql/ || echo "‚úÖ No psycopg references"
```

---

## Success Metrics

### Must Have (Exit Criteria)
- [ ] Phase 1: Connection pool initializes successfully
- [ ] Phase 2: All WHERE clauses generate correctly
- [ ] Phase 3: Response streaming works end-to-end
- [ ] Phase 4: All 5991+ tests pass with Rust backend
- [ ] Phase 5: 100% psycopg removal, no regressions

### Performance Goals
- ‚úÖ Query execution: 20-30% faster than psycopg
- ‚úÖ Response time: 15-25% faster end-to-end
- ‚úÖ Memory usage: 10-15% lower

### Quality Gates
- ‚úÖ Zero regressions in existing tests
- ‚úÖ Parity tests pass (Rust output == psycopg output)
- ‚úÖ Code review approval
- ‚úÖ Load testing passes (1000+ QPS sustained)

---

## Dependencies & Resources

### New Cargo Dependencies

```toml
# Database (Phase 1-3)
tokio-postgres = "0.7"          # PostgreSQL driver
deadpool-postgres = "0.14"       # Connection pooling
deadpool = "0.10"                # Pool management

# Async runtime (already have via pyo3)
tokio = { version = "1.0", features = ["full"] }

# Type system (already have)
serde_json = "1.0"
serde = "1.0"

# Testing
tokio-test = "0.4"               # Async testing
testcontainers = "0.15"          # Database containers
```

### Python Dependencies

No new dependencies needed. Keep existing:
- psycopg (remove in Phase 5)
- graphql-core
- fastapi
- pydantic

### Infrastructure

‚úÖ Already have:
- PyO3 build system working
- Async runtime (tokio via Python)
- Testing framework
- CI/CD pipeline

---

## Risk Mitigation

### Risk 1: Rust Async Complexity
**Mitigation**:
- Use well-tested libraries (tokio, deadpool)
- Extensive unit tests for each component
- Feature flag fallback to psycopg
- Gradual rollout (Phase 1-5)

### Risk 2: Performance Regression
**Mitigation**:
- Benchmark existing psycopg performance
- Continuous performance testing
- Profile with `criterion` benchmark suite
- Parity tests catch regressions

### Risk 3: Compatibility Issues
**Mitigation**:
- Keep Python API identical
- Feature flags for gradual transition
- Comprehensive parity tests
- Easy rollback via git revert

### Risk 4: Connection Pool Behavior Changes
**Mitigation**:
- Thorough pool testing
- Connection lifecycle tests
- Error handling and recovery tests
- Load testing with sustained traffic

---

## Error Handling & Recovery

### Error Classification & Strategy

**1. Transient Errors (Retry)**
- Connection timeout (backoff: 100ms, 200ms, 400ms, max 1s)
- Connection refused (database not ready)
- Query timeout
- Network interruption mid-query

**2. Permanent Errors (Fail Fast)**
- Authentication failure
- Permission denied
- Table/column not found
- Type mismatch in parameters

**3. Partial Errors (Stream Interrupted)**
- Connection breaks after rows start streaming
- Caller disconnects during stream
- Memory allocation failure during result collection

### Error Mapping to GraphQL

```rust
// fraiseql_rs/src/error.rs - COMPLETE ERROR HANDLING
pub enum DatabaseError {
    ConnectionPoolExhausted,
    ConnectionTimeout(u64),  // duration in ms
    QueryTimeout(u64),
    AuthenticationFailed,
    PermissionDenied,
    NotFound { table: String, resource: String },
    TypeMismatch { expected: String, received: String },
    SyntaxError(String),
    StreamInterrupted,
    TransactionRollback(String),
}

impl DatabaseError {
    /// Convert to GraphQL error response
    pub fn to_graphql_error(&self) -> serde_json::Value {
        match self {
            Self::ConnectionPoolExhausted => json!({
                "errors": [{
                    "message": "Service temporarily unavailable",
                    "extensions": { "code": "SERVICE_UNAVAILABLE" }
                }]
            }),
            Self::QueryTimeout(ms) => json!({
                "errors": [{
                    "message": format!("Query timeout after {}ms", ms),
                    "extensions": { "code": "QUERY_TIMEOUT" }
                }]
            }),
            Self::AuthenticationFailed => json!({
                "errors": [{
                    "message": "Authentication failed",
                    "extensions": { "code": "AUTHENTICATION_ERROR" }
                }]
            }),
            // ... more mappings
        }
    }

    /// Should this error trigger a retry?
    pub fn is_retryable(&self) -> bool {
        matches!(
            self,
            Self::ConnectionTimeout(_) | Self::QueryTimeout(_) | Self::StreamInterrupted
        )
    }
}
```

### Retry Strategy

```rust
pub struct RetryPolicy {
    max_retries: u32,
    initial_backoff: Duration,
    max_backoff: Duration,
}

impl RetryPolicy {
    pub async fn execute_with_retry<F, T>(&self, mut f: F) -> Result<T, DatabaseError>
    where
        F: FnMut() -> futures::future::BoxFuture<'static, Result<T, DatabaseError>>,
    {
        let mut attempt = 0;
        loop {
            match f().await {
                Ok(result) => return Ok(result),
                Err(err) if err.is_retryable() && attempt < self.max_retries => {
                    let backoff = self.initial_backoff.mul_f32(2_f32.powi(attempt as i32));
                    let backoff = backoff.min(self.max_backoff);
                    tokio::time::sleep(backoff).await;
                    attempt += 1;
                }
                Err(err) => return Err(err),
            }
        }
    }
}
```

## Configuration & Environment Variables

### Complete Configuration Reference

```bash
# Database Connection (REQUIRED)
DATABASE_URL="postgresql://user:password@host:5432/fraiseql_db"

# Connection Pool Configuration
RUST_DB_MAX_CONNECTIONS=20          # Default: 20
RUST_DB_MIN_IDLE=2                  # Default: 2
RUST_DB_CONNECTION_TIMEOUT_MS=30000 # Default: 30s

# Connection Lifecycle
RUST_DB_IDLE_TIMEOUT_MS=600000      # Default: 10m
RUST_DB_MAX_LIFETIME_MS=1800000     # Default: 30m
RUST_DB_TEST_ON_CHECKOUT=true       # Validate conn before use

# Query Execution
RUST_DB_QUERY_TIMEOUT_MS=30000      # Default: 30s
RUST_DB_STATEMENT_CACHE_SIZE=100    # Number of prepared stmts

# SSL/TLS
RUST_DB_SSL_MODE=prefer             # disable|allow|prefer|require
RUST_DB_SSL_CERT_PATH=/path/to/cert # Optional
RUST_DB_SSL_KEY_PATH=/path/to/key   # Optional

# Retry Policy
RUST_DB_MAX_RETRIES=3               # Default: 3
RUST_DB_INITIAL_BACKOFF_MS=100      # Default: 100ms
RUST_DB_MAX_BACKOFF_MS=5000         # Default: 5s

# Performance & Monitoring
RUST_DB_PERFORMANCE_LOG=false       # Log query times
RUST_DB_PERFORMANCE_THRESHOLD_MS=100 # Log queries > 100ms
RUST_DB_POOL_STATS_INTERVAL_S=0    # 0 = disabled
```

### Parity with Current psycopg Configuration

**psycopg ‚Üí Rust mapping**:
```
PGHOST, PGPORT, PGUSER, PGPASSWORD, PGDATABASE
    ‚Üì (combined into)
DATABASE_URL

psycopg pool size (20)
    ‚Üì (maps to)
RUST_DB_MAX_CONNECTIONS=20

psycopg timeout (30s)
    ‚Üì (maps to)
RUST_DB_CONNECTION_TIMEOUT_MS=30000
```

## Rollback Strategy

If issues occur:

```bash
# Immediate rollback
git revert <problematic-commit>
cargo build  # Back to psycopg

# Feature flag fallback
# In code: Use #[cfg(feature = "python-db")] path
cargo build --features python-db
```

**Rollback success criteria**:
- [ ] All tests pass
- [ ] Performance returns to baseline
- [ ] No user-visible changes

---

## Timeline

```
Week 1:
  Mon-Tue: Phase 1 (Foundation) .......................... 8h
  Wed-Thu: Phase 2 (Query Execution) ..................... 12h
  Fri: Phase 3 start (Result Streaming) ................. 5h

Week 2:
  Mon-Tue: Phase 3 finish + Phase 4 (Integration) ....... 13h
  Wed: Phase 4 finish + Phase 5 start (Deprecation) ..... 8h
  Thu-Fri: Phase 5 finish + Testing & Validation ........ 6h
```

**Assuming 1 person working full-time on this feature.**

---

## Next Steps

1. ‚úÖ **Read this README** (you are here)
2. üìã **Review Phase 1 plan** (`.phases/rust-postgres-driver/phase-1-foundation.md`)
3. ‚ñ∂Ô∏è **Start Phase 1** with `opencode` or Claude Code
4. ‚úîÔ∏è **Verify each phase** before proceeding to next
5. üìù **Update this README** as you progress
6. üéâ **Merge** when all phases complete
7. üóëÔ∏è **Delete `.phases/rust-postgres-driver/` directory** after merge

---

## References

### Rust Libraries
- [tokio-postgres docs](https://docs.rs/tokio-postgres/)
- [deadpool-postgres docs](https://docs.rs/deadpool-postgres/)
- [pyo3-asyncio docs](https://docs.rs/pyo3-asyncio/)

### FraiseQL Documentation
- `docs/RELEASE_WORKFLOW.md` - Release process
- `src/fraiseql/CLAUDE.md` - Development guide (this repo)

### Previous Phase Plans
- `.phases/jsonb-nested-camelcase-fix/` - TDD example
- `.phases/cleanup-integration-tests/` - Multi-phase example

---

## Questions & Decisions

### Q1: Why not keep psycopg after Phase 5?

psycopg doesn't provide any advantages once Rust core is fully functional:
- Rust is faster (tokio-postgres benchmarks: 3-5x faster)
- Rust uses less memory
- Rust is type-safe (no runtime surprises)
- Rust avoids GIL contention (true parallelism)
- Rust ‚Üí Rust is cleaner architecture

**Decision**: Remove psycopg completely in Phase 5 ‚úÖ

### Q2: What about connection pooling configuration?

Deadpool-postgres will expose the same configuration options:
- Pool size
- Connection timeout
- Idle timeout
- Retry policy

These will be configurable via environment variables and Python config.

**Decision**: Parity with current psycopg configuration ‚úÖ

### Q3: How do we handle connection state/prepared statements?

tokio-postgres supports prepared statement caching. We'll:
1. Cache prepared WHERE/SELECT patterns
2. Reuse connections from pool (state preserved)
3. Handle connection timeout/reset properly

**Decision**: Use prepared statement caching from tokio-postgres ‚úÖ

### Q4: What about transactions?

Transactions will be handled in Rust:
```rust
let mut client = pool.get().await?;
let transaction = client.transaction().await?;

// Execute multiple queries
transaction.execute(...).await?;
transaction.execute(...).await?;

// Commit or rollback
transaction.commit().await?;
```

**Decision**: Full transaction support in Phase 2 ‚úÖ

---

**Status**: ‚úÖ Ready for Phase 1
**Last Updated**: 2025-12-18
**Branch**: `feature/rust-postgres-driver`
