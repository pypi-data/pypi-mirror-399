{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8af1b18d",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/06_streaming/04_interpreting_diagnostics.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42cb37a3",
      "metadata": {
        "id": "colab-install"
      },
      "outputs": [],
      "source": [
        "# @title Install NLSQ (run once in Colab)\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Running in Google Colab - installing NLSQ...\")\n",
        "    !pip install -q nlsq\n",
        "    print(\"\u2705 NLSQ installed successfully!\")\n",
        "else:\n",
        "    print(\"Not running in Colab - assuming NLSQ is already installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b41140a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-18T21:00:40.159327Z",
          "iopub.status.busy": "2025-12-18T21:00:40.159131Z",
          "iopub.status.idle": "2025-12-18T21:00:40.448790Z",
          "shell.execute_reply": "2025-12-18T21:00:40.448242Z"
        }
      },
      "outputs": [],
      "source": [
        "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
        "# MUST come before importing matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "579ea5ff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-18T21:00:40.450538Z",
          "iopub.status.busy": "2025-12-18T21:00:40.450271Z",
          "iopub.status.idle": "2025-12-18T21:00:41.493982Z",
          "shell.execute_reply": "2025-12-18T21:00:41.493377Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Streaming Optimizer: Interpreting Diagnostics Example\n",
            "======================================================================\n",
            "\n",
            "Dataset: 5000 samples\n",
            "True parameters: a=1.0, b=2.0, c=-0.5\n",
            "\n",
            "Running optimization...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optimization complete!\n",
            "\n",
            "DIAGNOSTICS STRUCTURE\n",
            "======================================================================\n",
            "\n",
            "Available diagnostic fields:\n",
            "  - aggregate_stats                : dict\n",
            "  - batch_padding                  : dict\n",
            "  - batch_success_rate             : float\n",
            "  - checkpoint_info                : dict\n",
            "  - convergence_achieved           : bool\n",
            "  - elapsed_time                   : float\n",
            "  - error_types                    : dict\n",
            "  - failed_batches                 : list\n",
            "  - final_epoch                    : int\n",
            "  - recent_batch_stats             : list\n",
            "  - retry_counts                   : dict\n",
            "  - total_batches_attempted        : int\n",
            "  - total_retries                  : int\n",
            "\n",
            "SUCCESS METRICS\n",
            "======================================================================\n",
            "Batch success rate: 100.0%\n",
            "Total batches attempted: 250\n",
            "Failed batches: 0\n",
            "Total retries: 0\n",
            "Convergence achieved: False\n",
            "Final epoch: 4\n",
            "Elapsed time: 0.27s\n",
            "\n",
            "FAILURE ANALYSIS\n",
            "======================================================================\n",
            "No failed batches!\n",
            "\n",
            "AGGREGATE STATISTICS\n",
            "======================================================================\n",
            "Mean loss:          1.402242e+01\n",
            "Std loss:           2.656516e+01\n",
            "Mean gradient norm: 67.390432\n",
            "Std gradient norm:  119.519512\n",
            "Mean batch time:    0.57ms\n",
            "Std batch time:     0.27ms\n",
            "\n",
            "Interpretation:\n",
            "  - Coefficient of variation (loss): 189.45%\n",
            "    => High variability in loss\n",
            "\n",
            "RECENT BATCH STATISTICS (last 10 batches)\n",
            "======================================================================\n",
            "Showing 10 most recent batches:\n",
            "\n",
            "   Batch     Status         Loss   GradNorm     Time  Retries\n",
            "----------------------------------------------------------------------\n",
            "      40    SUCCESS   5.3999e-01    14.3886     0.8ms        0\n",
            "      41    SUCCESS   3.5484e-01    12.6708     0.7ms        0\n",
            "      42    SUCCESS   1.7551e-01     9.1965     0.4ms        0\n",
            "      43    SUCCESS   6.3852e-02     4.5913     0.6ms        0\n",
            "      44    SUCCESS   4.4350e-02     1.7245     0.5ms        0\n",
            "      45    SUCCESS   1.1181e-01     9.7515     0.5ms        0\n",
            "      46    SUCCESS   3.6009e-01    21.3581     0.5ms        0\n",
            "      47    SUCCESS   7.7338e-01    35.3558     0.5ms        0\n",
            "      48    SUCCESS   1.3590e+00    51.8964     0.4ms        0\n",
            "      49    SUCCESS   2.0940e+00    70.2738     0.5ms        0\n",
            "\n",
            "Recent batch statistics:\n",
            "  Success rate: 100.0%\n",
            "  Mean loss: 5.876851e-01\n",
            "  Min loss: 4.434964e-02\n",
            "  Max loss: 2.094022e+00\n",
            "\n",
            "CHECKPOINT INFORMATION\n",
            "======================================================================\n",
            "Latest checkpoint:\n",
            "  Path: checkpoints_diagnostics/checkpoint_iter_250.h5\n",
            "  Saved at: 2025-12-18T15:00:41.487220\n",
            "  Batch index: 49\n",
            "\n",
            "Resume using:\n",
            "  config = StreamingConfig(resume_from_checkpoint='checkpoints_diagnostics/checkpoint_iter_250.h5')\n",
            "\n",
            "EXPORT DIAGNOSTICS\n",
            "======================================================================\n",
            "Diagnostics exported to: streaming_diagnostics_example.json\n",
            "File size: 15953 bytes\n",
            "\n",
            "FINAL RESULTS\n",
            "======================================================================\n",
            "Best parameters:\n",
            "  a = 0.506970 (true: 1.0)\n",
            "  b = 1.037821 (true: 2.0)\n",
            "  c = -0.208632 (true: -0.5)\n",
            "  Best loss = 4.139387e-02\n",
            "\n",
            "======================================================================\n",
            "Example complete!\n",
            "\n",
            "Key takeaways:\n",
            "  - streaming_diagnostics contains comprehensive information\n",
            "  - Aggregate statistics summarize overall performance\n",
            "  - Recent batch statistics show optimization trajectory\n",
            "  - Checkpoint information enables recovery\n",
            "  - Error analysis helps diagnose issues\n",
            "  - Diagnostics can be exported to JSON for further analysis\n"
          ]
        }
      ],
      "source": [
        "def _make_serializable(obj):\n",
        "    \"\"\"Recursively convert objects to JSON-serializable types.\"\"\"\n",
        "    from collections import deque\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: _make_serializable(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (list, tuple, deque)):\n",
        "        return [_make_serializable(item) for item in obj]\n",
        "    elif isinstance(obj, (int, float, str, bool, type(None))):\n",
        "        return obj\n",
        "    elif hasattr(obj, \"tolist\"):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return str(obj)\n",
        "\n",
        "\n",
        "def export_diagnostics_json(diagnostics, filename=\"diagnostics.json\"):\n",
        "    \"\"\"Export diagnostics to JSON for further analysis\"\"\"\n",
        "    print(\"EXPORT DIAGNOSTICS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Create serializable copy (handle non-serializable types like deques)\n",
        "    diagnostics_copy = _make_serializable(diagnostics)\n",
        "\n",
        "    # Write to JSON file\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(diagnostics_copy, f, indent=2)\n",
        "\n",
        "    print(f\"Diagnostics exported to: {filename}\")\n",
        "    print(f\"File size: {len(json.dumps(diagnostics_copy))} bytes\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
