{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bae53932",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/06_streaming/01_basic_fault_tolerance.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81b43f1",
      "metadata": {
        "id": "colab-install"
      },
      "outputs": [],
      "source": [
        "# @title Install NLSQ (run once in Colab)\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Running in Google Colab - installing NLSQ...\")\n",
        "    !pip install -q nlsq\n",
        "    print(\"\u2705 NLSQ installed successfully!\")\n",
        "else:\n",
        "    print(\"Not running in Colab - assuming NLSQ is already installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0cbb0a09",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-18T21:00:22.751907Z",
          "iopub.status.busy": "2025-12-18T21:00:22.751710Z",
          "iopub.status.idle": "2025-12-18T21:00:23.054528Z",
          "shell.execute_reply": "2025-12-18T21:00:23.053856Z"
        }
      },
      "outputs": [],
      "source": [
        "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
        "# MUST come before importing matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "42fa4f64",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-18T21:00:23.056654Z",
          "iopub.status.busy": "2025-12-18T21:00:23.056442Z",
          "iopub.status.idle": "2025-12-18T21:00:26.344870Z",
          "shell.execute_reply": "2025-12-18T21:00:26.344426Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Streaming Optimizer: Basic Fault Tolerance Example\n",
            "======================================================================\n",
            "\n",
            "Dataset: 10000 samples\n",
            "True parameters: a=2.5, b=0.3\n",
            "\n",
            "Configuration:\n",
            "  Batch size: 100\n",
            "  Max epochs: 10\n",
            "  Learning rate: 0.001\n",
            "  Fault tolerance: True\n",
            "  Validate numerics: True\n",
            "  Min success rate: 50%\n",
            "  Max retries per batch: 2\n",
            "\n",
            "Initial guess: a=1.0, b=0.1\n",
            "\n",
            "Starting optimization...\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------\n",
            "\n",
            "RESULTS\n",
            "======================================================================\n",
            "Success: True\n",
            "Message: Optimization complete: 1000/1000 batches succeeded (100.0%)\n",
            "\n",
            "Best parameters found:\n",
            "  a = 1.189291 (true: 2.5)\n",
            "  b = 0.134749 (true: 0.3)\n",
            "  Best loss = 7.611412e-03\n",
            "\n",
            "DIAGNOSTICS\n",
            "======================================================================\n",
            "Batch success rate: 100.0%\n",
            "Total batches attempted: 1000\n",
            "Total retries: 0\n",
            "Convergence achieved: False\n",
            "Final epoch: 9\n",
            "Elapsed time: 0.62s\n",
            "\n",
            "Aggregate Statistics (from batch buffer):\n",
            "  Mean loss: 1.625896e-01\n",
            "  Std loss: 3.034042e-01\n",
            "  Mean gradient norm: 0.948855\n",
            "  Mean batch time: 0.40ms\n",
            "\n",
            "Recent batch statistics (last 100 batches):\n",
            "  Batch 95: SUCCESS, loss=1.803398e-02\n",
            "  Batch 96: SUCCESS, loss=1.725470e-02\n",
            "  Batch 97: SUCCESS, loss=1.732153e-02\n",
            "  Batch 98: SUCCESS, loss=1.525652e-02\n",
            "  Batch 99: SUCCESS, loss=1.644096e-02\n",
            "\n",
            "Checkpoint Information:\n",
            "  Path: checkpoints/checkpoint_iter_1000.h5\n",
            "  Saved at: 2025-12-18T15:00:26.340074\n",
            "  Batch index: 99\n",
            "\n",
            "======================================================================\n",
            "Example complete!\n",
            "\n",
            "Key takeaways:\n",
            "  - Fault tolerance enabled by default (no configuration needed)\n",
            "  - Best parameters always returned (never initial p0)\n",
            "  - NaN/Inf detection at three validation points\n",
            "  - Adaptive retry strategies for failed batches\n",
            "  - Comprehensive diagnostics for analysis\n",
            "  - Checkpoints saved automatically for recovery\n"
          ]
        }
      ],
      "source": [
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "from nlsq import StreamingConfig, StreamingOptimizer\n",
        "\n",
        "\n",
        "def exponential_decay(x, a, b):\n",
        "    \"\"\"Exponential decay model: y = a * exp(-b * x)\"\"\"\n",
        "    return a * jnp.exp(-b * x)\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Streaming Optimizer: Basic Fault Tolerance Example\")\n",
        "    print(\"=\" * 70)\n",
        "    print()\n",
        "\n",
        "    np.random.seed(42)\n",
        "    n_samples = 10000\n",
        "    x_data = np.linspace(0, 10, n_samples)\n",
        "    true_a, true_b = 2.5, 0.3\n",
        "    y_true = exponential_decay(x_data, true_a, true_b)\n",
        "    y_data = y_true + 0.1 * np.random.randn(n_samples)\n",
        "\n",
        "    print(f\"Dataset: {n_samples} samples\")\n",
        "    print(f\"True parameters: a={true_a}, b={true_b}\")\n",
        "    print()\n",
        "\n",
        "    config = StreamingConfig(\n",
        "        batch_size=100,\n",
        "        max_epochs=10,\n",
        "        learning_rate=0.001,\n",
        "        enable_fault_tolerance=True,  # Enable fault tolerance features\n",
        "        validate_numerics=True,  # Check for NaN/Inf\n",
        "        min_success_rate=0.5,  # Require 50% batch success\n",
        "        max_retries_per_batch=2,  # Max 2 retry attempts\n",
        "        checkpoint_dir=\"checkpoints\",\n",
        "        checkpoint_frequency=100,  # Save every 100 iterations\n",
        "        enable_checkpoints=True,\n",
        "    )\n",
        "\n",
        "    print(\"Configuration:\")\n",
        "    print(f\"  Batch size: {config.batch_size}\")\n",
        "    print(f\"  Max epochs: {config.max_epochs}\")\n",
        "    print(f\"  Learning rate: {config.learning_rate}\")\n",
        "    print(f\"  Fault tolerance: {config.enable_fault_tolerance}\")\n",
        "    print(f\"  Validate numerics: {config.validate_numerics}\")\n",
        "    print(f\"  Min success rate: {config.min_success_rate:.0%}\")\n",
        "    print(f\"  Max retries per batch: {config.max_retries_per_batch}\")\n",
        "    print()\n",
        "\n",
        "    optimizer = StreamingOptimizer(config)\n",
        "    p0 = np.array([1.0, 0.1])\n",
        "    print(f\"Initial guess: a={p0[0]}, b={p0[1]}\")\n",
        "    print()\n",
        "\n",
        "    print(\"Starting optimization...\")\n",
        "    print(\"-\" * 70)\n",
        "    result = optimizer.fit(\n",
        "        (x_data, y_data),  # Data as tuple\n",
        "        exponential_decay,  # Model function\n",
        "        p0,  # Initial parameters\n",
        "        verbose=1,  # Show progress\n",
        "    )\n",
        "    print(\"-\" * 70)\n",
        "    print()\n",
        "\n",
        "    best_params = result[\"x\"]\n",
        "    success = result[\"success\"]\n",
        "    message = result[\"message\"]\n",
        "    best_loss = result[\"best_loss\"]\n",
        "    diagnostics = result[\"streaming_diagnostics\"]\n",
        "\n",
        "    print(\"RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Success: {success}\")\n",
        "    print(f\"Message: {message}\")\n",
        "    print()\n",
        "    print(\"Best parameters found:\")\n",
        "    print(f\"  a = {best_params[0]:.6f} (true: {true_a})\")\n",
        "    print(f\"  b = {best_params[1]:.6f} (true: {true_b})\")\n",
        "    print(f\"  Best loss = {best_loss:.6e}\")\n",
        "    print()\n",
        "\n",
        "    print(\"DIAGNOSTICS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Batch success rate: {diagnostics['batch_success_rate']:.1%}\")\n",
        "    print(f\"Total batches attempted: {diagnostics['total_batches_attempted']}\")\n",
        "    print(f\"Total retries: {diagnostics['total_retries']}\")\n",
        "    print(f\"Convergence achieved: {diagnostics['convergence_achieved']}\")\n",
        "    print(f\"Final epoch: {diagnostics['final_epoch']}\")\n",
        "    print(f\"Elapsed time: {diagnostics['elapsed_time']:.2f}s\")\n",
        "    print()\n",
        "\n",
        "    if diagnostics[\"failed_batches\"]:\n",
        "        print(f\"Failed batches ({len(diagnostics['failed_batches'])}):\")\n",
        "        print(f\"  Indices: {diagnostics['failed_batches']}\")\n",
        "        print(f\"  Error types: {diagnostics['error_types']}\")\n",
        "        print()\n",
        "\n",
        "    agg = diagnostics[\"aggregate_stats\"]\n",
        "    print(\"Aggregate Statistics (from batch buffer):\")\n",
        "    print(f\"  Mean loss: {agg['mean_loss']:.6e}\")\n",
        "    print(f\"  Std loss: {agg['std_loss']:.6e}\")\n",
        "    print(f\"  Mean gradient norm: {agg['mean_grad_norm']:.6f}\")\n",
        "    print(f\"  Mean batch time: {agg['mean_batch_time'] * 1000:.2f}ms\")\n",
        "    print()\n",
        "\n",
        "    recent_stats = diagnostics[\"recent_batch_stats\"]\n",
        "    if recent_stats:\n",
        "        print(f\"Recent batch statistics (last {len(recent_stats)} batches):\")\n",
        "        # Convert deque to list for slicing\n",
        "        recent_list = list(recent_stats)[-5:]\n",
        "        for i, stats in enumerate(recent_list, 1):\n",
        "            status = \"SUCCESS\" if stats[\"success\"] else \"FAILED\"\n",
        "            retry_info = (\n",
        "                f\" (retries: {stats['retry_count']})\"\n",
        "                if stats[\"retry_count\"] > 0\n",
        "                else \"\"\n",
        "            )\n",
        "            print(\n",
        "                f\"  Batch {stats['batch_idx']}: {status}, loss={stats['loss']:.6e}{retry_info}\"\n",
        "            )\n",
        "        print()\n",
        "\n",
        "    if diagnostics[\"checkpoint_info\"]:\n",
        "        cp = diagnostics[\"checkpoint_info\"]\n",
        "        print(\"Checkpoint Information:\")\n",
        "        print(f\"  Path: {cp['path']}\")\n",
        "        print(f\"  Saved at: {cp['saved_at']}\")\n",
        "        print(f\"  Batch index: {cp['batch_idx']}\")\n",
        "        print()\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Example complete!\")\n",
        "    print()\n",
        "    print(\"Key takeaways:\")\n",
        "    print(\"  - Fault tolerance enabled by default (no configuration needed)\")\n",
        "    print(\"  - Best parameters always returned (never initial p0)\")\n",
        "    print(\"  - NaN/Inf detection at three validation points\")\n",
        "    print(\"  - Adaptive retry strategies for failed batches\")\n",
        "    print(\"  - Comprehensive diagnostics for analysis\")\n",
        "    print(\"  - Checkpoints saved automatically for recovery\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
