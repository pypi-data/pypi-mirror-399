{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a543e006",
   "metadata": {},
   "source": [
    "# 04 Workflow Presets\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/08_workflow_system/04_workflow_presets.ipynb)\n",
    "\n",
    "Converted from 04_workflow_presets.ipynb\n",
    "\n",
    "This script was automatically generated from a Jupyter notebook.\n",
    "Plots are saved to the figures/ directory instead of displayed inline.\n",
    "\n",
    "Features demonstrated:\n",
    "- All entries in the WORKFLOW_PRESETS dictionary\n",
    "- Using presets for common fitting scenarios\n",
    "- Inspecting preset configurations\n",
    "- Customizing presets as starting points\n",
    "\n",
    "Run this example:\n",
    "    python examples/scripts/08_workflow_system/04_workflow_presets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e05858",
   "metadata": {
    "id": "colab-install"
   },
   "outputs": [],
   "source": [
    "# @title Install NLSQ (run once in Colab)\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running in Google Colab - installing NLSQ...\")\n",
    "    !pip install -q nlsq\n",
    "    print(\"âœ… NLSQ installed successfully!\")\n",
    "else:\n",
    "    print(\"Not running in Colab - assuming NLSQ is already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00751be7",
   "metadata": {},
   "outputs": [],
   "source": "import time\nfrom pathlib import Path\nfrom pprint import pprint\n\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom nlsq import WORKFLOW_PRESETS, HybridStreamingConfig, WorkflowConfig, fit\n\nFIG_DIR = Path.cwd() / \"figures\"  # Modified for notebook compatibility\nFIG_DIR.mkdir(parents=True, exist_ok=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b98cd5",
   "metadata": {},
   "outputs": [],
   "source": "def exponential_model(x, a, b, c):\n    \"\"\"Exponential decay: y = a * exp(-b * x) + c\"\"\"\n    return a * jnp.exp(-b * x) + c\n\n\ndef main():\n    print(\"=\" * 70)\n    print(\"WORKFLOW_PRESETS Guide\")\n    print(\"=\" * 70)\n    print()\n\n    # Set random seed for reproducibility\n    np.random.seed(42)\n\n    # =========================================================================\n    # 1. Available Presets\n    # =========================================================================\n    print(\"1. Available WORKFLOW_PRESETS:\")\n    print(\"-\" * 60)\n\n    for preset_name in WORKFLOW_PRESETS:\n        description = WORKFLOW_PRESETS[preset_name].get(\"description\", \"No description\")\n        print(f\"  {preset_name:<20} - {description}\")\n\n    # =========================================================================\n    # 2. Inspecting Presets\n    # =========================================================================\n    print()\n    print(\"2. Inspecting Presets:\")\n    print(\"-\" * 60)\n\n    print(\"\\n'standard' preset:\")\n    pprint(WORKFLOW_PRESETS[\"standard\"])\n\n    print(\"\\n'quality' preset:\")\n    pprint(WORKFLOW_PRESETS[\"quality\"])\n\n    print(\"\\n'streaming' preset:\")\n    pprint(WORKFLOW_PRESETS[\"streaming\"])\n\n    # =========================================================================\n    # 3. Preset Comparison Table\n    # =========================================================================\n    print()\n    print(\"3. Preset Comparison:\")\n    print(\"=\" * 100)\n    print(\n        f\"{'Preset':<18} {'Tier':<12} {'Goal':<16} \"\n        f\"{'Multistart':<12} {'n_starts':<10} {'gtol':<12}\"\n    )\n    print(\"-\" * 100)\n\n    for name, config in WORKFLOW_PRESETS.items():\n        tier = config.get(\"tier\", \"STANDARD\")\n        goal = config.get(\"goal\", \"ROBUST\")\n        multistart = config.get(\"enable_multistart\", False)\n        n_starts = config.get(\"n_starts\", 0)\n        gtol = config.get(\"gtol\", 1e-8)\n\n        multistart_str = \"Yes\" if multistart else \"No\"\n\n        print(\n            f\"{name:<18} {tier:<12} {goal:<16} \"\n            f\"{multistart_str:<12} {n_starts:<10} {gtol:<12.0e}\"\n        )\n\n    # =========================================================================\n    # 4. Testing Presets\n    # =========================================================================\n    print()\n    print(\"4. Testing Presets on Exponential Decay:\")\n    print(\"-\" * 70)\n\n    # Generate test data\n    n_samples = 500\n    x_data = np.linspace(0, 5, n_samples)\n\n    # True parameters\n    true_a, true_b, true_c = 3.0, 1.2, 0.5\n    y_true = true_a * np.exp(-true_b * x_data) + true_c\n    noise = 0.15 * np.random.randn(n_samples)\n    y_data = y_true + noise\n\n    # Initial guess and bounds\n    p0 = [1.0, 0.5, 0.0]\n    bounds = ([0.1, 0.1, -1.0], [10.0, 5.0, 2.0])\n\n    print(f\"  True parameters: a={true_a}, b={true_b}, c={true_c}\")\n\n    presets_to_test = [\"fast\", \"standard\", \"quality\"]\n    results = {}\n\n    for preset_name in presets_to_test:\n        start_time = time.time()\n\n        popt, pcov = fit(\n            exponential_model,\n            x_data,\n            y_data,\n            p0=p0,\n            bounds=bounds,\n            preset=preset_name,\n        )\n\n        elapsed = time.time() - start_time\n\n        y_pred = exponential_model(x_data, *popt)\n        ssr = float(jnp.sum((y_data - y_pred) ** 2))\n\n        results[preset_name] = {\n            \"popt\": popt,\n            \"ssr\": ssr,\n            \"time\": elapsed,\n        }\n\n        print(f\"\\n  {preset_name.upper()}:\")\n        print(f\"    Time:       {elapsed:.4f}s\")\n        print(f\"    SSR:        {ssr:.6f}\")\n        print(f\"    Parameters: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n\n    # =========================================================================\n    # 5. Creating WorkflowConfig from Presets\n    # =========================================================================\n    print()\n    print(\"5. WorkflowConfig from Presets:\")\n    print(\"-\" * 50)\n\n    config = WorkflowConfig.from_preset(\"quality\")\n\n    print(\"\\nWorkflowConfig from 'quality' preset:\")\n    print(f\"  tier:              {config.tier.name}\")\n    print(f\"  goal:              {config.goal.name}\")\n    print(f\"  enable_multistart: {config.enable_multistart}\")\n    print(f\"  n_starts:          {config.n_starts}\")\n    print(f\"  gtol:              {config.gtol}\")\n\n    # =========================================================================\n    # 6. Customizing Presets\n    # =========================================================================\n    print()\n    print(\"6. Customizing Presets:\")\n    print(\"-\" * 50)\n\n    base_config = WorkflowConfig.from_preset(\"quality\")\n    custom_config = base_config.with_overrides(\n        n_starts=30,\n        sampler=\"sobol\",\n        gtol=1e-12,\n    )\n\n    print(\"\\nCustomized 'quality' preset:\")\n    print(f\"  Original n_starts: {base_config.n_starts}\")\n    print(f\"  Custom n_starts:   {custom_config.n_starts}\")\n    print(f\"  Original sampler:  {base_config.sampler}\")\n    print(f\"  Custom sampler:    {custom_config.sampler}\")\n    print(f\"  Original gtol:     {base_config.gtol}\")\n    print(f\"  Custom gtol:       {custom_config.gtol}\")\n\n    # =========================================================================\n    # 7. Preset Documentation\n    # =========================================================================\n    print()\n    print(\"7. Preset Use Case Guide:\")\n    print(\"=\" * 80)\n\n    preset_docs = {\n        \"standard\": {\n            \"summary\": \"Default curve_fit() behavior\",\n            \"best_for\": \"Well-conditioned problems with good initial guesses\",\n            \"tradeoffs\": \"Balanced speed/accuracy, no global search\",\n        },\n        \"quality\": {\n            \"summary\": \"Highest precision fitting\",\n            \"best_for\": \"Publication results, parameter uncertainty estimation\",\n            \"tradeoffs\": \"Slower due to multi-start and tight tolerances\",\n        },\n        \"fast\": {\n            \"summary\": \"Speed-optimized fitting\",\n            \"best_for\": \"Exploratory analysis, development, quick iterations\",\n            \"tradeoffs\": \"May converge to local minima\",\n        },\n        \"large_robust\": {\n            \"summary\": \"Chunked processing with multi-start\",\n            \"best_for\": \"Large datasets (1M-100M points) needing global search\",\n            \"tradeoffs\": \"Memory-efficient but slower than standard\",\n        },\n        \"streaming\": {\n            \"summary\": \"Streaming for huge datasets\",\n            \"best_for\": \"Datasets that exceed available memory (100M+ points)\",\n            \"tradeoffs\": \"No covariance matrix, approximate convergence\",\n        },\n        \"hpc_distributed\": {\n            \"summary\": \"Multi-GPU/node HPC clusters\",\n            \"best_for\": \"PBS Pro, Slurm clusters with checkpoint recovery\",\n            \"tradeoffs\": \"Requires HPC environment setup\",\n        },\n        \"memory_efficient\": {\n            \"summary\": \"Minimize memory footprint\",\n            \"best_for\": \"Memory-constrained systems, edge devices\",\n            \"tradeoffs\": \"Smaller chunk sizes = more overhead\",\n        },\n    }\n\n    for name, doc in preset_docs.items():\n        print(f\"\\n  {name.upper()}:\")\n        print(f\"    Summary:    {doc['summary']}\")\n        print(f\"    Best for:   {doc['best_for']}\")\n        print(f\"    Tradeoffs:  {doc['tradeoffs']}\")\n\n    # =========================================================================\n    # 8. Defense Layer Presets (v0.3.6+)\n    # =========================================================================\n    print()\n    print()\n    print(\"8. Defense Layer Presets (v0.3.6+):\")\n    print(\"-\" * 70)\n    print()\n    print(\"For streaming workflows, HybridStreamingConfig provides defense presets\")\n    print(\"that protect against Adam warmup divergence when starting near optimal:\")\n    print()\n\n    defense_presets = {\n        \"defense_strict\": {\n            \"method\": \"HybridStreamingConfig.defense_strict()\",\n            \"use_case\": \"Warm-start refinement (previous fit as p0)\",\n            \"lr_range\": \"1e-6 to 1e-4\",\n        },\n        \"defense_relaxed\": {\n            \"method\": \"HybridStreamingConfig.defense_relaxed()\",\n            \"use_case\": \"Exploration (rough initial guesses)\",\n            \"lr_range\": \"1e-4 to 0.01\",\n        },\n        \"scientific_default\": {\n            \"method\": \"HybridStreamingConfig.scientific_default()\",\n            \"use_case\": \"Production scientific computing\",\n            \"lr_range\": \"1e-6 to 0.001 (balanced)\",\n        },\n        \"defense_disabled\": {\n            \"method\": \"HybridStreamingConfig.defense_disabled()\",\n            \"use_case\": \"Pre-0.3.6 behavior (no protection)\",\n            \"lr_range\": \"Fixed at warmup_learning_rate\",\n        },\n    }\n\n    for name, info in defense_presets.items():\n        print(f\"  {name.upper()}:\")\n        print(f\"    Method:   {info['method']}\")\n        print(f\"    Use case: {info['use_case']}\")\n        print(f\"    LR range: {info['lr_range']}\")\n        print()\n\n    print(\"The 4-layer defense strategy:\")\n    print(\"  Layer 1: Warm Start Detection - Skip warmup if near optimal\")\n    print(\"  Layer 2: Adaptive Learning Rate - Scale LR based on fit quality\")\n    print(\"  Layer 3: Cost-Increase Guard - Abort if loss increases > 5%\")\n    print(\"  Layer 4: Step Clipping - Limit parameter update magnitude\")\n\n    # =========================================================================\n    # 9. Visualization\n    # =========================================================================\n    print()\n    print()\n    print(\"9. Saving visualizations...\")\n\n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n    preset_names = list(results.keys())\n    colors = {\"fast\": \"blue\", \"standard\": \"green\", \"quality\": \"red\"}\n\n    # SSR comparison\n    ax1 = axes[0]\n    ssrs = [results[p][\"ssr\"] for p in preset_names]\n    bars = ax1.bar(preset_names, ssrs, color=[colors[p] for p in preset_names])\n    ax1.set_xlabel(\"Preset\")\n    ax1.set_ylabel(\"Sum of Squared Residuals\")\n    ax1.set_title(\"Fit Quality by Preset\")\n    for bar, ssr in zip(bars, ssrs, strict=False):\n        ax1.text(\n            bar.get_x() + bar.get_width() / 2,\n            bar.get_height(),\n            f\"{ssr:.4f}\",\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=9,\n        )\n\n    # Time comparison\n    ax2 = axes[1]\n    times = [results[p][\"time\"] for p in preset_names]\n    bars = ax2.bar(preset_names, times, color=[colors[p] for p in preset_names])\n    ax2.set_xlabel(\"Preset\")\n    ax2.set_ylabel(\"Time (seconds)\")\n    ax2.set_title(\"Computation Time by Preset\")\n    for bar, t in zip(bars, times, strict=False):\n        ax2.text(\n            bar.get_x() + bar.get_width() / 2,\n            bar.get_height(),\n            f\"{t:.3f}s\",\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=9,\n        )\n\n    # Tolerance comparison\n    ax3 = axes[2]\n    tols = [WORKFLOW_PRESETS[p][\"gtol\"] for p in preset_names]\n    bars = ax3.bar(preset_names, tols, color=[colors[p] for p in preset_names])\n    ax3.set_xlabel(\"Preset\")\n    ax3.set_ylabel(\"gtol\")\n    ax3.set_title(\"Tolerance (gtol) by Preset\")\n    ax3.set_yscale(\"log\")\n    for bar, t in zip(bars, tols, strict=False):\n        ax3.text(\n            bar.get_x() + bar.get_width() / 2,\n            bar.get_height(),\n            f\"{t:.0e}\",\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=9,\n        )\n\n    plt.tight_layout()\n    plt.savefig(FIG_DIR / \"04_preset_comparison.png\", dpi=300, bbox_inches=\"tight\")\n    plt.close()\n    print(f\"  Saved: {FIG_DIR / '04_preset_comparison.png'}\")\n\n    # =========================================================================\n    # Summary\n    # =========================================================================\n    print()\n    print(\"=\" * 70)\n    print(\"Summary\")\n    print(\"=\" * 70)\n    print()\n    print(\"Available presets:\")\n    for name in WORKFLOW_PRESETS:\n        desc = WORKFLOW_PRESETS[name].get(\"description\", \"\")\n        print(f\"  - {name}: {desc}\")\n    print()\n    print(\"Quick usage:\")\n    print(\"  fit(model, x, y, preset='quality')\")\n    print(\"  WorkflowConfig.from_preset('quality')\")\n    print(\"  config.with_overrides(n_starts=30)\")\n    print()\n    print(\"Defense presets for streaming (v0.3.6+):\")\n    print(\"  HybridStreamingConfig.defense_strict()     # Warm-start refinement\")\n    print(\"  HybridStreamingConfig.defense_relaxed()    # Exploration\")\n    print(\"  HybridStreamingConfig.scientific_default() # Production scientific\")\n    print(\"  HybridStreamingConfig.defense_disabled()   # Pre-0.3.6 behavior\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af04a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
