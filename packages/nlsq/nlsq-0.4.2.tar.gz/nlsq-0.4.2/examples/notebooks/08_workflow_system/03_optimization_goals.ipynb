{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cb30dd",
   "metadata": {},
   "source": [
    "# 03 Optimization Goals\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/08_workflow_system/03_optimization_goals.ipynb)\n",
    "\n",
    "Converted from 03_optimization_goals.ipynb\n",
    "\n",
    "This script was automatically generated from a Jupyter notebook.\n",
    "Plots are saved to the figures/ directory instead of displayed inline.\n",
    "\n",
    "Features demonstrated:\n",
    "- All 5 OptimizationGoal values and their behaviors\n",
    "- Internal settings each goal applies\n",
    "- Combining goals with WorkflowTier\n",
    "- Visualization comparing goal performance\n",
    "\n",
    "Run this example:\n",
    "    python examples/scripts/08_workflow_system/03_optimization_goals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc6e16",
   "metadata": {
    "id": "colab-install"
   },
   "outputs": [],
   "source": [
    "# @title Install NLSQ (run once in Colab)\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running in Google Colab - installing NLSQ...\")\n",
    "    !pip install -q nlsq\n",
    "    print(\"âœ… NLSQ installed successfully!\")\n",
    "else:\n",
    "    print(\"Not running in Colab - assuming NLSQ is already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import OptimizationGoal, WorkflowConfig, WorkflowTier, fit\n",
    "from nlsq.core.workflow import DatasetSizeTier, calculate_adaptive_tolerances\n",
    "\n",
    "FIG_DIR = Path.cwd() / \"figures\"  # Modified for notebook compatibility\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e4a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(x, a, b, c):\n",
    "    \"\"\"Exponential decay: y = a * exp(-b * x) + c\"\"\"\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Goal-Driven Optimization\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # =========================================================================\n",
    "    # 1. OptimizationGoal Overview\n",
    "    # =========================================================================\n",
    "    print(\"1. OptimizationGoal Values:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for goal in OptimizationGoal:\n",
    "        print(f\"  {goal.name:<20} = {goal.value}\")\n",
    "\n",
    "    # Goal descriptions\n",
    "    goal_info = {\n",
    "        OptimizationGoal.FAST: {\n",
    "            \"description\": \"Prioritize speed with local optimization only\",\n",
    "            \"tolerances\": \"One tier looser\",\n",
    "            \"multistart\": \"Disabled\",\n",
    "            \"use_case\": \"Quick exploration, well-conditioned problems\",\n",
    "        },\n",
    "        OptimizationGoal.ROBUST: {\n",
    "            \"description\": \"Standard tolerances with multi-start\",\n",
    "            \"tolerances\": \"Dataset-appropriate\",\n",
    "            \"multistart\": \"Enabled\",\n",
    "            \"use_case\": \"Production use, unknown problem conditioning\",\n",
    "        },\n",
    "        OptimizationGoal.GLOBAL: {\n",
    "            \"description\": \"Synonym for ROBUST (emphasizes global optimization)\",\n",
    "            \"tolerances\": \"Dataset-appropriate\",\n",
    "            \"multistart\": \"Enabled\",\n",
    "            \"use_case\": \"Same as ROBUST, semantic clarity\",\n",
    "        },\n",
    "        OptimizationGoal.MEMORY_EFFICIENT: {\n",
    "            \"description\": \"Minimize memory usage with standard tolerances\",\n",
    "            \"tolerances\": \"Dataset-appropriate\",\n",
    "            \"multistart\": \"Disabled\",\n",
    "            \"use_case\": \"Memory-constrained environments\",\n",
    "        },\n",
    "        OptimizationGoal.QUALITY: {\n",
    "            \"description\": \"Highest precision/accuracy as TOP PRIORITY\",\n",
    "            \"tolerances\": \"One tier tighter\",\n",
    "            \"multistart\": \"Enabled + validation passes\",\n",
    "            \"use_case\": \"Publication-quality results\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    print(\"\\nGoal Details:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for goal, info in goal_info.items():\n",
    "        print(f\"\\n  {goal.name}:\")\n",
    "        print(f\"    Description:  {info['description']}\")\n",
    "        print(f\"    Tolerances:   {info['tolerances']}\")\n",
    "        print(f\"    Multi-start:  {info['multistart']}\")\n",
    "        print(f\"    Use case:     {info['use_case']}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # 2. Adaptive Tolerances\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"2. Adaptive Tolerances by Dataset Size and Goal:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Dataset Size':<15} {'FAST':<15} {'ROBUST':<15} {'QUALITY':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    dataset_sizes = [500, 5_000, 50_000, 500_000, 5_000_000]\n",
    "    goals_to_compare = [\n",
    "        OptimizationGoal.FAST,\n",
    "        OptimizationGoal.ROBUST,\n",
    "        OptimizationGoal.QUALITY,\n",
    "    ]\n",
    "\n",
    "    for n_points in dataset_sizes:\n",
    "        tols = {}\n",
    "        for goal in goals_to_compare:\n",
    "            tols[goal.name] = calculate_adaptive_tolerances(n_points, goal)[\"gtol\"]\n",
    "\n",
    "        print(\n",
    "            f\"{n_points:>12,}   {tols['FAST']:<15.0e} \"\n",
    "            f\"{tols['ROBUST']:<15.0e} {tols['QUALITY']:<15.0e}\"\n",
    "        )\n",
    "\n",
    "    # =========================================================================\n",
    "    # 3. DatasetSizeTier Reference\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"3. DatasetSizeTier Reference:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Tier':<15} {'Max Points':<15} {'Base Tolerance'}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for tier in DatasetSizeTier:\n",
    "        max_pts = tier.max_points\n",
    "        if max_pts == float(\"inf\"):\n",
    "            max_pts_str = \"unlimited\"\n",
    "        else:\n",
    "            max_pts_str = f\"{int(max_pts):,}\"\n",
    "        print(f\"{tier.name:<15} {max_pts_str:<15} {tier.tolerance:.0e}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # 4. Practical Comparison\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"4. Testing Goals on Exponential Decay Problem:\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Generate synthetic data\n",
    "    n_samples = 1000\n",
    "    x_data = np.linspace(0, 5, n_samples)\n",
    "\n",
    "    # True parameters\n",
    "    true_a, true_b, true_c = 3.0, 1.2, 0.5\n",
    "\n",
    "    y_true = true_a * np.exp(-true_b * x_data) + true_c\n",
    "    noise = 0.1 * np.random.randn(n_samples)\n",
    "    y_data = y_true + noise\n",
    "\n",
    "    # Initial guess and bounds\n",
    "    p0 = [1.0, 0.5, 0.0]\n",
    "    bounds = ([0.1, 0.1, -1.0], [10.0, 5.0, 2.0])\n",
    "\n",
    "    print(f\"  True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "    print(f\"  Dataset size: {n_samples} points\")\n",
    "\n",
    "    results = {}\n",
    "    goals_to_test = [\"fast\", \"robust\", \"global\"]\n",
    "\n",
    "    for goal_name in goals_to_test:\n",
    "        start_time = time.time()\n",
    "\n",
    "        popt, pcov = fit(\n",
    "            exponential_decay,\n",
    "            x_data,\n",
    "            y_data,\n",
    "            p0=p0,\n",
    "            bounds=bounds,\n",
    "            preset=goal_name,\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        y_pred = exponential_decay(x_data, *popt)\n",
    "        ssr = float(jnp.sum((y_data - y_pred) ** 2))\n",
    "\n",
    "        param_errors = [abs(popt[i] - [true_a, true_b, true_c][i]) for i in range(3)]\n",
    "\n",
    "        results[goal_name] = {\n",
    "            \"popt\": popt,\n",
    "            \"ssr\": ssr,\n",
    "            \"time\": elapsed,\n",
    "            \"errors\": param_errors,\n",
    "        }\n",
    "\n",
    "        print(f\"\\n  {goal_name.upper()}:\")\n",
    "        print(f\"    Time:       {elapsed:.4f}s\")\n",
    "        print(f\"    SSR:        {ssr:.6f}\")\n",
    "        print(f\"    Parameters: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "        print(\n",
    "            f\"    Errors:     a_err={param_errors[0]:.4f}, \"\n",
    "            f\"b_err={param_errors[1]:.4f}, c_err={param_errors[2]:.4f}\"\n",
    "        )\n",
    "\n",
    "    # =========================================================================\n",
    "    # 5. WorkflowConfig with Goals\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"5. WorkflowConfig with Different Goals:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for goal in [\n",
    "        OptimizationGoal.FAST,\n",
    "        OptimizationGoal.ROBUST,\n",
    "        OptimizationGoal.QUALITY,\n",
    "    ]:\n",
    "        config = WorkflowConfig(goal=goal)\n",
    "        print(f\"\\n  {goal.name}:\")\n",
    "        print(f\"    tier:              {config.tier.name}\")\n",
    "        print(f\"    gtol:              {config.gtol}\")\n",
    "        print(f\"    enable_multistart: {config.enable_multistart}\")\n",
    "\n",
    "    # Combining goals with tiers\n",
    "    print(\"\\n  Quality + Streaming (combined):\")\n",
    "    config_combined = WorkflowConfig(\n",
    "        goal=OptimizationGoal.QUALITY,\n",
    "        tier=WorkflowTier.STREAMING,\n",
    "        enable_multistart=True,\n",
    "        n_starts=20,\n",
    "    )\n",
    "    print(f\"    tier:              {config_combined.tier.name}\")\n",
    "    print(f\"    goal:              {config_combined.goal.name}\")\n",
    "    print(f\"    enable_multistart: {config_combined.enable_multistart}\")\n",
    "    print(f\"    n_starts:          {config_combined.n_starts}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # 6. GLOBAL vs ROBUST\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"6. GLOBAL and ROBUST Equivalence:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    normalized = OptimizationGoal.normalize(OptimizationGoal.GLOBAL)\n",
    "    print(f\"  OptimizationGoal.GLOBAL normalizes to: {normalized.name}\")\n",
    "\n",
    "    tols_global = calculate_adaptive_tolerances(10000, OptimizationGoal.GLOBAL)\n",
    "    tols_robust = calculate_adaptive_tolerances(10000, OptimizationGoal.ROBUST)\n",
    "\n",
    "    print(f\"  GLOBAL gtol: {tols_global['gtol']}\")\n",
    "    print(f\"  ROBUST gtol: {tols_robust['gtol']}\")\n",
    "    print(f\"  Same: {tols_global['gtol'] == tols_robust['gtol']}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # 7. Visualization\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"7. Saving visualizations...\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    colors = {\"fast\": \"blue\", \"robust\": \"green\", \"global\": \"red\"}\n",
    "\n",
    "    # Top left: Tolerance comparison across dataset sizes\n",
    "    ax1 = axes[0, 0]\n",
    "    sizes = np.logspace(2, 8, 50).astype(int)\n",
    "\n",
    "    for goal in [\n",
    "        OptimizationGoal.FAST,\n",
    "        OptimizationGoal.ROBUST,\n",
    "        OptimizationGoal.QUALITY,\n",
    "    ]:\n",
    "        tols = [calculate_adaptive_tolerances(n, goal)[\"gtol\"] for n in sizes]\n",
    "        ax1.loglog(sizes, tols, label=goal.name, linewidth=2)\n",
    "\n",
    "    ax1.set_xlabel(\"Dataset Size (points)\")\n",
    "    ax1.set_ylabel(\"gtol\")\n",
    "    ax1.set_title(\"Adaptive Tolerances by Goal\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Top right: SSR comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    goal_names = list(results.keys())\n",
    "    ssrs = [results[g][\"ssr\"] for g in goal_names]\n",
    "    bars = ax2.bar(goal_names, ssrs, color=[colors[g] for g in goal_names])\n",
    "    ax2.set_xlabel(\"Goal\")\n",
    "    ax2.set_ylabel(\"Sum of Squared Residuals\")\n",
    "    ax2.set_title(\"Fit Quality by Goal\")\n",
    "    for bar, ssr in zip(bars, ssrs, strict=False):\n",
    "        ax2.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            f\"{ssr:.4f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    # Bottom left: Time comparison\n",
    "    ax3 = axes[1, 0]\n",
    "    times = [results[g][\"time\"] for g in goal_names]\n",
    "    bars = ax3.bar(goal_names, times, color=[colors[g] for g in goal_names])\n",
    "    ax3.set_xlabel(\"Goal\")\n",
    "    ax3.set_ylabel(\"Time (seconds)\")\n",
    "    ax3.set_title(\"Computation Time by Goal\")\n",
    "    for bar, t in zip(bars, times, strict=False):\n",
    "        ax3.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            f\"{t:.3f}s\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    # Bottom right: Parameter errors\n",
    "    ax4 = axes[1, 1]\n",
    "    x_pos = np.arange(len(goal_names))\n",
    "    width = 0.25\n",
    "\n",
    "    for i, param in enumerate([\"a\", \"b\", \"c\"]):\n",
    "        errors = [results[g][\"errors\"][i] for g in goal_names]\n",
    "        ax4.bar(x_pos + i * width, errors, width, label=f\"{param} error\")\n",
    "\n",
    "    ax4.set_xlabel(\"Goal\")\n",
    "    ax4.set_ylabel(\"Absolute Error\")\n",
    "    ax4.set_title(\"Parameter Errors by Goal\")\n",
    "    ax4.set_xticks(x_pos + width)\n",
    "    ax4.set_xticklabels(goal_names)\n",
    "    ax4.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"03_goal_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"  Saved: {FIG_DIR / '03_goal_comparison.png'}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # Summary\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Summary\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "    print()\n",
    "    print(\"Goal recommendations:\")\n",
    "    print(\"  - Exploratory analysis:    OptimizationGoal.FAST\")\n",
    "    print(\"  - Production fitting:      OptimizationGoal.ROBUST\")\n",
    "    print(\"  - Global search emphasis:  OptimizationGoal.GLOBAL\")\n",
    "    print(\"  - Memory constraints:      OptimizationGoal.MEMORY_EFFICIENT\")\n",
    "    print(\"  - Publication quality:     OptimizationGoal.QUALITY\")\n",
    "    print()\n",
    "    print(\"Key behaviors:\")\n",
    "    print(\"  - FAST: Looser tolerances, no multi-start\")\n",
    "    print(\"  - ROBUST/GLOBAL: Standard tolerances, multi-start enabled\")\n",
    "    print(\"  - MEMORY_EFFICIENT: Standard tolerances, streaming/chunking preferred\")\n",
    "    print(\"  - QUALITY: Tighter tolerances, multi-start + validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abaa456",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
