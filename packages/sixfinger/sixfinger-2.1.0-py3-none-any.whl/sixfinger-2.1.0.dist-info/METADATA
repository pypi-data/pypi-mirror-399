Metadata-Version: 2.4
Name: sixfinger
Version: 2.1.0
Summary: Ultra-fast AI platform: Cloud API + On-device language models
Home-page: https://sfapi.pythonanywhere.com
Author: Sixfinger Team
Author-email: Sixfinger Team <sixfingerdev@gmail.com>
License: MIT
Project-URL: Homepage, https://sfapi.pythonanywhere.com
Project-URL: Documentation, https://sfapi.pythonanywhere.com/docs
Project-URL: Repository, https://github.com/sixfinger/sixfinger-python
Project-URL: Changelog, https://github.com/sixfinger/sixfinger-python/blob/main/CHANGELOG.md
Keywords: ai,chatbot,api,llm,sixfinger,artificial-intelligence,transformers,on-device,cpu-optimized,mobile-ml
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests>=2.25.0
Provides-Extra: async
Requires-Dist: aiohttp>=3.8.0; extra == "async"
Provides-Extra: transformers
Requires-Dist: numpy>=1.19.0; extra == "transformers"
Requires-Dist: tqdm>=4.50.0; extra == "transformers"
Provides-Extra: transformers-fast
Requires-Dist: numpy>=1.19.0; extra == "transformers-fast"
Requires-Dist: tqdm>=4.50.0; extra == "transformers-fast"
Requires-Dist: numba>=0.53.0; extra == "transformers-fast"
Provides-Extra: all
Requires-Dist: aiohttp>=3.8.0; extra == "all"
Requires-Dist: numpy>=1.19.0; extra == "all"
Requires-Dist: tqdm>=4.50.0; extra == "all"
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov>=2.12; extra == "dev"
Requires-Dist: black>=21.0; extra == "dev"
Requires-Dist: flake8>=3.9; extra == "dev"
Requires-Dist: mypy>=0.900; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# ğŸš€ Sixfinger - Ultra-Fast AI API

[![PyPI](https://img.shields.io/pypi/v/sixfinger.svg)](https://pypi.org/project/sixfinger/)
[![Python](https://img.shields.io/pypi/pyversions/sixfinger.svg)](https://pypi.org/project/sixfinger/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**~1,100 chars/sec** - 10-20x faster than OpenAI/Claude!

## âš¡ Features

- ğŸš€ **Ultra-fast**: ~1,100 characters/second
- ğŸ¤– **9 AI Models**: Llama 3.1/3.3, Qwen3, GPT-OSS, etc.
- ğŸ‡¹ğŸ‡· **Turkish optimized**: Qwen3-32B
- ğŸ’¬ **Conversation context**
- ğŸ“¡ **Streaming support**
- ğŸ’° **Free tier**: 200 requests/month

## ğŸ“¦ Installation

```bash
pip install sixfinger
For async support:

Bash

pip install sixfinger[async]
ğŸ”‘ Get API Key
Sign up
Verify email
Get key from Dashboard
ğŸš€ Quick Start
Python

from sixfinger import API

client = API(api_key="sixfinger_xxx")
response = client.chat("Merhaba!")
print(response.content)
Conversation
Python

from sixfinger import API

client = API(api_key="sixfinger_xxx")
conv = client.conversation()

conv.send("Merhaba!")
conv.send("Python nedir?")
conv.send("Neden popÃ¼ler?")  # Remembers context!
Streaming
Python

from sixfinger import API

client = API(api_key="sixfinger_xxx")

for chunk in client.chat("Tell me a story", stream=True):
    print(chunk, end='', flush=True)
Async
Python

import asyncio
from sixfinger import AsyncAPI

async def main():
    async with AsyncAPI(api_key="sixfinger_xxx") as client:
        response = await client.chat("Merhaba!")
        print(response.content)

asyncio.run(main())
Model Selection
Python

# Auto model (recommended)
response = client.chat("Merhaba!")

# Turkish
response = client.chat("OsmanlÄ± tarihi", model="qwen3-32b")

# Complex tasks
response = client.chat("Explain quantum physics", model="llama-70b")

# Fast
response = client.chat("Quick answer", model="llama-8b-instant")
ğŸ¤– Available Models
Model	Key	Size	Language	Plan
Llama 3.1 8B Instant	llama-8b-instant	8B	Multilingual	FREE+
Allam 2 7B	allam-2-7b	7B	Turkish/Arabic	FREE+
Qwen3 32B â­	qwen3-32b	32B	Turkish	STARTER+
Llama 3.3 70B	llama-70b	70B	Multilingual	STARTER+
GPT-OSS 120B	gpt-oss-120b	120B	Multilingual	PRO+
ğŸ“Š Rate Limits
Plan	Price	Requests/Month	Tokens/Month
FREE	$0	200	20K
STARTER	$79	3K	300K
PRO	$199	75K	7.5M
PLUS	$499	500K	50M
ğŸ“š Documentation
Full docs: https://sfapi.pythonanywhere.com

ğŸ¤ Support
Email: sixfingerdev@gmail.com

ğŸ“„ License
MIT License
