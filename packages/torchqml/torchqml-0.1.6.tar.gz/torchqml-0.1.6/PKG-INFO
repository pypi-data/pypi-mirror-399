Metadata-Version: 2.4
Name: torchqml
Version: 0.1.6
Summary: PyTorch Quantum Machine Learning with cuQuantum - Fast Adjoint Differentiation
Author: Your Name
Author-email: Masaki Shiraishi <masaki.shiraishi@fuji.waseda.jp>
License: MIT
Project-URL: Homepage, https://github.com/masa-whitestone/torch-qml
Project-URL: Bug Reports, https://github.com/masa-whitestone/torch-qml/issues
Project-URL: Source, https://github.com/masa-whitestone/torch-qml
Keywords: quantum,machine learning,pytorch,cuquantum,adjoint differentiation
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Physics
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: torch>=2.0.0
Requires-Dist: numpy>=1.20.0
Requires-Dist: cupy-cuda12x>=12.0.0
Requires-Dist: cuquantum-python-cu12
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Provides-Extra: benchmark
Requires-Dist: pennylane>=0.30.0; extra == "benchmark"
Requires-Dist: pennylane-lightning[gpu]>=0.30.0; extra == "benchmark"
Dynamic: author
Dynamic: requires-python

# torchqml

PyTorch Quantum Machine Learning with cuQuantum - Fast Adjoint Differentiation

## Features

- **Adjoint Differentiation**: O(G) gradient calculation using cuQuantum's `custatevec` and optimized C++ kernels.
- **PyTorch Native**: Fully integrated with `torch.autograd` and `torch.nn`.
- **High Performance**: Custom C++/CUDA extension reusing cuStateVec/cuBLAS handles for minimize overhead.

## Performance
TorchQML outperforms PennyLane's `lightning.gpu` backend significantly on NVIDIA GPUs (measured on T4):

| Qubits | Layers | TorchQML (ms) | PennyLane (ms) | Speedup |
| :--- | :--- | :--- | :--- | :--- |
| 4 | 5 | 5.72 | 16.99 | **3.0x** |
| 8 | 10 | 13.18 | 48.69 | **3.7x** |
| 12 | 10 | 24.29 | 69.65 | **2.9x** |

## Installation

```bash
pip install .
```

## Usage

```python
import torch
import torchqml as tq

# Build circuit
qc = tq.QuantumCircuit(2)
qc.h(0)
qc.ry(0, param_index=0)
qc.cx(0, 1)

# Parameters
params = torch.tensor([[0.5]], requires_grad=True)

# Expectation
exp_val = qc.expectation(params, tq.Z(0))

# Backward
exp_val.backward()
print(params.grad)
```
