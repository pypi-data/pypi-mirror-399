import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import numpy as np

import yaml


# form utils import load_config

# ---------------------------------------------------------
# 1. å®šä¹‰ LSTM åˆ†ç±»ç½‘ç»œ
# ---------------------------------------------------------
class LSTMClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout=0.2):
        super(LSTMClassifier, self).__init__()

        self.lstm = nn.LSTM(
            input_dim,
            hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout
        )

        # print(f"self.fc = nn.Linear({hidden_dim}, {num_classes})")

        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        # x: (batch, time, channels)
        out, _ = self.lstm(x)
        out = out[:, -1, :]          # æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        out = self.fc(out)
        return out


class CNNClassifier(nn.Module):
    def __init__(self, n_channels, n_classes, 
                 channels=[64, 128], 
                 kernel_sizes=[5, 5],
                 use_batchnorm=True,
                 pooling_type='avg',
                 dropout_rate=0.5):
        """
        å¯é…ç½®å‚æ•°çš„EEGCNNæ¨¡å‹
        
        Args:
            n_channels: è¾“å…¥é€šé“æ•°
            n_classes: åˆ†ç±»ç±»åˆ«æ•°
            channels: å„å±‚é€šé“æ•°åˆ—è¡¨ï¼Œä¾‹å¦‚ [64, 128]
            kernel_sizes: å„å±‚å·ç§¯æ ¸å¤§å°åˆ—è¡¨
            use_batchnorm: æ˜¯å¦ä½¿ç”¨æ‰¹å½’ä¸€åŒ–
            pooling_type: æ± åŒ–ç±»å‹ 'avg' æˆ– 'max'
            dropout_rate: Dropoutæ¯”ç‡
        """
        super().__init__()
        
        assert len(channels) == len(kernel_sizes), "channelså’Œkernel_sizesé•¿åº¦å¿…é¡»ä¸€è‡´"
        
        layers = []
        in_channels = n_channels
        
        # æ„å»ºå·ç§¯å±‚
        for i, (out_channels, kernel_size) in enumerate(zip(channels, kernel_sizes)):
            padding = kernel_size // 2  # ä¿æŒæ—¶é—´ç»´åº¦ä¸å˜
            layers.append(nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding))
            
            if use_batchnorm:
                layers.append(nn.BatchNorm1d(out_channels))
            
            layers.append(nn.ReLU())
            
            # é™¤äº†æœ€åä¸€å±‚å¤–æ·»åŠ dropout
            if i < len(channels) - 1 and dropout_rate > 0:
                layers.append(nn.Dropout(dropout_rate))
            
            in_channels = out_channels
        
        self.conv_layers = nn.Sequential(*layers)
        
        # æ± åŒ–å±‚
        if pooling_type == 'avg':
            self.pool = nn.AdaptiveAvgPool1d(1)
        elif pooling_type == 'max':
            self.pool = nn.AdaptiveMaxPool1d(1)
        else:
            raise ValueError("pooling_typeå¿…é¡»æ˜¯ 'avg' æˆ– 'max'")
        
        # å…¨è¿æ¥å±‚
        self.fc = nn.Linear(channels[-1], n_classes)
        
    def forward(self, x):
        # x: (batch, time, channels) -> (batch, channels, time)
        x = x.permute(0, 2, 1)
        x = self.conv_layers(x)
        x = self.pool(x).squeeze(-1)
        x = self.fc(x)
        return x

# ---------------------------------------------------------
# 2. LSTM è§£ç å™¨ç±»
# ---------------------------------------------------------
class LSTM_ClassificationDecoder:

    def __init__(self,
                 input_dim,
                 num_classes,
                 hidden_dim=64,
                 num_layers=2,
                 lr=1e-3,
                 batch_size=64,
                 epochs=100,
                 device="cuda:0"):

        self.device = device
        self.batch_size = batch_size
        self.epochs = epochs

        # ç½‘ç»œ
        self.model = LSTMClassifier(
            input_dim=input_dim,
            hidden_dim=hidden_dim,
            num_layers=num_layers,
            num_classes=num_classes
        ).to(device)

        # self.model = CNNClassifier(
        #     n_channels=input_dim,
        #     n_classes=num_classes).to(device)

        self.loss_fn = nn.CrossEntropyLoss()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        self.best_state_dict = None
        self.best_val_acc = -1


    # -----------------------------------------------------
    # è®­ç»ƒï¼šä¿å­˜éªŒè¯é›†å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹æƒé‡
    # -----------------------------------------------------
    def fit(self, X, y):

        # ç¡®ä¿ numpy â†’ torch
        X = torch.tensor(X, dtype=torch.float32)
        y = torch.tensor(y, dtype=torch.long)

        # åˆ’åˆ†è®­ç»ƒä¸éªŒè¯
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.25, shuffle=True, stratify=y
        )

        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
        val_dataset = torch.utils.data.TensorDataset(X_val, y_val)

        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=self.batch_size)

        # ---------------- Training Loop ----------------
        for epoch in range(self.epochs):
            self.model.train()
            for xb, yb in train_loader:
                xb = xb.to(self.device)
                yb = yb.to(self.device)

                pred = self.model(xb)
                loss = self.loss_fn(pred, yb)

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            # ---------------- Validation ----------------
            val_acc = self.evaluate(val_loader)
            if val_acc > self.best_val_acc:
                self.best_val_acc = val_acc
                self.best_state_dict = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}

            print(f"Epoch {epoch+1}/{self.epochs}, Val ACC={val_acc:.4f}")

        print(f"\nğŸ”¥ Best Val ACC = {self.best_val_acc:.4f}\n")


    # -----------------------------------------------------
    # éªŒè¯å‡½æ•°
    # -----------------------------------------------------
    def evaluate(self, loader):
        self.model.eval()
        preds = []
        labels = []

        with torch.no_grad():
            for xb, yb in loader:
                xb = xb.to(self.device)
                out = self.model(xb)
                pred = out.argmax(dim=1).cpu().numpy()

                preds.append(pred)
                labels.append(yb.numpy())

        preds = np.concatenate(preds)
        labels = np.concatenate(labels)
        return accuracy_score(labels, preds)


    # -----------------------------------------------------
    # é¢„æµ‹ï¼šä½¿ç”¨è®­ç»ƒä¸­éªŒè¯é›†æœ€ä¼˜æƒé‡ best_state_dict
    # -----------------------------------------------------
    def predict(self, X_test):

        # åŠ è½½æœ€ä¼˜æ¨¡å‹
        if self.best_state_dict is not None:
            self.model.load_state_dict(self.best_state_dict)
        else:
            print("Warning: No best weights found! Did you run fit()?")

        X_test = torch.tensor(X_test, dtype=torch.float32).to(self.device)

        self.model.eval()
        with torch.no_grad():
            out = self.model(X_test)
            preds = out.argmax(dim=1).cpu().numpy()

        return preds
    
    # ======================================================
    # âœ” ä¸¥æ ¼æ¨¡å¼ build_model
    # ======================================================
    @staticmethod
    def build_model(model_params: dict):
    # def build_model(path: str):
        """
        Build LSTM_ClassificationDecoder from config dict.
        `input_dim` and `num_classes` are REQUIRED.
        """

        # with open(path, "r") as f:
        #     model_params = yaml.safe_load(f)

        # ---------- å¿…é¡»å‚æ•° ----------
        if "input_dim" not in model_params:
            raise KeyError(
                "[LSTM_ClassificationDecoder] Missing required parameter: `input_dim`"
            )

        if "num_classes" not in model_params and "output_dim" not in model_params:
            raise KeyError(
                "[LSTM_ClassificationDecoder] Missing required parameter: "
                "`num_classes` or `output_dim`"
            )

        # ç»Ÿä¸€ç±»åˆ«å‚æ•°å
        num_classes = (
            model_params["num_classes"]
            if "num_classes" in model_params
            else model_params["output_dim"]
        )

        # ---------- æ„å»ºæ¨¡å‹ ----------
        return LSTM_ClassificationDecoder(
            input_dim=int(model_params["input_dim"]),
            num_classes=int(num_classes),
            hidden_dim=int(model_params.get("hidden_dim", 64)),
            num_layers=int(model_params.get("num_layers", 2)),
            lr=float(model_params.get("lr", 1e-3)),
            batch_size=int(model_params.get("batch_size", 64)),
            epochs=int(model_params.get("epochs", 100)),
            device=model_params.get("device", "cuda:0"),
        )
    
    def save_weights(self, path):
         
         torch.save(self.best_state_dict, path)

    def load_weights(self, path):
        try:
            # åŠ è½½æƒé‡
            state_dict = torch.load(path, map_location=self.device)
            
            # åŠ è½½åˆ°æ¨¡å‹ä¸­
            self.model.load_state_dict(state_dict)
            
            # æ›´æ–° best_state_dict
            self.best_state_dict = state_dict
            
            print(f" æ¨¡å‹æƒé‡å·²ä» {path} åŠ è½½")
            
            
        except Exception as e:
            print(f" åŠ è½½æƒé‡å¤±è´¥: {e}")
    

# ---------------------------------------------------------
# 2. CNN è§£ç å™¨ç±»ï¼ˆç»“æ„ä»¿ç…§ä½ çš„ CEBRA + LRï¼‰
# ---------------------------------------------------------
class CNN_ClassificationDecoder:

    def __init__(self,
                 input_dim,
                 num_classes,
                 channels=[64, 128],
                 kernel_sizes=[5, 5],
                 lr=1e-3,
                 batch_size=64,
                 epochs=100,
                 device="cuda:0"):

        self.device = device
        self.batch_size = batch_size
        self.epochs = epochs

        # ç½‘ç»œ
        # self.model = LSTMClassifier(
        #     input_dim=input_dim,
        #     hidden_dim=hidden_dim,
        #     num_layers=num_layers,
        #     num_classes=num_classes
        # ).to(device)

        self.model = CNNClassifier(
            n_channels=input_dim,
            n_classes=num_classes,
            channels=channels,
            kernel_sizes=kernel_sizes).to(device)

        self.loss_fn = nn.CrossEntropyLoss()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        self.best_state_dict = None
        self.best_val_acc = -1


    # -----------------------------------------------------
    # è®­ç»ƒï¼šä¿å­˜éªŒè¯é›†å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹æƒé‡
    # -----------------------------------------------------
    def fit(self, X, y):

        # ç¡®ä¿ numpy â†’ torch
        X = torch.tensor(X, dtype=torch.float32)
        y = torch.tensor(y, dtype=torch.long)

        # åˆ’åˆ†è®­ç»ƒä¸éªŒè¯
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.25, shuffle=True, stratify=y
        )

        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
        val_dataset = torch.utils.data.TensorDataset(X_val, y_val)

        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=self.batch_size)

        # ---------------- Training Loop ----------------
        for epoch in range(self.epochs):
            self.model.train()
            for xb, yb in train_loader:
                xb = xb.to(self.device)
                yb = yb.to(self.device)

                pred = self.model(xb)
                loss = self.loss_fn(pred, yb)

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            # ---------------- Validation ----------------
            val_acc = self.evaluate(val_loader)
            if val_acc > self.best_val_acc:
                self.best_val_acc = val_acc
                self.best_state_dict = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}

            print(f"Epoch {epoch+1}/{self.epochs}, Val ACC={val_acc:.4f}")

        print(f"\nğŸ”¥ Best Val ACC = {self.best_val_acc:.4f}\n")


    # -----------------------------------------------------
    # éªŒè¯å‡½æ•°
    # -----------------------------------------------------
    def evaluate(self, loader):
        self.model.eval()
        preds = []
        labels = []

        with torch.no_grad():
            for xb, yb in loader:
                xb = xb.to(self.device)
                out = self.model(xb)
                pred = out.argmax(dim=1).cpu().numpy()

                preds.append(pred)
                labels.append(yb.numpy())

        preds = np.concatenate(preds)
        labels = np.concatenate(labels)
        return accuracy_score(labels, preds)


    # -----------------------------------------------------
    # é¢„æµ‹ï¼šä½¿ç”¨è®­ç»ƒä¸­éªŒè¯é›†æœ€ä¼˜æƒé‡ best_state_dict
    # -----------------------------------------------------
    def predict(self, X_test):

        # åŠ è½½æœ€ä¼˜æ¨¡å‹
        if self.best_state_dict is not None:
            self.model.load_state_dict(self.best_state_dict)
        else:
            print("Warning: No best weights found! Did you run fit()?")

        X_test = torch.tensor(X_test, dtype=torch.float32).to(self.device)

        self.model.eval()
        with torch.no_grad():
            out = self.model(X_test)
            preds = out.argmax(dim=1).cpu().numpy()

        return preds
    



import torch
import torch.nn as nn
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score


# -----------------------------
# LSTM ç½‘ç»œç»“æ„ï¼ˆå›å½’è¾“å‡ºï¼‰
# -----------------------------
class LSTMRegressor(nn.Module):
    def __init__(self, input_dim, hidden_dim=64, num_layers=1, output_dim=1):
        super().__init__()

        self.lstm = nn.LSTM(
            input_dim,
            hidden_dim,
            num_layers=num_layers,
            batch_first=True
        )

        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = out[:, -1, :]          # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        out = self.fc(out)
        return out
    
class CNN_Regressor(nn.Module):
    def __init__(self, n_channels, output_dim,
                 channels=[64, 128],
                 kernel_sizes=[5, 5],
                 use_batchnorm=True,
                 dropout_rate=0.5):
        """
        CNN ç”¨äºå›å½’ä»»åŠ¡ï¼ˆè¾“å‡ºè¿ç»­å€¼ï¼‰
        
        Args:
            n_channels: è¾“å…¥ä¿¡å·é€šé“æ•°
            output_dim: å›å½’è¾“å‡ºç»´åº¦ï¼Œä¾‹å¦‚ 2 (x, y)
        """
        super().__init__()
        
        assert len(channels) == len(kernel_sizes), "channels å’Œ kernel_sizes é•¿åº¦å¿…é¡»ä¸€è‡´"
        
        layers = []
        in_channels = n_channels
        
        for i, (out_channels, kernel_size) in enumerate(zip(channels, kernel_sizes)):
            padding = kernel_size // 2
            layers.append(nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding))
            
            if use_batchnorm:
                layers.append(nn.BatchNorm1d(out_channels))
            
            layers.append(nn.ReLU())
            
            if i < len(channels) - 1 and dropout_rate > 0:
                layers.append(nn.Dropout(dropout_rate))
            
            in_channels = out_channels
        
        self.conv_layers = nn.Sequential(*layers)
        
        # --- ä¿®æ”¹ä¸ºå›å½’ä»»åŠ¡ ---
        self.fc = nn.Linear(channels[-1], output_dim)
    
    def forward(self, x):
        # x: (batch, time, channels) -> (batch, channels, time)
        x = x.permute(0, 2, 1)
        x = self.conv_layers(x)

        # ä½¿ç”¨ CNN çš„æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾è¿›è¡Œå›å½’
        x_last = x[:, :, -1]  # (batch, channels[-1])
        out = self.fc(x_last)
        return out




# -----------------------------------------------------
# LSTM å›å½’è§£ç å™¨
# -----------------------------------------------------
class LSTM_RegressionDecoder:
    def __init__(
            self,
            input_dim,
            output_dim=1,
            hidden_dim=64,
            num_layers=1,
            batch_size=128,
            epochs=100,
            lr=1e-3,
            device="cuda:0"
    ):

        self.device = device
        self.batch_size = batch_size
        self.epochs = epochs

        # æ¨¡å‹
        self.model = LSTMRegressor(
            input_dim=input_dim,
            hidden_dim=hidden_dim,
            num_layers=num_layers,
            output_dim=output_dim
        ).to(device)

        # self.model = CNN_Regressor(n_channels=input_dim, output_dim=output_dim).to(device)

        # print(f"self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)", float(lr))


        # self.loss_fn = nn.MSELoss()
        self.loss_fn = nn.SmoothL1Loss()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)

        # self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)

        

        # ä¿å­˜æœ€ä½³æƒé‡
        self.best_state_dict = None
        self.best_val_r2 = -999


    # -----------------------------------------------------
    # è®­ç»ƒæµç¨‹ï¼šä¿å­˜éªŒè¯é›† RÂ² æœ€ä½³çš„å‚æ•°
    # -----------------------------------------------------
    def fit(self, X, y):

        
        # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        y = y[:, -1, :]   # (N, 2)

        X = torch.tensor(X, dtype=torch.float32)
        y = torch.tensor(y, dtype=torch.float32)

        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, shuffle=False
        )

        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
        val_dataset = torch.utils.data.TensorDataset(X_val, y_val)

        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=False)
        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=self.batch_size)

        # ---------------- Training Loop ----------------
        for epoch in range(self.epochs):
            self.model.train()

            for xb, yb in train_loader:
                xb = xb.to(self.device)
                yb = yb.to(self.device)

                pred = self.model(xb)
                loss = self.loss_fn(pred, yb)

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            # ---------------- Validation ----------------
            val_r2 = self.evaluate(val_loader)

            if val_r2 > self.best_val_r2:
                self.best_val_r2 = val_r2
                self.best_state_dict = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}

            print(f"Epoch {epoch+1}/{self.epochs}, Val R2 = {val_r2:.4f}")

        print(f"\n Best Validation R2 = {self.best_val_r2:.4f}\n")


    # -----------------------------------------------------
    # éªŒè¯å‡½æ•°ï¼šè¿”å› RÂ²
    # -----------------------------------------------------
    def evaluate(self, loader):
        self.model.eval()
        preds = []
        labels = []

        with torch.no_grad():
            for xb, yb in loader:
                xb = xb.to(self.device)
                out = self.model(xb).cpu().numpy()

                preds.append(out)
                labels.append(yb.numpy())

        preds = np.concatenate(preds).squeeze()
        labels = np.concatenate(labels).squeeze()

        return r2_score(labels, preds)


    # -----------------------------------------------------
    # é¢„æµ‹ï¼šä½¿ç”¨è®­ç»ƒä¸­éªŒè¯é›† RÂ² æœ€å¥½æ—¶çš„æƒé‡
    # -----------------------------------------------------
    def predict(self, X_test):

        if self.best_state_dict is not None:
            self.model.load_state_dict(self.best_state_dict)
        else:
            print("Warning: No best weights stored, did you run fit()?")

        X_test = torch.tensor(X_test, dtype=torch.float32).to(self.device)

        self.model.eval()
        with torch.no_grad():
            out = self.model(X_test)

        return out.cpu().numpy().squeeze()
    
    def save_weights(self, path):
         
         torch.save(self.best_state_dict, path)

    def load_weights(self, path):
        try:
            # åŠ è½½æƒé‡
            state_dict = torch.load(path, map_location=self.device)
            
            # åŠ è½½åˆ°æ¨¡å‹ä¸­
            self.model.load_state_dict(state_dict)
            
            # æ›´æ–° best_state_dict
            self.best_state_dict = state_dict
            
            print(f" æ¨¡å‹æƒé‡å·²ä» {path} åŠ è½½")
            
            
        except Exception as e:
            print(f" åŠ è½½æƒé‡å¤±è´¥: {e}")

    # ======================================================
    # âœ” ä¸¥æ ¼æ¨¡å¼ build_model
    # ======================================================
    @staticmethod
    def build_model(model_params: dict, path=None):
    # def build_model(path: str):
        """
        Build LSTM_ClassificationDecoder from config dict.
        `input_dim` and `num_classes` are REQUIRED.
        """

        # with open(path, "r") as f:
        #     model_params = yaml.safe_load(f)

        # ---------- å¿…é¡»å‚æ•° ----------
        if "input_dim" not in model_params:
            raise KeyError(
                "[LSTM_ClassificationDecoder] Missing required parameter: `input_dim`"
            )

        if "num_classes" not in model_params and "output_dim" not in model_params:
            raise KeyError(
                "[LSTM_ClassificationDecoder] Missing required parameter: "
                "`num_classes` or `output_dim`"
            )

        # ç»Ÿä¸€ç±»åˆ«å‚æ•°å
        num_classes = (
            model_params["num_classes"]
            if "num_classes" in model_params
            else model_params["output_dim"]
        )

        # ---------- æ„å»ºæ¨¡å‹ ----------
        return LSTM_RegressionDecoder(
            input_dim=int(model_params["input_dim"]),
            output_dim=int(num_classes),
            hidden_dim=int(model_params.get("hidden_dim", 64)),
            num_layers=int(model_params.get("num_layers", 2)),
            lr=float(model_params.get("lr", 1e-3)),
            batch_size=int(model_params.get("batch_size", 64)),
            epochs=int(model_params.get("epochs", 100)),
            device=model_params.get("device", "cuda:0"),
        )
    

            
    

# -----------------------------------------------------
# CNN å›å½’è§£ç å™¨
# -----------------------------------------------------
class CNN_RegressionDecoder:
    def __init__(
            self,
            input_dim,
            output_dim=1,
            channels=[64, 128],
            kernel_sizes=[5,5],
            batch_size=128,
            epochs=100,
            lr=1e-3,
            device="cuda:0"
    ):

        self.device = device
        self.batch_size = batch_size
        self.epochs = epochs

        # æ¨¡å‹
        # self.model = LSTMRegressor(
        #     input_dim=input_dim,
        #     hidden_dim=hidden_dim,
        #     num_layers=num_layers,
        #     output_dim=output_dim
        # ).to(device)

        self.model = CNN_Regressor(n_channels=input_dim, output_dim=output_dim, channels=channels, kernel_sizes=kernel_sizes).to(device)


        # self.loss_fn = nn.MSELoss()
        self.loss_fn = nn.SmoothL1Loss()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)

        # ä¿å­˜æœ€ä½³æƒé‡
        self.best_state_dict = None
        self.best_val_r2 = -999


    # -----------------------------------------------------
    # è®­ç»ƒæµç¨‹ï¼šä¿å­˜éªŒè¯é›† RÂ² æœ€ä½³çš„å‚æ•°
    # -----------------------------------------------------
    def fit(self, X, y):

        
        # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        y = y[:, -1, :]   # (N, 2)

        X = torch.tensor(X, dtype=torch.float32)
        y = torch.tensor(y, dtype=torch.float32)

        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, shuffle=False
        )

        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
        val_dataset = torch.utils.data.TensorDataset(X_val, y_val)

        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=False)
        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=self.batch_size)

        # ---------------- Training Loop ----------------
        for epoch in range(self.epochs):
            self.model.train()

            for xb, yb in train_loader:
                xb = xb.to(self.device)
                yb = yb.to(self.device)

                pred = self.model(xb)
                loss = self.loss_fn(pred, yb)

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            # ---------------- Validation ----------------
            val_r2 = self.evaluate(val_loader)

            if val_r2 > self.best_val_r2:
                self.best_val_r2 = val_r2
                self.best_state_dict = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}

            print(f"Epoch {epoch+1}/{self.epochs}, Val R2 = {val_r2:.4f}")

        print(f"\nğŸ”¥ Best Validation R2 = {self.best_val_r2:.4f}\n")


    # -----------------------------------------------------
    # éªŒè¯å‡½æ•°ï¼šè¿”å› RÂ²
    # -----------------------------------------------------
    def evaluate(self, loader):
        self.model.eval()
        preds = []
        labels = []

        with torch.no_grad():
            for xb, yb in loader:
                xb = xb.to(self.device)
                out = self.model(xb).cpu().numpy()

                preds.append(out)
                labels.append(yb.numpy())

        preds = np.concatenate(preds).squeeze()
        labels = np.concatenate(labels).squeeze()

        return r2_score(labels, preds)


    # -----------------------------------------------------
    # é¢„æµ‹ï¼šä½¿ç”¨è®­ç»ƒä¸­éªŒè¯é›† RÂ² æœ€å¥½æ—¶çš„æƒé‡
    # -----------------------------------------------------
    def predict(self, X_test):

        if self.best_state_dict is not None:
            self.model.load_state_dict(self.best_state_dict)
        else:
            print("âš ï¸ Warning: No best weights stored, did you run fit()?")

        X_test = torch.tensor(X_test, dtype=torch.float32).to(self.device)

        self.model.eval()
        with torch.no_grad():
            out = self.model(X_test)

        return out.cpu().numpy().squeeze()


    
import numpy as np

def generate_regression_mock_data(N=2000, seq_len=50, x_dim=16):
    """
    æ¨¡æ‹Ÿ LSTM å›å½’ä»»åŠ¡çš„æ•°æ®ï¼š
    X: (N, 50, x_dim)
    y: (N, 50, 2)
    
    y çš„è§„åˆ™ä¸ºï¼š
    y[t] = [ sum(X[t]), mean(X[t]) ] + noise
    """
    X = np.random.randn(N, seq_len, x_dim).astype(np.float32)

    y = np.zeros((N, seq_len, 2), dtype=np.float32)
    for i in range(N):
        for t in range(seq_len):
            s = X[i, t].sum()
            m = X[i, t].mean()
            y[i, t, 0] = s + 0.1*np.random.randn()       # ç¬¬1ä¸ªè¾“å‡º
            y[i, t, 1] = m + 0.1*np.random.randn()       # ç¬¬2ä¸ªè¾“å‡º

    return X, y

import numpy as np

def generate_synthetic_classification_data(
        N=1000,     # æ ·æœ¬æ•°é‡
        T=50,       # æ—¶é—´æ­¥
        C=16,       # é€šé“æ•°
        num_classes=3,  # åˆ†ç±»ç±»åˆ«
        noise_level=0.1 # å™ªå£°æ°´å¹³
    ):
    """
    ç”Ÿæˆ EEG é£æ ¼çš„åˆ†ç±»æ¨¡æ‹Ÿæ•°æ® X, y
    X shape = (N, T, C)
    y shape = (N,)
    """
    X = np.zeros((N, T, C), dtype=np.float32)
    y = np.zeros((N,), dtype=np.int64)

    for i in range(N):
        label = np.random.randint(0, num_classes)
        y[i] = label

        # -------- ä¸åŒç±»åˆ«å…·æœ‰ä¸åŒçš„é¢‘ç‡æ¨¡å¼ --------
        freq = 1 + label   # ç±»åˆ« 0 â†’ 1Hz, ç±»åˆ« 1 â†’ 2Hz, ç±»åˆ« 2 â†’ 3Hz

        t = np.linspace(0, 1, T)

        # æ¯ä¸ªé€šé“éƒ½æœ‰è½»å¾®å˜åŒ–
        signal = np.sin(2 * np.pi * freq * t)[..., None]  # (T, 1)
        signal = np.repeat(signal, C, axis=1)

        # åŠ ä¸€äº›éšæœºçš„æƒé‡æ‰°åŠ¨
        signal *= (1 + 0.1 * np.random.randn(C))

        # æ·»åŠ å™ªå£°
        noise = noise_level * np.random.randn(T, C)

        X[i] = signal + noise

    return X, y






if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    # X_dummy = np.random.rand(1000, 10, 16)  # (samples, time_steps, features)
    # y_dummy = np.random.randint(0, 5, size=(1000,))  # 5 classes

    # æµ‹è¯•ä¸€ä¸‹
    X, y = generate_synthetic_classification_data()
    print("X shape:", X.shape)
    print("y shape:", y.shape)
    print("Class distribution:", np.bincount(y))

    decoder = LSTM_ClassificationDecoder(
        input_dim=16,
        num_classes=3,
        hidden_dim=32,
        num_layers=1,
        lr=1e-3,
        batch_size=32,
        epochs=10,
        device="cuda:0"
    )

    decoder.fit(X[:800,:,:], y[:800])
    preds = decoder.predict(X[800:,:,:])

    acc = accuracy_score(y[800:], preds)
    print(f"Test Accuracy: {acc:.4f}")




    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    X, y = generate_regression_mock_data(N=2000, seq_len=50, x_dim=16)

    decoder = LSTM_RegressionDecoder(
        input_dim=16,
        output_dim=2,
        device="cuda:0"
    )



    decoder.fit(X, y)

    # é¢„æµ‹æœ€åä¸€ä¸ªæ—¶é—´æ­¥
    y_pred = decoder.predict(X[:10])
    print("Pred:", y_pred.shape)






