# Benchmarks

## Quality and performance evaluations
Summarize the model’s performance across public and internal benchmarks and describe how it compares to other third-party models. Include the types of benchmarks used, grouped by capability areas (reasoning, language understanding, math, multilingual, etc.) and limitations (knowledge capacity, etc.). Include specific datasets and tasks that demonstrate the model’s performance across diverse domains, highlight any custom or adversarial evaluations, and note any planned mitigations

## Benchmarking methodology
Share additional details about your team’s benchmarking methodology, including how prompts are standardized across models for fair comparison. Note any exceptions and clarify what is and isn’t allowed when adapting prompts. If needed, organize the appendix (A, B, C, etc.) based on specific benchmarks such as robustness, short & long context, multilingual, etc.

## Public data summary
Link to the relevant public data summary or summaries for this model
