# Responsible AI considerations

## Safety techniques
Policies, techniques and safety frameworks applied to enable model hosting on Foundry (i.e. Provenance). 

Describe the safety alignment strategy used during post-training. Include the types of datasets leveraged, specify the techniques applied along with the safety objectives they target.

## Safety evaluations
Describe the evaluation methods used to assess model safety prior to release. Include both quantitative and qualitive approaches and specify the risk categories evaluated [i.e.  disallowed content (sexual, violent, hateful, or self-harm content), copyright content/IP, and jailbreaks] and any collaboration with internal or external safety teams. Refer to other relevant documentation for more details.

## Known limitations
Outline known limitations and potential risks associated with the model, including fairness, representation, offensive content, reliability, and misuse. Clearly state areas where the model may underperform (non-English languages, sensitive domains, etc.). Provide specific guidance for developers on applying responsible AI practices, legal compliance, and appropriate safeguards for high-risk or consequential use cases.

# Acceptable use

## Acceptable use policy
Link to any relevant acceptable use policies. Otherwise state N/A.

# Terms of Service

## Terms of Service Link
Type or category of license (e.g. free/open source or proprietary). If there is no license, describe how access to the model is provided. State the license.