Metadata-Version: 2.4
Name: dagoptimizer
Version: 1.0.0
Summary: Advanced DAG optimization library with adaptive transitive reduction, PERT/CPM analysis, and 25+ research-grade metrics
Home-page: https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs
Author: Sahil Shrivastava
Author-email: Sahil Shrivastava <sahilshrivastava28@gmail.com>
Maintainer-email: Sahil Shrivastava <sahilshrivastava28@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs
Project-URL: Documentation, https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs/wiki
Project-URL: Repository, https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs
Project-URL: Bug Tracker, https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs/issues
Project-URL: Demo Application, https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs#demo-application
Keywords: dag,graph,optimization,transitive-reduction,pert,cpm,critical-path,networkx,directed-acyclic-graph,graph-algorithms,workflow-optimization
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: networkx>=2.6
Requires-Dist: numpy>=1.20
Requires-Dist: scipy>=1.7
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: flake8>=5.0.0; extra == "dev"
Requires-Dist: mypy>=0.990; extra == "dev"
Provides-Extra: neo4j
Requires-Dist: neo4j>=5.0.0; extra == "neo4j"
Provides-Extra: visualization
Requires-Dist: matplotlib>=3.5.0; extra == "visualization"
Requires-Dist: pygraphviz>=1.10; extra == "visualization"
Provides-Extra: ai
Requires-Dist: openai>=1.0.0; extra == "ai"
Requires-Dist: anthropic>=0.5.0; extra == "ai"
Provides-Extra: all
Requires-Dist: dagoptimizer[ai,dev,neo4j,visualization]; extra == "all"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# üì¶ DAG Optimizer - Advanced Python Library for DAG Optimization

<div align="center">

**A Production-Ready Python Library for Directed Acyclic Graph Optimization**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyPI version](https://img.shields.io/badge/pypi-v1.0.0-blue)](https://pypi.org/project/dagoptimizer/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Research Paper](https://img.shields.io/badge/research-paper-green.svg)](Research%20Papers/)

**[Quick Start](#-quick-start)** ‚Ä¢ **[Installation](#-installation)** ‚Ä¢ **[Features](#-features)** ‚Ä¢ **[Demo App](#-interactive-demo-application)** ‚Ä¢ **[Research](#-research-paper)** ‚Ä¢ **[Documentation](#-documentation)**

</div>

---

## üéØ What is DAG Optimizer?

**DAG Optimizer** is an open-source Python library that provides state-of-the-art algorithms for optimizing Directed Acyclic Graphs (DAGs). Built on rigorous research and validated on 995 real-world test cases, it offers:

- **42.9% average edge reduction** while preserving 100% reachability
- **Adaptive transitive reduction** (DFS for sparse, Floyd-Warshall for dense)
- **PERT/CPM critical path analysis** for scheduling optimization
- **25+ research-grade metrics** for comprehensive graph analysis
- **Production-ready** with type hints, comprehensive tests, and documentation

### Why DAG Optimizer?

| Problem | DAG Optimizer Solution |
|---------|----------------------|
| **Redundant dependencies** slow down builds | ‚úÖ Remove 40-87% of redundant edges |
| **Can't identify bottlenecks** in workflows | ‚úÖ PERT/CPM analysis finds critical paths |
| **Don't know parallelism potential** | ‚úÖ Layer analysis shows optimal concurrency |
| **One-size-fits-all** algorithms are slow | ‚úÖ Adaptive selection: sparse or dense algorithms |
| **Hard to understand** graph complexity | ‚úÖ 25+ metrics with mathematical explanations |

---

## üöÄ Quick Start

### Installation

```bash
pip install dagoptimizer
```

### Basic Usage

```python
from dagoptimizer import DAGOptimizer

# Define your DAG (e.g., build dependencies)
edges = [
    ('compile', 'link'),
    ('compile', 'test'),
    ('link', 'test'),      # Redundant! test already depends on compile
    ('test', 'deploy')
]

# Optimize
optimizer = DAGOptimizer(edges)
optimizer.transitive_reduction()

# Results
print(f"‚úÖ Reduced from {optimizer.original_graph.number_of_edges()} to {optimizer.graph.number_of_edges()} edges")
# Output: ‚úÖ Reduced from 4 to 3 edges

# Get optimized edges
print(f"Optimized edges: {list(optimizer.graph.edges())}")
# Output: [('compile', 'link'), ('compile', 'test'), ('test', 'deploy')]
```

### Advanced Usage

```python
from dagoptimizer import DAGOptimizer

edges = [('A', 'B'), ('B', 'C'), ('C', 'D'), ('A', 'C'), ('B', 'D'), ('A', 'D')]

optimizer = DAGOptimizer(edges)
optimizer.transitive_reduction()

# PERT/CPM Critical Path Analysis
critical_path = optimizer.compute_critical_path_with_slack(optimizer.graph)
print(f"Critical Path: {critical_path['critical_path']}")
print(f"Makespan: {critical_path['makespan']} time units")
print(f"Parallel Time Saved: {critical_path['parallel_time_saved']:.1%}")

# Layer Analysis (Parallelism Potential)
layers = optimizer.compute_layer_structure(optimizer.graph)
print(f"Max Parallel Tasks: {layers['width']}")
print(f"Min Execution Depth: {layers['depth']}")
print(f"Speedup Potential: {len(edges) / layers['depth']:.1f}√ó")

# Edge Criticality (Which edges are critical?)
criticality = optimizer.compute_edge_criticality(optimizer.graph)
print(f"Critical Edges: {len(criticality['critical_edges'])}")
print(f"Redundant Edges Removed: {len(criticality['redundant_edges'])}")

# Comprehensive Metrics
metrics = optimizer.evaluate_graph_metrics(optimizer.graph)
print(f"Efficiency Score: {metrics['efficiency_score']:.1%}")
print(f"Redundancy Ratio: {metrics['redundancy_ratio']:.1%}")
print(f"Graph Density: {metrics['density']:.3f}")
```

---

## üìã Table of Contents

- [Installation](#-installation)
- [Features](#-features)
- [Real-World Use Cases](#-real-world-use-cases)
- [Benchmark Results](#-benchmark-results)
- [Interactive Demo Application](#-interactive-demo-application)
- [API Reference](#-api-reference)
- [Research Paper](#-research-paper)
- [Contributing](#-contributing)
- [License](#-license)

---

## üì¶ Installation

### Basic Installation

```bash
pip install dagoptimizer
```

### With Optional Dependencies

```bash
# For Neo4j database integration
pip install dagoptimizer[neo4j]

# For visualization (matplotlib, pygraphviz)
pip install dagoptimizer[visualization]

# For AI-powered features (OpenAI, Anthropic)
pip install dagoptimizer[ai]

# Install everything
pip install dagoptimizer[all]
```

### Development Installation

```bash
git clone https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs.git
cd Optimisation_of_DAGs
pip install -e ".[dev]"
```

### Requirements

- Python >= 3.8
- NetworkX >= 2.6
- NumPy >= 1.20
- SciPy >= 1.7

---

## ‚ú® Features

### üß† Core Optimization Algorithms

#### 1. **Adaptive Transitive Reduction**
Automatically selects the best algorithm based on graph density:

```python
optimizer = DAGOptimizer(edges)
optimizer.transitive_reduction()
print(optimizer.optimization_method)
# Output: "DFS-based TR (sparse graph)" or "Floyd-Warshall TR (dense graph)"
```

- **Sparse graphs (density < 0.1)**: DFS-based, O(n¬∑m)
- **Dense graphs (density ‚â• 0.1)**: Floyd-Warshall, O(n¬≥)
- **Result**: 42.9% average reduction, up to 86.9% for dense graphs

#### 2. **Node Equivalence Merging** (Optional)
Merge nodes with identical predecessors and successors:

```python
optimizer = DAGOptimizer(edges)
optimizer.transitive_reduction()
optimizer.merge_equivalent_nodes()  # Optional
```

#### 3. **PERT/CPM Critical Path Analysis**
Identify bottlenecks and optimize scheduling:

```python
cp = optimizer.compute_critical_path_with_slack(optimizer.graph)

# Results include:
# - critical_path: List of nodes on critical path
# - makespan: Total execution time
# - est: Earliest Start Time for each task
# - lst: Latest Start Time for each task
# - slack: Slack time (LST - EST) for each task
# - parallel_time_saved: Percentage time saved through parallelization
```

**Use Case**: Task scheduling, CI/CD pipeline optimization

#### 4. **Layer-Based Parallelism Analysis**
Calculate optimal parallel execution strategy:

```python
layers = optimizer.compute_layer_structure(optimizer.graph)

# Results include:
# - layers: Dict mapping layer number to nodes in that layer
# - width: Maximum layer width (max parallel tasks)
# - depth: Number of layers (min execution time)
# - avg_layer_size: Average tasks per layer
# - width_efficiency: How efficiently parallelism is used
```

**Use Case**: Build systems, workflow orchestration

#### 5. **Edge Criticality Classification**
Distinguish critical edges from redundant ones:

```python
criticality = optimizer.compute_edge_criticality(optimizer.graph)

# Results include:
# - critical_edges: Edges that cannot be removed
# - redundant_edges: Edges that were transitive
# - edge_criticality_scores: Score per edge (1.0 = critical, 0.0 = redundant)
# - avg_criticality: Average criticality ratio
```

**Use Case**: Dependency analysis, refactoring

### üìä Research-Grade Metrics (25+)

Get comprehensive analysis with a single method:

```python
metrics = optimizer.evaluate_graph_metrics(optimizer.graph)
```

**Available Metrics**:

| Category | Metrics | Description |
|----------|---------|-------------|
| **Basic** | nodes, edges, density, leaf_nodes | Fundamental graph properties |
| **Path Analysis** | longest_path, shortest_path, avg_path_length, diameter | Path-based measurements |
| **Structural** | topological_complexity, degree_distribution, degree_entropy | Complexity analysis |
| **Efficiency** | efficiency_score, redundancy_ratio, compactness_score | Optimization quality |
| **Critical Path** | critical_path_length, bottleneck_nodes, makespan | Scheduling analysis |
| **Parallelism** | max_width, depth, width_efficiency | Concurrency potential |
| **Advanced** | strongly_connected_components, transitivity | Graph theory metrics |

---

## üåç Real-World Use Cases

### 1. **Build System Optimization**
```python
# Example: Maven/Gradle build dependencies
build_deps = [
    ('checkout', 'compile'),
    ('compile', 'test'),
    ('compile', 'package'),
    ('test', 'deploy'),
    ('package', 'deploy'),
    ('checkout', 'test'),      # Redundant!
    ('checkout', 'package'),   # Redundant!
    ('checkout', 'deploy'),    # Redundant!
]

optimizer = DAGOptimizer(build_deps)
optimizer.transitive_reduction()
# Reduced from 8 to 5 edges (37.5% reduction)

# Find critical path
cp = optimizer.compute_critical_path_with_slack(optimizer.graph)
print(f"Critical: {cp['critical_path']}")
# Output: ['checkout', 'compile', 'test', 'deploy']
```

### 2. **CI/CD Pipeline Analysis**
```python
# GitHub Actions / Jenkins pipeline
pipeline = [
    ('lint', 'unit_tests'),
    ('lint', 'integration_tests'),
    ('unit_tests', 'build'),
    ('integration_tests', 'build'),
    ('build', 'deploy_staging'),
    ('deploy_staging', 'e2e_tests'),
    ('e2e_tests', 'deploy_prod'),
]

optimizer = DAGOptimizer(pipeline)
layers = optimizer.compute_layer_structure(optimizer.graph)

print(f"Max parallel jobs: {layers['width']}")
print(f"Min pipeline depth: {layers['depth']}")
# Optimize GitHub Actions to run tests in parallel!
```

### 3. **Data Pipeline Optimization**
```python
# Apache Airflow / Prefect workflow
data_pipeline = [
    ('extract_db', 'transform_users'),
    ('extract_db', 'transform_orders'),
    ('extract_api', 'transform_events'),
    ('transform_users', 'join_data'),
    ('transform_orders', 'join_data'),
    ('transform_events', 'join_data'),
    ('join_data', 'load_warehouse'),
]

optimizer = DAGOptimizer(data_pipeline)
optimizer.transitive_reduction()

# Analyze parallelism
layers = optimizer.compute_layer_structure(optimizer.graph)
for layer_num, tasks in layers['layers'].items():
    print(f"Layer {layer_num}: {len(tasks)} tasks can run in parallel")
```

### 4. **Package Dependency Analysis**
```python
# npm / pip / cargo dependencies
packages = [
    ('lodash', 'app'),
    ('react', 'app'),
    ('react', 'react-dom'),
    ('react-dom', 'app'),
    # Many transitive dependencies...
]

optimizer = DAGOptimizer(packages)
optimizer.transitive_reduction()

metrics = optimizer.evaluate_graph_metrics(optimizer.graph)
print(f"Dependency efficiency: {metrics['efficiency_score']:.1%}")
print(f"Redundant dependencies: {metrics['redundancy_ratio']:.1%}")
```

---

## üìä Benchmark Results

Validated on **995 synthetic DAGs** (10-500 nodes, 7 density categories):

| Graph Type | Test Cases | Avg Reduction | Best Result | Real-World Example |
|------------|-----------|---------------|-------------|-------------------|
| **Sparse Small** | 195 | 1.2% | 5% | Simple workflows |
| **Sparse Medium** | 200 | 12.0% | 20% | CI/CD pipelines |
| **Sparse Large** | 100 | 16.5% | 25% | Large codebases |
| **Medium Small** | 150 | 40.5% | 55% | Task graphs |
| **Medium Medium** | 150 | 75.2% | 82% | Build systems |
| **Dense Small** | 100 | 68.0% | 75% | Complex workflows |
| **Dense Medium** | 100 | **86.9%** üèÜ | 90% | Highly connected systems |
| **Overall** | **995** | **42.9%** | **86.9%** | **All use cases** |

**Key Findings**:
- ‚úÖ **99.5% success rate** across all test cases
- ‚úÖ **68-87% reduction** for dense graphs (build systems, complex workflows)
- ‚úÖ **40-75% reduction** for medium graphs (CI/CD, task scheduling)
- ‚úÖ **10-25% reduction** even for sparse graphs
- ‚úÖ **25.6√ó overhead** for comprehensive analysis (5√ó features at ~17ms/feature)

---

## üé® Streamlit Demo Application (Optional)

To help you **understand how the optimization works visually**, we've included a simple Streamlit demo application:

### Demo Features

- **üì§ Multiple Input Methods**: CSV upload, text input, random generation, or ML workflow templates
- **üéØ Real-Time Optimization**: See the graph transform with adaptive algorithm selection
- **üìä Side-by-Side Visualization**: Compare original vs optimized graphs
- **üìà Comprehensive Metrics**: View all 25+ research-grade metrics with explanations
- **üî¨ Advanced Analysis**: PERT/CPM critical path, layer analysis, edge criticality
- **üìÑ Export Options**: Download metrics (Markdown), graphs (CSV/JSON), visualizations (PNG)
- **ü§ñ ML Examples**: Pre-built templates for ML pipelines, LangGraph, distributed training
- **üóÑÔ∏è Neo4j Export**: Push graphs to Neo4j for advanced querying

### Running the Demo

```bash
# 1. Clone the repository
git clone https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs.git
cd Optimisation_of_DAGs

# 2. Install library in editable mode
pip install -e .

# 3. Install demo dependencies
pip install -r requirements-demo.txt

# 4. Run Streamlit app
streamlit run app.py

# 5. Open browser
# Streamlit will automatically open http://localhost:8501
```

**Note**: The demo application is for **demonstration and educational purposes**. For production use, install the library with `pip install dagoptimizer` and use it directly in your code (see [Quick Start](#-quick-start)).

### Demo Highlights

The Streamlit app provides an intuitive interface to:
- **Load DAGs**: Upload CSV/Excel files, paste edge lists, generate random DAGs, or use ML workflow templates
- **Visualize**: See before/after graph visualizations with hierarchical layouts
- **Optimize**: Apply transitive reduction and node merging with one click
- **Analyze**: View PERT/CPM critical paths, parallelism layers, and edge criticality
- **Export**: Download comprehensive reports and optimized graphs in multiple formats

---

## üìö API Reference

### `DAGOptimizer` Class

#### Constructor

```python
DAGOptimizer(edges, edge_attrs=None)
```

**Parameters**:
- `edges` (list): List of (u, v) tuples representing directed edges
- `edge_attrs` (dict, optional): Mapping of edges to attributes

**Raises**:
- `ValueError`: If the input graph contains cycles (not a DAG)

#### Methods

##### `transitive_reduction()`
Apply adaptive transitive reduction.

```python
optimizer.transitive_reduction()
```

**Returns**: None (modifies `optimizer.graph` in-place)

##### `merge_equivalent_nodes()`
Merge nodes with identical predecessors and successors.

```python
optimizer.merge_equivalent_nodes()
```

**Returns**: None (modifies `optimizer.graph` in-place)

##### `compute_critical_path_with_slack(G)`
Compute PERT/CPM critical path analysis.

```python
result = optimizer.compute_critical_path_with_slack(optimizer.graph)
```

**Returns**: Dictionary containing:
- `critical_path`: List of nodes on critical path
- `makespan`: Total execution time
- `est`: Dict of Earliest Start Times
- `lst`: Dict of Latest Start Times
- `slack`: Dict of slack times per node
- `parallel_time_saved`: Percentage time saved through parallelization

##### `compute_layer_structure(G)`
Compute layer-based structure for parallelism analysis.

```python
result = optimizer.compute_layer_structure(optimizer.graph)
```

**Returns**: Dictionary containing:
- `layers`: Dict mapping layer number to list of nodes
- `width`: Maximum layer width
- `depth`: Number of layers
- `avg_layer_size`: Average nodes per layer
- `width_efficiency`: Parallelism efficiency ratio

##### `compute_edge_criticality(G)`
Classify edges as critical or redundant.

```python
result = optimizer.compute_edge_criticality(optimizer.graph)
```

**Returns**: Dictionary containing:
- `critical_edges`: List of critical edges (cannot be removed)
- `redundant_edges`: List of redundant edges (removed by TR)
- `edge_criticality_scores`: Dict mapping edge string to score (0-1)
- `avg_criticality`: Average criticality across all edges

##### `evaluate_graph_metrics(G)`
Compute 25+ comprehensive graph metrics.

```python
metrics = optimizer.evaluate_graph_metrics(optimizer.graph)
```

**Returns**: Dictionary containing all metrics (see [Features](#-features) section)

### Convenience Function

```python
from dagoptimizer import optimize_dag

optimizer = optimize_dag(edges, transitive_reduction=True, merge_nodes=False)
```

Quick optimization function with sensible defaults.

---

## üìñ Research Paper

This library is backed by rigorous research:

**Title**: "Adaptive Algorithms for DAG Optimization: A Density-Aware Approach"  
**Author**: Sahil Shrivastava (Independent Researcher)  
**Email**: sahilshrivastava28@gmail.com

### Key Contributions

1. **Adaptive Algorithm Selection**: First library to dynamically select transitive reduction algorithm based on graph density
2. **Comprehensive Metrics Suite**: 25+ research-grade metrics beyond basic NetworkX functionality
3. **PERT/CPM Integration**: Critical path analysis integrated with graph optimization
4. **Validated Results**: 995 test cases with statistical significance (p < 0.001, R¬≤ = 0.92)
5. **Production-Ready**: Type hints, comprehensive tests, and documentation

### Read the Full Paper

- **Paper**: [Research Papers/DAG_Optimization_Sahil_Shrivastava_UPDATED.docx](Research%20Papers/)
- **Wiki**: [GitHub Wiki](https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs/wiki)
- **Benchmark Data**: [docs/BENCHMARK_SUMMARY.md](docs/BENCHMARK_SUMMARY.md)

### Citation

If you use this library in your research, please cite:

```bibtex
@software{shrivastava2025dagoptimizer,
  author = {Shrivastava, Sahil},
  title = {DAG Optimizer: Adaptive Algorithms for Directed Acyclic Graph Optimization},
  year = {2025},
  url = {https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs},
  version = {1.0.0}
}
```

---

## üìö Documentation

- **[Quick Start](docs/QUICK_START.md)**: 5-minute setup guide
- **[API Reference](#-api-reference)**: Complete API documentation (above)
- **[Research Features](docs/RESEARCH_FEATURES_SUMMARY.md)**: Deep dive into advanced features
- **[Benchmark Results](docs/BENCHMARK_SUMMARY.md)**: Full 995-DAG benchmark data
- **[Contributing](CONTRIBUTING.md)**: How to contribute to the project
- **[Changelog](CHANGELOG.md)**: Version history and updates
- **[GitHub Wiki](https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs/wiki)**: Comprehensive guides and tutorials

---

## ü§ù Contributing

We welcome contributions from the community! Whether it's:

- üêõ **Bug reports** and feature requests
- üìù **Documentation** improvements
- üîß **Code contributions** (new features, optimizations, tests)
- üí° **Use cases** and examples
- ‚≠ê **Starring** the repository

Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Clone the repository
git clone https://github.com/SahilShrivastava-Dev/Optimisation_of_DAGs.git
cd Optimisation_of_DAGs

# Install development dependencies
pip install -e ".[dev]"

# Run tests
pytest

# Run linting
black src/
flake8 src/
mypy src/
```

---

## üìÑ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

You are free to:
- ‚úÖ Use commercially
- ‚úÖ Modify
- ‚úÖ Distribute
- ‚úÖ Use privately

Under the conditions of:
- üìù Include the license and copyright notice

---

## üôè Acknowledgments

- **NetworkX**: Core graph algorithms and data structures
- **Research Papers**: Aho, Garey, Ullman (1972) - Transitive Reduction algorithms
- **Community**: All contributors and users who provide feedback

---

## üìß Contact

**Sahil Shrivastava**  
üìß Email: sahilshrivastava28@gmail.com  
üêô GitHub: [@SahilShrivastava-Dev](https://github.com/SahilShrivastava-Dev)  
üîó LinkedIn: [Sahil Shrivastava](https://www.linkedin.com/in/sahil-shrivastava/)

---

## ‚≠ê Star History

If you find this library useful, please consider starring the repository!

[![Star History Chart](https://api.star-history.com/svg?repos=SahilShrivastava-Dev/Optimisation_of_DAGs&type=Date)](https://star-history.com/#SahilShrivastava-Dev/Optimisation_of_DAGs&Date)

---

<div align="center">

**Made with ‚ù§Ô∏è by [Sahil Shrivastava](https://github.com/SahilShrivastava-Dev)**

**[‚¨Ü Back to Top](#-dag-optimizer---advanced-python-library-for-dag-optimization)**

</div>
