# loreley.config

Centralised configuration for the Loreley application, backed by `pydantic-settings` and environment variables.

## Settings

- **`Settings`**: `BaseSettings` subclass that loads core application configuration.
  - **Environment**: `app_name`, `environment`, `log_level`, `logs_base_dir`. `log_level` controls the global Loguru log level used across long-running processes (including the scheduler, workers, and their CLI wrappers); `logs_base_dir` (via `LOGS_BASE_DIR`) optionally overrides the base directory where long-running process logs are written, defaulting to a `logs/` directory under the current working directory. See the scripts documentation under `docs/script` for concrete examples.
  - **OpenAI-compatible API**: `OPENAI_API_KEY`, `OPENAI_BASE_URL`, `OPENAI_API_SPEC` configure the API key, base URL, and API surface for all OpenAI-compatible LLM and embedding calls, used by `loreley.core.map_elites.code_embedding.CodeEmbedder`, `loreley.core.map_elites.summarization_embedding.SummaryEmbedder`, and `loreley.core.worker.commit_summary.CommitSummarizer`. When unset, `OPENAI_API_KEY`/`OPENAI_BASE_URL` fall back to the OpenAI Python client's own environment variable defaults. `OPENAI_API_SPEC` accepts:
    - `"responses"` (default): use the unified `responses` API (`client.responses.create`) for text generation.
    - `"chat_completions"`: use the classic Chat Completions API (`client.chat.completions.create`) while preserving the same high-level behaviour.
  - **Database**: either a raw `DATABASE_URL` or individual `DB_*` fields (scheme, host, port, username, password, database name, pool options, echo flag).
  - **Metrics**: `metrics_retention_days` controls how long metrics are retained.
  - **Task queue**: `TASKS_REDIS_URL`, `TASKS_REDIS_HOST`, `TASKS_REDIS_PORT`, `TASKS_REDIS_DB`, `TASKS_REDIS_PASSWORD`, `TASKS_REDIS_NAMESPACE`, `TASKS_QUEUE_NAME`, `TASKS_WORKER_MAX_RETRIES`, and `TASKS_WORKER_TIME_LIMIT_SECONDS` configure the Dramatiq Redis broker connection details, logical namespace, queue routing, retry policy, and actor time limits used by `loreley.tasks.broker` and `loreley.tasks.workers`. When `TASKS_REDIS_URL` is set and includes credentials, only a sanitised `scheme://host:port/db` form is logged, never the raw URL or password. `TASKS_WORKER_TIME_LIMIT_SECONDS` is interpreted in seconds and converted to Dramatiq's millisecond `time_limit`: values `<= 0` disable the time limit (no hard cap on actor runtime), while positive values enforce a per-job wall-clock limit.
  - **Scheduler**: `SCHEDULER_REPO_ROOT`, `SCHEDULER_POLL_INTERVAL_SECONDS`, `SCHEDULER_MAX_UNFINISHED_JOBS`, `SCHEDULER_MAX_TOTAL_JOBS`, `SCHEDULER_SCHEDULE_BATCH_SIZE`, `SCHEDULER_DISPATCH_BATCH_SIZE`, and `SCHEDULER_INGEST_BATCH_SIZE` drive `loreley.scheduler.main`. These options determine which git worktree the scheduler inspects, how often it runs a reconciliation tick, how many unfinished jobs are allowed at once, the optional cap on total jobs, how aggressively it samples new MAP-Elites jobs per tick, how many pending jobs are dispatched to Dramatiq each cycle, and how many completed jobs are ingested back into the archive per tick.
  - **Worker repository**: `WORKER_REPO_REMOTE_URL`, `WORKER_REPO_BRANCH`, `WORKER_REPO_WORKTREE`, `WORKER_REPO_WORKTREE_RANDOMIZE`, `WORKER_REPO_WORKTREE_RANDOM_SUFFIX_LEN`, `WORKER_REPO_GIT_BIN`, `WORKER_REPO_FETCH_DEPTH`, `WORKER_REPO_CLEAN_EXCLUDES`, `WORKER_REPO_JOB_BRANCH_PREFIX`, `WORKER_REPO_ENABLE_LFS`, and `WORKER_REPO_JOB_BRANCH_TTL_HOURS` configure the git worktree used by worker processes (upstream remote and branch, local checkout path, optional randomised suffix for concurrent workers, git binary, shallow clone depth, clean exclusions, job branch naming, optional Git LFS support, and how long remote job branches are retained before pruning), used by `loreley.core.worker.repository.WorkerRepository`.
  - **Worker planning**: `WORKER_PLANNING_*` options configuring how the external Codex CLI planner is invoked (binary path, optional profile, maximum attempts, timeout, extra environment variables, an optional JSON schema override, the Codex schema mode, and the validation mode), used by `loreley.core.worker.planning.PlanningAgent`. You can override the entire backend via `WORKER_PLANNING_BACKEND` (dotted `module:attr`), and `WORKER_PLANNING_CODEX_SCHEMA_MODE` selects `"auto"` / `"native"` / `"prompt"` / `"none"` when the Codex backend is used. `WORKER_PLANNING_VALIDATION_MODE` controls how strictly the worker enforces the planner's JSON output:
    - `"strict"`: require the backend to produce JSON that matches the planning schema; both Codex (in native schema mode) and the local Pydantic models validate the payload, and failures cause retries and eventually a hard error.
    - `"lenient"` (default): still provide the JSON schema to the backend when applicable, but treat JSON decoding / schema validation failures as non-fatal. The worker first tries to parse the response using the planning schema; if that fails, it synthesises a minimal `PlanningPlan` from the free-form output while preserving as much structure as possible for downstream consumers.
    - `"none"`: disable JSON-based validation entirely. The planner may respond in arbitrary free-form text; the worker skips JSON parsing and always builds a minimal `PlanningPlan` directly from the raw output and job context.
  - **Worker coding**: `WORKER_CODING_*` options configuring how the external Codex-based coding agent is invoked (binary path, optional profile, maximum attempts, timeout, extra environment variables, an optional JSON schema override, the Codex schema mode, and the validation mode), used by `loreley.core.worker.coding.CodingAgent`. You can override the backend via `WORKER_CODING_BACKEND` (dotted `module:attr`), and `WORKER_CODING_CODEX_SCHEMA_MODE` selects `"auto"` / `"native"` / `"prompt"` / `"none"` when the Codex backend is used. `WORKER_CODING_VALIDATION_MODE` follows the same `"strict"` / `"lenient"` / `"none"` semantics as the planning agent, but applied to the coding agent's structured execution report.
  - **Cursor backend**: `WORKER_CURSOR_MODEL` selects the model passed to the Cursor Agent CLI (default `"gpt-5.1-codex-max-high"`), used by `loreley.core.worker.agent_backend.cursor_backend_from_settings()` when wiring Cursor as a backend for planning or coding.
  `WORKER_CURSOR_FORCE` (default `true`) appends `--force` so the Cursor agent allows commands unless explicitly denied; set it to `false` to omit the flag.
  - **Worker evaluator**: `WORKER_EVALUATOR_PLUGIN`, `WORKER_EVALUATOR_PYTHON_PATHS`, `WORKER_EVALUATOR_TIMEOUT_SECONDS`, and `WORKER_EVALUATOR_MAX_METRICS` configure the evaluation plugin entry point, additional Python paths, subprocess timeout, and the maximum number of metrics to keep, used by `loreley.core.worker.evaluator.Evaluator`.
  - **Worker evolution commits**: `WORKER_EVOLUTION_COMMIT_MODEL`, `WORKER_EVOLUTION_COMMIT_TEMPERATURE`, `WORKER_EVOLUTION_COMMIT_MAX_OUTPUT_TOKENS`, `WORKER_EVOLUTION_COMMIT_MAX_RETRIES`, `WORKER_EVOLUTION_COMMIT_RETRY_BACKOFF_SECONDS`, `WORKER_EVOLUTION_COMMIT_AUTHOR`, `WORKER_EVOLUTION_COMMIT_EMAIL`, and `WORKER_EVOLUTION_COMMIT_SUBJECT_MAX_CHARS` configure how the evolution worker generates and records commit subjects (LLM model, sampling behaviour, retry policy, and subject length) and which author identity is used when creating commits, used by `loreley.core.worker.commit_summary.CommitSummarizer` and `loreley.core.worker.repository.WorkerRepository`.
  - **Worker evolution global goal**: `WORKER_EVOLUTION_GLOBAL_GOAL` provides a single, plain‑language evolution objective that is shared across all jobs. When a job row does not provide a per‑job `goal`, this value is used as the **Global objective** in both the planning and coding prompts so that the worker consistently optimises towards a user‑defined high‑level target.
  - **Map-Elites preprocessing**: `MAPELITES_PREPROCESS_*` options controlling which repository code files are considered for feature extraction (limits on file size, allowed extensions/filenames, excluded path globs, whitespace handling, and comment stripping), used by `loreley.core.map_elites.preprocess.CodePreprocessor` and the repo-state embedding file enumerator.
  - **Map-Elites chunking**: `MAPELITES_CHUNK_*` options controlling how preprocessed files are split into chunks (target and minimum lines per chunk, overlap, maximum chunks per file, and boundary keywords used by the chunker), used by `loreley.core.map_elites.chunk.CodeChunker`.
  - **Map-Elites code embedding**: `MAPELITES_CODE_EMBEDDING_*` options configuring the embedding model, optional output dimensions, batch size, per-commit chunk budget, retry count, and exponential backoff for embedding requests, used by `loreley.core.map_elites.code_embedding.CodeEmbedder`.
  - **Map-Elites summary embedding (optional)**: `MAPELITES_SUMMARY_*` and `MAPELITES_SUMMARY_EMBEDDING_*` options configuring the LLM summary model (name, temperature, max output tokens, source excerpt character limit, retries, and backoff) and the summary embedding model (name, dimensions, and batch size), used by `loreley.core.map_elites.summarization_embedding.SummaryEmbedder`. Repo-state MAP-Elites behaviour descriptors do not include these summary vectors.
  - **Map-Elites dimensionality reduction**: `MAPELITES_DIMENSION_REDUCTION_*` options controlling how commit embeddings are normalised, the target feature dimensions, minimum sample count for fitting PCA, rolling history size, and refit cadence, used by `loreley.core.map_elites.dimension_reduction.DimensionReducer`. In repo-state mode, the input embedding is the repo-state code vector.
  - **Map-Elites feature normalization and archive**: `MAPELITES_FEATURE_TRUNCATION_K` sets the symmetric clip radius applied to PCA outputs before they are linearly mapped into `[0, 1]^d`; `MAPELITES_FEATURE_NORMALIZATION_WARMUP_SAMPLES` controls the minimum history required before fitting/using PCA (never below `MAPELITES_DIMENSION_REDUCTION_MIN_FIT_SAMPLES`); and `MAPELITES_FEATURE_CLIP` toggles defensive clipping. `MAPELITES_ARCHIVE_*` options continue to configure grid resolution and learning parameters for the underlying MAP-Elites archive, used by `loreley.core.map_elites.map_elites.MapElitesManager`.
  - **Map-Elites fitness and sampling**: `MAPELITES_FITNESS_*` and `MAPELITES_SAMPLER_*` options that configure which metric to optimise, how to treat fitness direction/floor, and how new jobs are drawn from the archive (inspiration count, neighbour radius, fallback sampling, default priority), used by `loreley.core.map_elites.map_elites.MapElitesManager` and `loreley.core.map_elites.sampler.MapElitesSampler`. `MAPELITES_SEED_POPULATION_SIZE` sets the initial seed population size for new islands.
  - **Map-Elites embedding mode and cache**: `MAPELITES_EMBEDDING_MODE` selects how commits are represented for MAP-Elites (currently only supports `"repo_state"`), `MAPELITES_FILE_EMBEDDING_CACHE_BACKEND` selects the file-level embedding cache backend (`"db"` (default) or `"memory"`), and `MAPELITES_REPO_STATE_MAX_FILES` optionally caps the number of eligible files considered in repo-state mode (default: unlimited).
  - **Map-Elites experiment root commit**: `MAPELITES_EXPERIMENT_ROOT_COMMIT` optionally pins a specific git commit hash as the logical root for a given experiment. When set, the scheduler ensures this commit is recorded in the `commit_cards` table and evaluated to populate baseline metrics before scheduling evolution jobs, so all subsequent jobs branch from a well-defined starting point.
- **`database_dsn`**: computed property that returns a SQLAlchemy-compatible DSN, preferring `DATABASE_URL` when set and otherwise building one from the individual DB fields (with credentials URL-encoded).
- **`export_safe()`**: helper that returns a dict of non-sensitive configuration values suitable for logging.

## Access helpers

- **`get_settings()`**: cached factory that instantiates `Settings`, logs a concise summary of the environment and DB host using `rich`/`loguru`, and returns a singleton instance for reuse across the loreley.
