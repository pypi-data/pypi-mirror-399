[
  {
    "provider": "openai",
    "model": "gpt-5.1",
    "description": "Best overall quality for complex tasks, analysis, and long-form answers",
    "input_price_per_million": 1.25,
    "output_price_per_million": 10.0,
    "tier": "premium",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "openai",
    "model": "gpt-5-mini",
    "description": "Smart general-purpose model for most everyday work",
    "input_price_per_million": 0.25,
    "output_price_per_million": 2.0,
    "tier": "standard",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "openai",
    "model": "gpt-5-nano",
    "description": "Very fast, low-cost choice for simple and high-volume tasks",
    "input_price_per_million": 0.05,
    "output_price_per_million": 0.4,
    "tier": "cheap",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "openai",
    "model": "gpt-4o",
    "description": "Balanced flagship model for multimodal reasoning and coding",
    "input_price_per_million": 0.5,
    "output_price_per_million": 5.0,
    "tier": "standard",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": true,
      "video": false
    }
  },
  {
    "provider": "openai",
    "model": "gpt-4o-mini",
    "description": "Fast, budget-friendly model for chat, code, and lightweight multimodal tasks",
    "input_price_per_million": 0.15,
    "output_price_per_million": 0.6,
    "tier": "cheap",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "description": "High-reliability model for production apps needing long context and strong tools",
    "input_price_per_million": 0.75,
    "output_price_per_million": 8.0,
    "tier": "premium",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "openai",
    "model": "gpt-4.1-mini",
    "description": "Good quality, long-context model for most backend and agent workloads",
    "input_price_per_million": 0.2,
    "output_price_per_million": 1.0,
    "tier": "standard",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "openai",
    "model": "gpt-4.1-nano",
    "description": "Tiny, ultra-fast model for lightweight logic and simple routing tasks",
    "input_price_per_million": 0.03,
    "output_price_per_million": 0.1,
    "tier": "cheap",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "anthropic",
    "model": "claude-sonnet-4-5",
    "description": "Top-tier Claude for long-running agents, coding, and complex workflows",
    "input_price_per_million": 3.0,
    "output_price_per_million": 15.0,
    "tier": "premium",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "anthropic",
    "model": "claude-sonnet-4",
    "description": "General flagship Claude for reasoning, coding, and enterprise use",
    "input_price_per_million": 2.5,
    "output_price_per_million": 12.0,
    "tier": "premium",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "anthropic",
    "model": "claude-haiku-4-5",
    "description": "Fast, smaller Claude ideal for chatbots, support flows, and quick tools",
    "input_price_per_million": 0.4,
    "output_price_per_million": 2.0,
    "tier": "cheap",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "anthropic",
    "model": "claude-opus-4-1",
    "description": "Latest Opus for the most demanding reasoning and analysis tasks",
    "input_price_per_million": 4.0,
    "output_price_per_million": 20.0,
    "tier": "premium",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "anthropic",
    "model": "claude-opus-4",
    "description": "Frontier-level Claude model for maximum capability and accuracy",
    "input_price_per_million": 3.5,
    "output_price_per_million": 18.0,
    "tier": "premium",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-3-pro-preview",
    "description": "Newest Gemini for deep multimodal reasoning across text, code, media, and docs",
    "input_price_per_million": 2.0,
    "output_price_per_million": 12.0,
    "tier": "premium",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": true,
      "video": true
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.5-pro",
    "description": "Flagship Gemini with strong reasoning and full multimodal support",
    "input_price_per_million": 1.25,
    "output_price_per_million": 10.0,
    "tier": "premium",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": true,
      "video": true
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "description": "High-speed multimodal Gemini optimized for low-latency, high-volume workloads",
    "input_price_per_million": 0.35,
    "output_price_per_million": 2.8,
    "tier": "standard",
    "modalities": {
      "text": true,
      "image": true,
      "pdf": true,
      "audio": true,
      "video": true
    }
  },
  {
    "provider": "moonshot",
    "model": "kimi-k2-thinking",
    "description": "Reasoning-focused Kimi model for long-context, tool-using agents",
    "input_price_per_million": 0.6,
    "output_price_per_million": 1.8,
    "tier": "standard",
    "modalities": {
      "text": true,
      "image": false,
      "pdf": false,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "moonshot",
    "model": "kimi-k2-thinking-turbo",
    "description": "Faster K2 Thinking variant tuned for responsive agent loops",
    "input_price_per_million": 0.45,
    "output_price_per_million": 1.4,
    "tier": "standard",
    "modalities": {
      "text": true,
      "image": false,
      "pdf": false,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "moonshot",
    "model": "kimi-k2-0905-preview",
    "description": "Preview K2 model showcasing latest language and coding improvements",
    "input_price_per_million": 0.4,
    "output_price_per_million": 1.2,
    "tier": "cheap",
    "modalities": {
      "text": true,
      "image": false,
      "pdf": false,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "moonshot",
    "model": "kimi-k2-turbo-preview",
    "description": "Turbo K2 for very fast, low-cost interactive chat and coding",
    "input_price_per_million": 0.3,
    "output_price_per_million": 0.9,
    "tier": "cheap",
    "modalities": {
      "text": true,
      "image": false,
      "pdf": false,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "deepseek",
    "model": "deepseek-chat",
    "description": "DeepSeek V3-style general chat model with strong reasoning and multimodal support",
    "input_price_per_million": 0.27,
    "output_price_per_million": 1.1,
    "tier": "cheap",
    "modalities": {
      "text": true,
      "image": false,
      "pdf": false,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "deepseek",
    "model": "deepseek-coder",
    "description": "Specialized coding assistant for reading and writing code",
    "input_price_per_million": 0.14,
    "output_price_per_million": 0.28,
    "tier": "cheap",
    "modalities": {
      "text": true,
      "image": false,
      "pdf": false,
      "audio": false,
      "video": false
    }
  },
  {
    "provider": "deepseek",
    "model": "deepseek-reasoner",
    "description": "Reasoning-focused model for step-by-step problem solving",
    "input_price_per_million": 0.55,
    "output_price_per_million": 2.19,
    "tier": "standard",
    "modalities": {
      "text": true,
      "image": false,
      "pdf": false,
      "audio": false,
      "video": false
    }
  }
]
