from datetime import datetime, time, timedelta
import numpy as np
import scipy
from numpy import ndarray
import pandas as pd
import os
import contextlib
from types import ModuleType
import re
from typing import Optional
from functools import partial
from inspect import signature
import glob


class ProcessedAttribute:

    def __init__(self, value):
        self.value = value

    def __call__(self, *args, **kwargs):
        return partial(self.value, **kwargs)


class base:

    def __getattribute__(self, name: str):
        if not name.startswith("_"):
            return ProcessedAttribute(super().__getattribute__(name))
        return super().__getattribute__(name)


def ensure_numeric_dataframe(data: pd.DataFrame) -> pd.DataFrame:
    """ç¡®ä¿DataFrameä¸­çš„æ•°å€¼åˆ—æ˜¯æ­£ç¡®ç±»å‹"""
    data = data.copy()

    # å®šä¹‰æ•°å€¼åˆ—
    numeric_columns = ['open', 'high', 'low', 'close', 'volume']

    for col in numeric_columns:
        if col in data.columns:
            # å¤„ç†å„ç§å¯èƒ½çš„å¼‚å¸¸æƒ…å†µ
            try:
                data[col] = pd.to_numeric(data[col], errors='coerce')
                # ç¡®ä¿æœ€ç»ˆæ˜¯float64ç±»å‹
                data[col] = data[col].astype(np.float64)
            except Exception as e:
                # print(f"è­¦å‘Š: è½¬æ¢åˆ— {col} æ—¶å‡ºé”™: {e}")
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                data[col] = data[col].apply(
                    lambda x: float(x) if pd.notnull(x) else np.nan)

    # å¤„ç†datetimeåˆ—
    if 'datetime' in data.columns:
        try:
            data['datetime'] = pd.to_datetime(
                data['datetime'], errors='coerce')
        except Exception as e:
            # print(f"è­¦å‘Š: è½¬æ¢datetimeåˆ—æ—¶å‡ºé”™: {e}")
            ...

    return data


def read_unknown_file(file_path: str) -> Optional[pd.DataFrame]:
    """
    è¯»å–æœªçŸ¥æ ¼å¼çš„æ–‡ä»¶å¹¶è½¬æ¢ä¸ºpandas DataFrameï¼Œæ”¯æŒå¸¸è§æ•°æ®æ ¼å¼

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå«æ–‡ä»¶åï¼‰

    Returns:
        æˆåŠŸåˆ™è¿”å›DataFrameï¼Œå¤±è´¥åˆ™è¿”å›Noneå¹¶æç¤ºé”™è¯¯
    """
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        print(f"é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {file_path}")
        return None

    # è·å–æ–‡ä»¶æ‰©å±•åï¼ˆå°å†™ï¼‰
    _, ext = os.path.splitext(file_path)
    ext = ext.lower()  # ç»Ÿä¸€è½¬ä¸ºå°å†™ï¼Œé¿å…å¤§å°å†™é—®é¢˜ï¼ˆå¦‚.CSVå’Œ.csvï¼‰

    # å®šä¹‰ï¼šæ‰©å±•å -> (è¯»å–å‡½æ•°, å¿…è¦å‚æ•°)
    format_handlers = {
        # æ–‡æœ¬æ ¼å¼
        '.csv': (pd.read_csv, {}),
        '.tsv': (pd.read_csv, {'sep': '\t'}),  # åˆ¶è¡¨ç¬¦åˆ†éš”
        '.txt': (pd.read_csv, {}),  # å°è¯•ç”¨csvé»˜è®¤æ–¹å¼è¯»å–æ–‡æœ¬

        # Excelæ ¼å¼
        '.xlsx': (pd.read_excel, {'engine': 'openpyxl'}),
        '.xls': (pd.read_excel, {'engine': 'xlrd'}),

        # ç»“æ„åŒ–æ ¼å¼
        '.json': (pd.read_json, {}),
        '.parquet': (pd.read_parquet, {}),
        '.feather': (pd.read_feather, {}),
        '.pkl': (pd.read_pickle, {}),
        '.pickle': (pd.read_pickle, {}),

        # å…¶ä»–æ ¼å¼
        '.html': (pd.read_html, {}),  # è¯»å–HTMLè¡¨æ ¼ï¼ˆè¿”å›åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªï¼‰
    }

    # å°è¯•1ï¼šæ ¹æ®æ‰©å±•åè¯»å–
    if ext in format_handlers:
        reader, kwargs = format_handlers[ext]
        try:
            if ext == '.html':
                # read_htmlè¿”å›åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªè¡¨æ ¼
                df_list = reader(file_path, **kwargs)
                return df_list[0] if df_list else None
            return reader(file_path, ** kwargs)
        except Exception as e:
            print(f"æŒ‰æ‰©å±•å{ext}è¯»å–å¤±è´¥ï¼š{str(e)}ï¼Œå°è¯•å…¶ä»–æ ¼å¼...")

    # å°è¯•2ï¼šå¦‚æœæ— æ‰©å±•åæˆ–æ‰©å±•åæœªçŸ¥ï¼ŒæŒ‰å¸¸è§æ ¼å¼é¡ºåºå°è¯•
    unknown_ext_formats = [
        '.csv', '.json', '.parquet', '.xlsx', '.pkl'  # ä¼˜å…ˆçº§ä»é«˜åˆ°ä½
    ]
    for fmt in unknown_ext_formats:
        if fmt == ext:
            continue  # è·³è¿‡å·²å°è¯•è¿‡çš„æ ¼å¼
        reader, kwargs = format_handlers[fmt]
        try:
            if fmt == '.html':
                df_list = reader(file_path, **kwargs)
                return df_list[0] if df_list else None
            return reader(file_path, ** kwargs)
        except:
            continue  # å¤±è´¥åˆ™å°è¯•ä¸‹ä¸€ç§

    # æ‰€æœ‰å°è¯•å¤±è´¥
    print(f"æ— æ³•è¯†åˆ«æ–‡ä»¶æ ¼å¼ï¼Œå·²å°è¯•æ‰€æœ‰æ”¯æŒçš„æ ¼å¼ï¼š{list(format_handlers.keys())}")
    return None


class FILED:
    """æ•°æ®å­—æ®µ
    ----------

    >>> ALL = np.array(['datetime', 'open', 'high', 'low','close', 'volume'])
        TALL = np.array(['time', 'open', 'high', 'low',
                        'close', 'volume'], dtype='<U16')
        TICK = np.array(['time', 'volume', 'price'], dtype='<U16')
        Quote = np.array(['datetime', 'open', 'high', 'low','close',
                         'volume',"symbol", "duration","price_tick", "volume_multiple"])
        DOHLV = np.array(['datetime', 'open', 'high',
                         'low', 'volume'], dtype='<U16')
        C = np.array(['close',])
        V = np.array(['volume'])
        CV = np.array(['close', 'volume'])
        OC = np.array(['open', 'close'])
        HL = np.array(['high', 'low'])
        HLC = np.array(['high', 'low','close'])
        HLV = np.array(['high', 'low', 'volume'])
        OHLC = np.array(['open', 'high', 'low','close'])
        HLCV = np.array(['high', 'low','close', 'volume'])
        OHLCV = np.array(['open', 'high', 'low','close', 'volume'])
        dtype : ndarray
    """
    ALL = np.array(['datetime', 'open', 'high', 'low',
                   'close', 'volume'], dtype='<U16')
    TALL = np.array(['time', 'open', 'high', 'low',
                     'close', 'volume'], dtype='<U16')
    TICK = np.array(['time', 'volume', 'price'], dtype='<U16')
    Quote = np.append(ALL, ["symbol", "duration",
                      "price_tick", "volume_multiple"])
    DOHLV = np.array(['datetime', 'open', 'high',
                     'low', 'volume'], dtype='<U16')
    D = ALL[0:1]
    O = ALL[1:2]
    H = ALL[2:3]
    L = ALL[3:4]
    C = ALL[4:5]
    V = ALL[5:]
    CV = ALL[4:]
    OC = ALL[[1, 4]]
    HL = ALL[2:4]
    OHL = ALL[1:4]
    HLC = ALL[2:5]
    HLV = ALL[[2, 3, 5]]
    OHLC = ALL[1:5]
    HLCV = ALL[2:]
    OHLCV = ALL[1:]
    DV = ALL[[0, 5]]
    TV = TALL[[0, 5]]


def save_and_generate_utils(data: pd.DataFrame, base_dir: str, save: Optional[str], name: Optional[str]):
    # å¤„ç†æ–‡ä»¶åï¼ˆé»˜è®¤ç”¨symbolï¼Œæ”¯æŒè‡ªå®šä¹‰ï¼‰
    file_name = save if isinstance(save, str) else name
    if "." in file_name:
        file_name = file_name.split(".")[1]
    file_name = f"{file_name}.csv"
    # ä¿å­˜è·¯å¾„ï¼ˆBASE_DIR/data/test/ï¼‰
    path = os.path.join(base_dir, "data", "test", file_name)
    data.to_csv(path, index=False)
    # è‡ªåŠ¨æ›´æ–°æœ¬åœ°æ•°æ®å·¥å…·ç±»ï¼ˆç”Ÿæˆutils.pyï¼ŒåŒ…å«æ‰€æœ‰CSVæ•°æ®çš„å¼•ç”¨ï¼‰
    csv_files = glob.glob(os.path.join(
        base_dir, "data", "test", "*.csv"))
    py_file_path = os.path.join(base_dir, "data", "utils.py")
    # ç”Ÿæˆå·¥å…·ç±»å†…å®¹
    class_content = [
        'from .tools import *', "", "",
        'class LocalDatas(base):', '    """æœ¬åœ°CSVæ•°æ®"""']
    for file in csv_files:
        file_name = os.path.splitext(os.path.basename(file))[0]
        class_content.append(
            f'    {file_name} = DataString("{file_name}")')
    class_content.extend(["", ""])
    class_content.append('LocalDatas=LocalDatas()')
    # å†™å…¥æ–‡ä»¶
    with open(py_file_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(class_content))


def find_pth_files(cwd=None, file_extension=".pth"):
    """è·å–æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰.pthæ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
    if cwd is None:
        cwd = os.getcwd()  # é»˜è®¤å½“å‰å·¥ä½œç›®å½•
    pth_files = []
    for root, _, files in os.walk(cwd):
        for file in files:
            if file.endswith(file_extension):
                pth_files.append(os.path.join(root, file))
    return pth_files


def extract_numeric_key(file_path):
    """ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ–‡ä»¶åçš„æ•°å­—éƒ¨åˆ†ï¼Œè½¬æ¢ä¸ºæ•°å€¼å…ƒç»„ä½œä¸ºæ’åºé”®"""
    file_name = os.path.basename(file_path)  # æå–æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
    # åŒ¹é…æ‰€æœ‰æ•°å­—éƒ¨åˆ†ï¼ˆæ”¯æŒæ•´æ•°å’Œå°æ•°ï¼Œå¦‚"0002048"ã€"1501.000"ï¼‰
    numeric_strings = re.findall(r"\d+\.?\d*", file_name)
    # å°†æ•°å­—å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼ˆintæˆ–floatï¼‰
    numeric_values = []
    for s in numeric_strings:
        if "." in s:
            numeric_values.append(float(s))  # å°æ•°éƒ¨åˆ†
        else:
            numeric_values.append(int(s))    # æ•´æ•°éƒ¨åˆ†
    return tuple(numeric_values)  # ä»¥å…ƒç»„å½¢å¼è¿”å›ï¼Œæ”¯æŒå¤šæ•°å­—éƒ¨åˆ†æ’åº


def get_sorted_pth_files(cwd: str, file_extension: str = ".pth") -> list:
    """### è·å–æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰.pthæ–‡ä»¶ï¼Œå¹¶æŒ‰æ–‡ä»¶åä¸­çš„æ•°å­—ä»å¤§åˆ°å°æ’åº
    ### 1. è·å–æ‰€æœ‰.pthæ–‡ä»¶è·¯å¾„
    >>> pth_paths = find_pth_files()

    ### 2. æŒ‰æ–‡ä»¶åä¸­çš„æ•°å­—ä»å¤§åˆ°å°æ’åº
    >>> sorted_paths = sorted(pth_paths, key=extract_numeric_key, reverse=True)

    ### 3. è¾“å‡ºæ’åºåçš„è·¯å¾„
    >>> print("æŒ‰æ•°å­—ä»å¤§åˆ°å°æ’åºçš„.pthæ–‡ä»¶è·¯å¾„ï¼š")
        for path in sorted_paths:
            print(path)"""
    pth_files = find_pth_files(cwd, file_extension)
    sorted_files = sorted(pth_files, key=extract_numeric_key, reverse=True)
    return sorted_files


class DisabledModule(ModuleType):
    """ç¦ç”¨çš„æ¨¡å—ï¼Œé˜²æ­¢ä»»æ„å¯¼å…¥"""

    def __getattr__(self, name):
        raise RuntimeError(f"åœ¨å®‰å…¨æ¨¡å¼ä¸‹ç¦æ­¢è®¿é—®æ¨¡å— '{self.__name__}' çš„å±æ€§ '{name}'")


class SafeLoader:
    """å®‰å…¨åŠ è½½å™¨ï¼Œé™åˆ¶å…¨å±€å‘½åç©ºé—´"""

    def __init__(self, allowed_classes=None):
        self.allowed_classes = allowed_classes or []
        self.original_builtins = None
        self.original_import = None

    def _safe_import(self, name, globals=None, locals=None, fromlist=(), level=0):
        """å®‰å…¨å¯¼å…¥å‡½æ•°ï¼Œåªå…è®¸ç‰¹å®šæ¨¡å—"""
        # å…è®¸çš„æ¨¡å—åˆ—è¡¨ï¼ˆæ ¹æ®éœ€è¦æ‰©å±•ï¼‰
        allowed_modules = ["torch", "torch.nn", "numpy", "builtins"]

        # æ£€æŸ¥æ¨¡å—æ˜¯å¦å…è®¸
        if any(name.startswith(mod) for mod in allowed_modules):
            return self.original_import(name, globals, locals, fromlist, level)

        # å¯¹äºä¸å…è®¸çš„æ¨¡å—ï¼Œè¿”å›ç¦ç”¨çš„æ¨¡å—å¯¹è±¡
        return DisabledModule(name)

    def __enter__(self):
        global __builtins__  # æ˜ç¡®å¼•ç”¨å…¨å±€çš„ __builtins__

        # å¤‡ä»½åŸå§‹çš„å†…ç½®å‘½åç©ºé—´å’Œå¯¼å…¥å‡½æ•°
        if isinstance(__builtins__, dict):
            self.original_builtins = __builtins__.copy()
        else:
            # åœ¨æŸäº›ç¯å¢ƒä¸­ï¼Œ__builtins__ å¯èƒ½æ˜¯æ¨¡å—å¯¹è±¡
            self.original_builtins = __builtins__.__dict__.copy()

        self.original_import = __builtins__['__import__']

        # åˆ›å»ºå®‰å…¨çš„å…¨å±€å‘½åç©ºé—´
        safe_globals = {}

        # æ·»åŠ å…è®¸çš„ç±»
        for cls in self.allowed_classes:
            safe_globals[cls.__name__] = cls

        # æ·»åŠ åŸºæœ¬çš„å†…ç½®å‡½æ•°å’Œç±»å‹
        if isinstance(__builtins__, dict):
            builtins_dict = __builtins__
        else:
            builtins_dict = __builtins__.__dict__

        for name, obj in builtins_dict.items():
            if isinstance(obj, type) or callable(obj):
                safe_globals[name] = obj

        # æ›¿æ¢å†…ç½®å‘½åç©ºé—´å’Œå¯¼å…¥å‡½æ•°
        __builtins__ = safe_globals
        __builtins__['__import__'] = self._safe_import

        return self

    def __exit__(self, exc_type, exc_value, traceback):
        global __builtins__  # æ˜ç¡®å¼•ç”¨å…¨å±€çš„ __builtins__

        # æ¢å¤åŸå§‹çš„å†…ç½®å‘½åç©ºé—´å’Œå¯¼å…¥å‡½æ•°
        if isinstance(self.original_builtins, dict):
            __builtins__ = self.original_builtins
        else:
            __builtins__.clear()
            __builtins__.update(self.original_builtins)

        __builtins__['__import__'] = self.original_import
        return False  # ä¸æŠ‘åˆ¶å¼‚å¸¸


@contextlib.contextmanager
def safe_globals(allowed_classes):
    """### å®‰å…¨å…¨å±€å‘½åç©ºé—´ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    ### ä½¿ç”¨æ–¹æ³•
    >>> from minibt.elegantrl.agents import AgentDiscretePPO
        with safe_globals([AgentDiscretePPO]):
            model = torch.load("model.pth", map_location="cpu")"""
    with SafeLoader(allowed_classes) as loader:
        yield loader


class Meta(type):
    """å¯è¿­ä»£å…ƒç±»"""
    def __iter__(cls):
        # ä»…è¿­ä»£éç‰¹æ®Šå±æ€§ï¼ˆå¯é€‰ï¼‰
        return iter([v for k, v in vars(cls).items() if not k.startswith('__')])

    def __contains__(cls, item):
        # ä»…æ£€æŸ¥éç‰¹æ®Šå±æ€§çš„å€¼
        return item in [v for k, v in vars(cls).items() if not k.startswith('__')]


class KeyMeta(type):
    """å¯è¿­ä»£å…ƒç±»"""
    def __iter__(cls):
        # ä»…è¿­ä»£é”®å±æ€§
        return iter([k for k, _ in vars(cls).items() if not k.startswith('__')])

    def __contains__(cls, item):
        # ä»…æ£€æŸ¥é”®å±æ€§
        return item in [k for k, _ in vars(cls).items() if not k.startswith('__')]


def get_func_args_dict(func, *args, **kwargs) -> dict:
    """
    å°†å‡½æ•°è°ƒç”¨çš„å‚æ•°ï¼ˆä½ç½®å‚æ•°+å…³é”®å­—å‚æ•°ï¼‰è½¬æ¢ä¸ºã€Œå‚æ•°å:å‚æ•°å€¼ã€çš„å­—å…¸ï¼ŒåŒ…å«é»˜è®¤å‚æ•°

    Args:
        func: ç›®æ ‡å‡½æ•°ï¼ˆå¦‚ testï¼‰
        *args: å‡½æ•°è°ƒç”¨çš„ä½ç½®å‚æ•°ï¼ˆå¦‚ 3,4,5,6ï¼‰
        **kwargs: å‡½æ•°è°ƒç”¨çš„å…³é”®å­—å‚æ•°ï¼ˆå¦‚ c=5,d=6ï¼‰

    Returns:
        åŒ…å«æ‰€æœ‰å‚æ•°åä¸å¯¹åº”å€¼çš„å­—å…¸
    """
    # 1. è·å–å‡½æ•°çš„å‚æ•°ç­¾å
    func_sig = signature(func)
    # 2. ç»‘å®šå‚æ•°ï¼ˆæ”¯æŒä½ç½®+å…³é”®å­—å‚æ•°ï¼Œè‡ªåŠ¨åŒ¹é…å‚æ•°åï¼‰
    bound_args = func_sig.bind_partial(*args, **kwargs)
    # 3. å¡«å……å‡½æ•°çš„é»˜è®¤å‚æ•°ï¼ˆæœªä¼ çš„é»˜è®¤å‚æ•°ä¼šè‡ªåŠ¨è¡¥å…¨ï¼‰
    bound_args.apply_defaults()
    # 4. è¿”å›å‚æ•°åä¸å€¼çš„å­—å…¸ï¼ˆarguments å±æ€§æœ¬èº«å°±æ˜¯æœ‰åºå­—å…¸ï¼ŒPython3.7+ ä¼šä¿ç•™å‚æ•°é¡ºåºï¼‰
    return dict(bound_args.arguments)


def pad_lists(list1, list2, fill_value=False) -> zip:
    padded_list2 = len(list1) > len(list2) and list2 + \
        [fill_value] * (len(list1) - len(list2)) or list2[:len(list1)]
    return zip(list1, padded_list2)


def format_3col_report(metrics: list[str, float, str], name="", col_width: int = 30):
    # æ„é€ åˆ†ç»„ï¼ˆæ¯3ä¸ªæŒ‡æ ‡ä¸ºä¸€ç»„ï¼‰
    metric_groups = [metrics[i:i+3] for i in range(0, len(metrics), 3)]

    # æ„å»ºæŠ¥å‘Šå†…å®¹
    report = []
    total_width = (col_width+3) * 3 - 1  # 3åˆ—å®½åº¦ + åˆ†éš”ç¬¦
    separator = "â•‘" + "â•" * total_width + "â•‘"

    report.append(separator)
    report.append("â•‘{:^{total_width}}â•‘".format(
        f"{name} Strategy performance reports", total_width=total_width))
    report.append(separator)

    for group in metric_groups:
        line: list[str] = []
        for metric in group:
            name, value, fmt = metric
            # å›ºå®šåç§°å’Œæ•°å€¼å®½åº¦
            name_part = name.ljust(int(col_width/2)-1)
            value_part = fmt.format(value).rjust(int(col_width/2)-1)
            line.append(f"{name_part}{value_part}")
        # è¡¥è¶³ç©ºç™½åˆ—å¹¶ä¿æŒå¯¹é½
        while len(line) < 3:
            line.append(" " * (col_width - 1))  # -2 è¡¥å¿åˆ†éš”ç¬¦ç©ºé—´
        # æ„å»ºè¡Œ
        report_line = "â•‘ {} â”‚ {} â”‚ {} â•‘".format(*[
            item.ljust(col_width, " ")  # 'ã€€')  # ä½¿ç”¨å…¨è§’ç©ºæ ¼å¡«å……
            for item in line
        ])
        report.append(report_line)

    report.append(separator)
    return "\n".join(report)


def _datetime_to_timestamp_nano(dt: datetime) -> int:
    # timestamp() è¿”å›å€¼ç²¾åº¦ä¸º microsecond,ç›´æ¥ä¹˜ä»¥ 1e9 å¯èƒ½æœ‰ç²¾åº¦é—®é¢˜
    return int(dt.timestamp() * 1000000) * 1000


def _str_to_timestamp_nano(current_datetime: str, fmt="%Y-%m-%d %H:%M:%S") -> int:
    return _datetime_to_timestamp_nano(datetime.strptime(current_datetime, fmt))


def _to_ns_timestamp(input_time):
    """
    è¾…åŠ©å‡½æ•°: å°†ä¼ å…¥çš„æ—¶é—´è½¬æ¢ä¸ºintç±»å‹çš„çº³ç§’çº§æ—¶é—´æˆ³

    Args:
    input_time (str/ int/ float/ datetime.datetime): éœ€è¦è½¬æ¢çš„æ—¶é—´:
        * str: str ç±»å‹çš„æ—¶é—´,å¦‚Quoteè¡Œæƒ…æ—¶é—´çš„datetimeå­—æ®µ (eg. 2019-10-14 14:26:01.000000)

        * int: int ç±»å‹çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³

        * float: float ç±»å‹çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³,å¦‚Kçº¿æˆ–tickçš„datetimeå­—æ®µ (eg. 1.57103449e+18)

        * datetime.datetime: datetime æ¨¡å—ä¸­ datetime ç±»å‹

    Returns:
        int : int ç±»å‹çº³ç§’çº§æ—¶é—´æˆ³
    """
    if type(input_time) in {int, float, np.float64, np.float32, np.int64, np.int32}:  # æ—¶é—´æˆ³
        if input_time > 2 ** 32:  # çº³ç§’( å°† > 2*32æ•°å€¼å½’ä¸ºçº³ç§’çº§)
            return int(input_time)
        else:  # ç§’
            return int(input_time * 1e9)
    elif isinstance(input_time, str):  # str ç±»å‹æ—¶é—´
        return _str_to_timestamp_nano(input_time)
    elif isinstance(input_time, datetime):  # datetime ç±»å‹æ—¶é—´
        return _datetime_to_timestamp_nano(input_time)
    else:
        raise TypeError("æš‚ä¸æ”¯æŒæ­¤ç±»å‹çš„è½¬æ¢")


def time_to_str(input_time):
    """
    å°†ä¼ å…¥çš„æ—¶é—´è½¬æ¢ä¸º %Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„ str ç±»å‹

    Args:
        input_time (int/ float/ datetime.datetime): éœ€è¦è½¬æ¢çš„æ—¶é—´:

            * int: int ç±»å‹çš„çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³

            * float: float ç±»å‹çš„çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³,å¦‚Kçº¿æˆ–tickçš„datetimeå­—æ®µ (eg. 1.57103449e+18)

            * datetime.datetime: datetime æ¨¡å—ä¸­çš„ datetime ç±»å‹æ—¶é—´

    Returns:
        str : %Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„ str ç±»å‹æ—¶é—´

    Example::

        from tqsdk.tafunc import time_to_str
        print(time_to_str(1.57103449e+18))  # å°†çº³ç§’çº§æ—¶é—´æˆ³è½¬ä¸º%Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„strç±»å‹æ—¶é—´
        print(time_to_str(1571103122))  # å°†ç§’çº§æ—¶é—´æˆ³è½¬ä¸º%Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„strç±»å‹æ—¶é—´
        print(time_to_str(datetime.datetime(2019, 10, 14, 14, 26, 1)))  # å°†datetime.datetimeæ—¶é—´è½¬ä¸º%Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„strç±»å‹æ—¶é—´
    """
    # è½¬ä¸ºç§’çº§æ—¶é—´æˆ³
    ts = _to_ns_timestamp(input_time) / 1e9
    # è½¬ä¸º %Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„ str ç±»å‹æ—¶é—´
    dt = datetime.fromtimestamp(ts)
    dt = dt.strftime('%Y-%m-%d %H:%M:%S')
    return dt


def time_to_datetime(input_time):
    """
    å°†ä¼ å…¥çš„æ—¶é—´è½¬æ¢ä¸º datetime.datetime ç±»å‹

    Args:
        input_time (int/ float/ str): éœ€è¦è½¬æ¢çš„æ—¶é—´:

            * int: int ç±»å‹çš„çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³

            * float: float ç±»å‹çš„çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³,å¦‚Kçº¿æˆ–tickçš„datetimeå­—æ®µ (eg. 1.57103449e+18)

            * str: str ç±»å‹çš„æ—¶é—´,å¦‚Quoteè¡Œæƒ…æ—¶é—´çš„ datetime å­—æ®µ (eg. 2019-10-14 14:26:01.000000)

    Returns:
        datetime.datetime : datetime æ¨¡å—ä¸­çš„ datetime ç±»å‹æ—¶é—´

    Example::

        from tqsdk.tafunc import time_to_datetime
        print(time_to_datetime(1.57103449e+18))  # å°†çº³ç§’çº§æ—¶é—´æˆ³è½¬ä¸ºdatetime.datetimeæ—¶é—´
        print(time_to_datetime(1571103122))  # å°†ç§’çº§æ—¶é—´æˆ³è½¬ä¸ºdatetime.datetimeæ—¶é—´
        print(time_to_datetime("2019-10-14 14:26:01.000000"))  # å°†%Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„strç±»å‹æ—¶é—´è½¬ä¸ºdatetime.datetimeæ—¶é—´
    """
    # è½¬ä¸ºç§’çº§æ—¶é—´æˆ³
    ts = _to_ns_timestamp(input_time) / 1e9
    # è½¬ä¸ºdatetime.datetimeç±»å‹
    dt = datetime.fromtimestamp(ts)
    return dt


def timestamp_to_time(input_time):
    raise time_to_datetime(input_time).time()


def time_to_s_timestamp(input_time):
    """
    å°†ä¼ å…¥çš„æ—¶é—´è½¬æ¢ä¸ºintç±»å‹çš„ç§’çº§æ—¶é—´æˆ³

    Args:
        input_time (str/ int/ float/ datetime.datetime): éœ€è¦è½¬æ¢çš„æ—¶é—´:
            * str: str ç±»å‹çš„æ—¶é—´,å¦‚Quoteè¡Œæƒ…æ—¶é—´çš„datetimeå­—æ®µ (eg. 2019-10-14 14:26:01.000000)

            * int: int ç±»å‹çš„çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³

            * float: float ç±»å‹çš„çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³,å¦‚Kçº¿æˆ–tickçš„datetimeå­—æ®µ (eg. 1.57103449e+18)

            * datetime.datetime: datetime æ¨¡å—ä¸­çš„ datetime ç±»å‹æ—¶é—´

    Returns:
        int : intç±»å‹çš„ç§’çº§æ—¶é—´æˆ³

    Example::

        from tqsdk.tafunc import time_to_s_timestamp
        print(time_to_s_timestamp(1.57103449e+18))  # å°†çº³ç§’çº§æ—¶é—´æˆ³è½¬ä¸ºç§’çº§æ—¶é—´æˆ³
        print(time_to_s_timestamp("2019-10-14 14:26:01.000000"))  # å°†%Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„strç±»å‹æ—¶é—´è½¬ä¸ºç§’çº§æ—¶é—´æˆ³
        print(time_to_s_timestamp(datetime.datetime(2019, 10, 14, 14, 26, 1)))  # å°†datetime.datetimeæ—¶é—´è½¬ä¸ºç§’æ—¶é—´æˆ³
    """
    return int(_to_ns_timestamp(input_time) / 1e9)


def time_to_ns_timestamp(input_time):
    """
    å°†ä¼ å…¥çš„æ—¶é—´è½¬æ¢ä¸ºintç±»å‹çš„çº³ç§’çº§æ—¶é—´æˆ³

    Args:
        input_time (str/ int/ float/ datetime.datetime): éœ€è¦è½¬æ¢çš„æ—¶é—´:
            * str: str ç±»å‹çš„æ—¶é—´,å¦‚Quoteè¡Œæƒ…æ—¶é—´çš„datetimeå­—æ®µ (eg. 2019-10-14 14:26:01.000000)

            * int: int ç±»å‹çš„çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³

            * float: float ç±»å‹çš„çº³ç§’çº§æˆ–ç§’çº§æ—¶é—´æˆ³,å¦‚Kçº¿æˆ–tickçš„datetimeå­—æ®µ (eg. 1.57103449e+18)

            * datetime.datetime: datetime æ¨¡å—ä¸­çš„ datetime ç±»å‹æ—¶é—´

    Returns:
        int : int ç±»å‹çš„çº³ç§’çº§æ—¶é—´æˆ³

    Example::

        from tqsdk.tafunc import time_to_ns_timestamp
        print(time_to_ns_timestamp("2019-10-14 14:26:01.000000"))  # å°†%Y-%m-%d %H:%M:%S.%f æ ¼å¼çš„strç±»å‹è½¬ä¸ºçº³ç§’æ—¶é—´æˆ³
        print(time_to_ns_timestamp(1571103122))  # å°†ç§’çº§è½¬ä¸ºçº³ç§’æ—¶é—´æˆ³
        print(time_to_ns_timestamp(datetime.datetime(2019, 10, 14, 14, 26, 1)))  # å°†datetime.datetimeæ—¶é—´è½¬ä¸ºçº³ç§’æ—¶é—´æˆ³
    """
    return _to_ns_timestamp(input_time)


def compute_time(signal, fs) -> np.ndarray:
    """Creates the signal correspondent time array.

    Parameters
    ----------
    signal: nd-array
        Input from which the time is computed.
    fs: int
        Sampling Frequency

    Returns
    -------
    time : float list
        Signal time

    """

    return np.arange(0, len(signal))/fs


def calc_fft(signal, fs):
    """ This functions computes the fft of a signal.

    Parameters
    ----------
    signal : nd-array
        The input signal from which fft is computed
    fs : float
        Sampling frequency

    Returns
    -------
    f: nd-array
        Frequency values (xx axis)
    fmag: nd-array
        Amplitude of the frequency values (yy axis)

    """

    fmag = np.abs(np.fft.rfft(signal))
    f = np.fft.rfftfreq(len(signal), d=1/fs)

    return f.copy(), fmag.copy()


def filterbank(signal, fs, pre_emphasis=0.97, nfft=512, nfilt=40):
    """Computes the MEL-spaced filterbank.

    It provides the information about the power in each frequency band.

    Implementation details and description on:
    https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial
    https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html#fnref:1

    Parameters
    ----------
    signal : nd-array
        Input from which filterbank is computed
    fs : float
        Sampling frequency
    pre_emphasis : float
        Pre-emphasis coefficient for pre-emphasis filter application
    nfft : int
        Number of points of fft
    nfilt : int
        Number of filters

    Returns
    -------
    nd-array
        MEL-spaced filterbank

    """

    # Signal is already a window from the original signal, so no frame is needed.
    # According to the references it is needed the application of a window function such as
    # hann window. However if the signal windows don't have overlap, we will lose information,
    # as the application of a hann window will overshadow the windows signal edges.

    # pre-emphasis filter to amplify the high frequencies

    emphasized_signal = np.append(np.array(signal)[0], np.array(
        signal[1:]) - pre_emphasis * np.array(signal[:-1]))

    # Fourier transform and Power spectrum
    mag_frames = np.absolute(np.fft.rfft(
        emphasized_signal, nfft))  # Magnitude of the FFT

    pow_frames = ((1.0 / nfft) * (mag_frames ** 2))  # Power Spectrum

    low_freq_mel = 0
    high_freq_mel = (2595 * np.log10(1 + (fs / 2) / 700))  # Convert Hz to Mel
    # Equally spaced in Mel scale
    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)
    hz_points = (700 * (10 ** (mel_points / 2595) - 1))  # Convert Mel to Hz
    filter_bin = np.floor((nfft + 1) * hz_points / fs)

    fbank = np.zeros((nfilt, int(np.floor(nfft / 2 + 1))))
    for m in range(1, nfilt + 1):

        f_m_minus = int(filter_bin[m - 1])  # left
        f_m = int(filter_bin[m])  # center
        f_m_plus = int(filter_bin[m + 1])  # right

        for k in range(f_m_minus, f_m):
            fbank[m - 1, k] = (k - filter_bin[m - 1]) / \
                (filter_bin[m] - filter_bin[m - 1])
        for k in range(f_m, f_m_plus):
            fbank[m - 1, k] = (filter_bin[m + 1] - k) / \
                (filter_bin[m + 1] - filter_bin[m])

    # Area Normalization
    # If we don't normalize the noise will increase with frequency because of the filter width.
    enorm = 2.0 / (hz_points[2:nfilt + 2] - hz_points[:nfilt])
    fbank *= enorm[:, np.newaxis]

    filter_banks = np.dot(pow_frames, fbank.T)
    filter_banks = np.where(filter_banks == 0, np.finfo(
        float).eps, filter_banks)  # Numerical Stability
    filter_banks = 20 * np.log10(filter_banks)  # dB

    return filter_banks


def autocorr_norm(signal):
    """Computes the autocorrelation.

    Implementation details and description in:
    https://ccrma.stanford.edu/~orchi/Documents/speaker_recognition_report.pdf

    Parameters
    ----------
    signal : nd-array
        Input from linear prediction coefficients are computed

    Returns
    -------
    nd-array
        Autocorrelation result

    """

    variance = np.var(signal)
    signal = np.copy(signal - signal.mean())
    r = scipy.signal.correlate(signal, signal)[-len(signal):]

    if (signal == 0).all():
        return np.zeros(len(signal))

    acf = r / variance / len(signal)

    return acf


def create_symmetric_matrix(acf, order=11):
    """Computes a symmetric matrix.

    Implementation details and description in:
    https://ccrma.stanford.edu/~orchi/Documents/speaker_recognition_report.pdf

    Parameters
    ----------
    acf : nd-array
        Input from which a symmetric matrix is computed
    order : int
        Order

    Returns
    -------
    nd-array
        Symmetric Matrix

    """

    smatrix = np.empty((order, order))
    xx = np.arange(order)
    j = np.tile(xx, order)
    i = np.repeat(xx, order)
    smatrix[i, j] = acf[np.abs(i - j)]

    return smatrix


def lpc(signal, n_coeff=12):
    """Computes the linear prediction coefficients.

    Implementation details and description in:
    https://ccrma.stanford.edu/~orchi/Documents/speaker_recognition_report.pdf

    Parameters
    ----------
    signal : nd-array
        Input from linear prediction coefficients are computed
    n_coeff : int
        Number of coefficients

    Returns
    -------
    nd-array
        Linear prediction coefficients

    """

    if signal.ndim > 1:
        raise ValueError("Only 1 dimensional arrays are valid")
    if n_coeff > signal.size:
        raise ValueError("Input signal must have a length >= n_coeff")

    # Calculate the order based on the number of coefficients
    order = n_coeff - 1

    # Calculate LPC with Yule-Walker
    acf = np.correlate(signal, signal, 'full')

    r = np.zeros(order+1, 'float32')
    # Assuring that works for all type of input lengths
    nx = np.min([order+1, len(signal)])
    r[:nx] = acf[len(signal)-1:len(signal)+order]

    smatrix = create_symmetric_matrix(r[:-1], order)

    if np.sum(smatrix) == 0:
        return tuple(np.zeros(order+1))

    lpc_coeffs = np.dot(np.linalg.inv(smatrix), -r[1:])

    return tuple(np.concatenate(([1.], lpc_coeffs)))


def create_xx(features):
    """Computes the range of features amplitude for the probability density function calculus.

    Parameters
    ----------
    features : nd-array
        Input features

    Returns
    -------
    nd-array
        range of features amplitude

    """

    features_ = np.copy(features)

    if max(features_) < 0:
        max_f = - max(features_)
        min_f = min(features_)
    else:
        min_f = min(features_)
        max_f = max(features_)

    if min(features_) == max(features_):
        xx = np.linspace(min_f, min_f + 10, len(features_))
    else:
        xx = np.linspace(min_f, max_f, len(features_))

    return xx


def kde(features):
    """Computes the probability density function of the input signal using a Gaussian KDE (Kernel Density Estimate)

    Parameters
    ----------
    features : nd-array
        Input from which probability density function is computed

    Returns
    -------
    nd-array
        probability density values

    """
    features_ = np.copy(features)
    xx = create_xx(features_)

    if min(features_) == max(features_):
        noise = np.random.randn(len(features_)) * 0.0001
        features_ = np.copy(features_ + noise)

    kernel = scipy.stats.gaussian_kde(features_, bw_method='silverman')

    return np.array(kernel(xx) / np.sum(kernel(xx)))


def gaussian(features):
    """Computes the probability density function of the input signal using a Gaussian function

    Parameters
    ----------
    features : nd-array
        Input from which probability density function is computed
    Returns
    -------
    nd-array
        probability density values

    """

    features_ = np.copy(features)

    xx = create_xx(features_)
    std_value = np.std(features_)
    mean_value = np.mean(features_)

    if std_value == 0:
        return 0.0
    pdf_gauss = scipy.stats.norm.pdf(xx, mean_value, std_value)

    return np.array(pdf_gauss / np.sum(pdf_gauss))


def wavelet(signal, function=scipy.signal.ricker, widths=np.arange(1, 10)):
    """Computes CWT (continuous wavelet transform) of the signal.

    Parameters
    ----------
    signal : nd-array
        Input from which CWT is computed
    function :  wavelet function
        Default: scipy.signal.ricker
    widths :  nd-array
        Widths to use for transformation
        Default: np.arange(1,10)

    Returns
    -------
    nd-array
        The result of the CWT along the time axis
        matrix with size (len(widths),len(signal))

    """

    if isinstance(function, str):
        function = eval(function)

    if isinstance(widths, str):
        widths = eval(widths)

    cwt = scipy.signal.cwt(signal, function, widths)

    return cwt


def calc_ecdf(signal):
    """Computes the ECDF of the signal.

      Parameters
      ----------
      signal : nd-array
          Input from which ECDF is computed
      Returns
      -------
      nd-array
        Sorted signal and computed ECDF.

      """
    return np.sort(signal), np.arange(1, len(signal)+1)/len(signal)


def get_lennan(*args: tuple[ndarray, pd.Series]) -> int:
    """å‚æ•°å¿…é¡»ä¸ºnp.ndarray"""
    args = [arg.values if hasattr(arg, "values") else arg for arg in args]
    result = [len(arg[pd.isnull(arg)])
              for arg in args if isinstance(arg, ndarray)]
    if len(result) == 1:
        return result[0]
    return max(*result)


def get_final_html(report_name: str, final_css: str, nav_html: str, merged_content: str, final_js: str) -> str:
    return f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>åˆå¹¶ç‰ˆQuantStatsåˆ†ææŠ¥å‘Š - {report_name}</title>
            <style type="text/css">
                {final_css}
                /* å…¨å±€æ ·å¼ */
                body {{
                    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
                    background: #fafafa;
                    color: #2d3748;
                    margin: 0;
                    padding: 0;
                }}
                .strategy-report {{
                    margin: 25px 0;
                    padding: 20px;
                    border: 1px solid #e0e0e0;
                    border-radius: 8px;
                    background: #fff;
                    display: none;
                }}
                .strategy-report.active {{
                    display: block !important;
                }}
                #report-nav {{
                    position: fixed;
                    left: 0;
                    top: 0;
                    width: 250px;
                    height: 100%;
                    overflow-y: auto;
                    background: #f7fafc;
                    padding: 20px;
                    box-shadow: 2px 0 5px rgba(0,0,0,0.1);
                    z-index: 1000;
                }}
                #report-nav ul li {{
                    margin-bottom: 10px;
                }}
                #report-nav ul li a {{
                    color: #3182ce;
                    text-decoration: none;
                    display: block;
                    padding: 8px 12px;
                    border-radius: 4px;
                    transition: background 0.2s;
                }}
                #report-nav ul li a:hover {{
                    background: #edf2f7;
                }}
                #report-nav ul li a.active {{
                    background: #3182ce;
                    color: white;
                }}
                #content-area {{
                    margin-left: 270px;
                    padding: 20px;
                }}
                /* å“åº”å¼è®¾è®¡ */
                @media (max-width: 768px) {{
                    #report-nav {{
                        position: relative;
                        width: 100%;
                        height: auto;
                        margin-bottom: 20px;
                    }}
                    #content-area {{
                        margin-left: 0;
                    }}
                }}
            /* å¼ºåˆ¶ä½¿ç”¨äº®è‰²ä¸»é¢˜ */
            body {{
                background-color: #ffffff !important;
                color: #000000 !important;
            }}
            .js-plotly-plot .plotly, .plot-container {{
                background-color: #ffffff !important;
            }}
            .modebar {{
                background-color: #ffffff !important;
            }}
            .main-svg {{
                background-color: #ffffff !important;
            }}
            .bg-dark {{
                background-color: #f8f9fa !important;
                color: #000000 !important;
            }}
            .text-white {{
                color: #000000 !important;
            }}
            .navbar-dark {{
                background-color: #f8f9fa !important;
            }}
            .navbar-dark .navbar-nav .nav-link {{
                color: rgba(0, 0, 0, 0.8) !important;
            }}
            .card {{
                background-color: #ffffff !important;
                border: 1px solid #e0e0e0 !important;
            }}
            .table {{
                color: #000000 !important;
            }}
            </style>
        </head>
        <body>
            {nav_html}
            <div id="content-area">
                {''.join(merged_content)}
            </div>
            <script type="text/javascript">
                {final_js}
                
                // ä¿®å¤ï¼šä½¿ç”¨æ›´å¯é çš„æ–¹å¼ç¡®ä¿DOMå®Œå…¨åŠ è½½
                function initReports() {{
                    // è·å–æ‰€æœ‰ç­–ç•¥æŠ¥å‘Š
                    const strategyReports = document.querySelectorAll('.strategy-report');
                    
                    // æ˜¾ç¤ºç¬¬ä¸€ä¸ªç­–ç•¥æŠ¥å‘Š
                    if (strategyReports.length > 0) {{
                        strategyReports[0].classList.add('active');
                        // æ¿€æ´»ç¬¬ä¸€ä¸ªå¯¼èˆªé“¾æ¥
                        const firstNavLink = document.querySelector('.nav-link');
                        if (firstNavLink) {{
                            firstNavLink.classList.add('active');
                        }}
                    }}
                    
                    // ä¸ºå¯¼èˆªé“¾æ¥æ·»åŠ ç‚¹å‡»äº‹ä»¶
                    const navLinks = document.querySelectorAll('.nav-link');
                    navLinks.forEach(link => {{
                        link.addEventListener('click', function(e) {{
                            e.preventDefault();
                            const targetId = this.getAttribute('data-target');
                            scrollToStrategy(targetId);
                            
                            // æ›´æ–°å¯¼èˆªé“¾æ¥æ¿€æ´»çŠ¶æ€
                            navLinks.forEach(l => l.classList.remove('active'));
                            this.classList.add('active');
                        }});
                    }});
                }}
                
                // æ»šåŠ¨åˆ°æŒ‡å®šç­–ç•¥æŠ¥å‘Š
                function scrollToStrategy(strategyId) {{
                    // éšè—æ‰€æœ‰ç­–ç•¥æŠ¥å‘Š
                    const strategyReports = document.querySelectorAll('.strategy-report');
                    strategyReports.forEach(report => {{
                        report.classList.remove('active');
                    }});
                    
                    // æ˜¾ç¤ºé€‰ä¸­çš„ç­–ç•¥æŠ¥å‘Š
                    const targetReport = document.getElementById(strategyId);
                    if (targetReport) {{
                        targetReport.classList.add('active');
                        
                        // æ»šåŠ¨åˆ°æŠ¥å‘Šä½ç½®
                        window.scrollTo({{
                            top: targetReport.offsetTop - 20,
                            behavior: 'smooth'
                        }});
                    }}
                }}
                
                // ä¿®å¤ï¼šå¤šç§æ–¹å¼ç¡®ä¿åˆå§‹åŒ–ä»£ç æ‰§è¡Œ
                if (document.readyState === 'loading') {{
                    document.addEventListener('DOMContentLoaded', initReports);
                }} else {{
                    initReports();
                }}
                
                // é¢å¤–ä¿é™©ï¼šå»¶è¿Ÿæ‰§è¡Œç¡®ä¿æ‰€æœ‰å…ƒç´ å·²åŠ è½½
                setTimeout(initReports, 100);
            </script>
        </body>
        </html>
        """


def get_nav_html(nav_items: list[str]) -> str:
    return f"""
        <div id="report-nav" style="position: fixed; left: 0; top: 0; width: 250px; height: 100%; 
                overflow-y: auto; background: #f7fafc; padding: 20px; box-shadow: 2px 0 5px rgba(0,0,0,0.1); z-index: 1000;">
            <h3 style="margin: 0 0 15px 0; color: #2d3748;">ç­–ç•¥å¯¼èˆª</h3>
            <ul style="list-style: none; padding: 0; margin: 0;">
                {''.join(nav_items)}
            </ul>
        </div>
        """ if nav_items else ""


def get_final_merged_html(final_merged_output, data_uri, filename, escaped_html, report_height) -> tuple[str]:
    return f"""
        <p>ğŸ“Š åˆå¹¶æŠ¥å‘Š:</p>
        <!-- æµè§ˆå™¨æ¸²æŸ“æ‰“å¼€ï¼ˆé»˜è®¤æ˜¾ç¤ºé¡µé¢æ•ˆæœï¼‰ -->
        <a href="{final_merged_output}" target="_blank" style="display: inline-block; margin-right: 15px; padding: 8px 12px; background: #4CAF50; color: white; text-decoration: none; border-radius: 4px;">
            â†’ ç‚¹å‡»æŸ¥çœ‹HTMLæºæ–‡ä»¶ï¼š{filename}
        </a>
        
        <!-- ä¸‹è½½HTMLæºæ–‡ä»¶ -->
        <a href="{data_uri}" download="{filename}" style="display: inline-block; padding: 8px 12px; background: #2196F3; color: white; text-decoration: none; border-radius: 4px;">
            â†’ ç‚¹å‡»ä¸‹è½½HTMLæºæ–‡ä»¶ï¼š{filename}
        </a>""", f"""
        <div style="margin: 20px 0; border: 1px solid #ddd; border-radius: 5px; padding: 10px;">
            <h4 style="margin-top: 0;">åˆå¹¶æŠ¥å‘Šé¢„è§ˆ</h4>
            <iframe 
                srcdoc='{escaped_html}' 
                width="100%" 
                height="{report_height}" 
                frameborder="0"
                style="border: 1px solid #eee; border-radius: 3px;"
            ></iframe>
            <p style="font-size: 12px; color: #666; margin: 10px 0 0 0;">
                å¦‚æœå›¾è¡¨æœªæ­£å¸¸æ˜¾ç¤ºï¼Œè¯·ç‚¹å‡»ä¸Šæ–¹é“¾æ¥æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š
            </p>
        </div>
        """
