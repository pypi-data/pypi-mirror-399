"""
FedProto èšåˆå™¨

ä»Ž methods/aggregators/fedproto.py è¿ç§»åˆ° src/

å®žçŽ° FedProto (Federated Prototypical Learning) èšåˆç®—æ³•ã€‚
é™¤äº†èšåˆæ¨¡åž‹æƒé‡,è¿˜éœ€è¦èšåˆå„ä¸ªå®¢æˆ·ç«¯çš„ç±»åˆ«åŽŸåž‹(prototypes)ã€‚

è®ºæ–‡: FedProto: Federated Prototype Learning across Heterogeneous Clients
ä½œè€…: Yue Tan et al.
å‘è¡¨: AAAI 2022

ç®—æ³•ç‰¹ç‚¹:
1. ä½¿ç”¨FedAvgèšåˆæ¨¡åž‹æƒé‡
2. èšåˆå®¢æˆ·ç«¯çš„ç±»åˆ«åŽŸåž‹(æŒ‰æ ·æœ¬æ•°åŠ æƒ)
3. åŽŸåž‹ç”¨äºŽå®¢æˆ·ç«¯çš„çŸ¥è¯†è’¸é¦
"""

import torch
from typing import List, Dict, Any
from loguru import logger

from ...core.aggregator import Aggregator
from ...core.types import ClientUpdate
from ...registry import aggregator


@aggregator(
    name='fedproto',
    description='FedProtoåŽŸåž‹èšåˆå™¨',
    version='1.0'
)
class FedProtoAggregator(Aggregator):
    """
    FedProto èšåˆå™¨å®žçŽ°

    æ‰§è¡Œä¸¤ä¸ªå±‚é¢çš„èšåˆ:
    1. æ¨¡åž‹æƒé‡èšåˆ: ä½¿ç”¨FedAvgåŠ æƒå¹³å‡
    2. åŽŸåž‹èšåˆ: èšåˆå„å®¢æˆ·ç«¯çš„ç±»åˆ«åŽŸåž‹

    åŽŸåž‹èšåˆå…¬å¼:
    proto_global[c] = Î£(n_k * proto_k[c]) / Î£(n_k)

    å…¶ä¸­:
    - proto_k[c]: å®¢æˆ·ç«¯kå¯¹ç±»åˆ«cçš„åŽŸåž‹
    - n_k: å®¢æˆ·ç«¯kä¸­ç±»åˆ«cçš„æ ·æœ¬æ•°é‡
    - proto_global[c]: ç±»åˆ«cçš„å…¨å±€åŽŸåž‹

    å‚æ•°:
    - weighted: æ˜¯å¦æŒ‰æ ·æœ¬æ•°é‡åŠ æƒ,é»˜è®¤True
    - device: è®¡ç®—è®¾å¤‡,é»˜è®¤è‡ªåŠ¨æ£€æµ‹
    """

    def __init__(self, weighted: bool = True, **kwargs):
        """åˆå§‹åŒ–FedProtoèšåˆå™¨"""
        # èšåˆé…ç½®
        self._weighted = weighted

        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        device = kwargs.get("device", "auto")
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = device

        # ç»Ÿè®¡ä¿¡æ¯
        self.round_count = 0
        self.total_aggregations = 0

        logger.info(f"âœ… FedProtoèšåˆå™¨åˆå§‹åŒ–å®Œæˆ - åŠ æƒ: {self._weighted}, è®¾å¤‡: {self.device}")

    def aggregate(self, updates: List[ClientUpdate], global_model=None) -> Dict[str, Any]:
        """
        æ‰§è¡ŒFedProtoèšåˆ

        Args:
            updates: å®¢æˆ·ç«¯æ›´æ–°åˆ—è¡¨ (List[ClientUpdate])
            global_model: å…¨å±€æ¨¡åž‹ (å¯é€‰)

        Returns:
            èšåˆç»“æžœå­—å…¸,åŒ…å«:
            - aggregated_weights: èšåˆåŽçš„æ¨¡åž‹æƒé‡
            - global_prototypes: èšåˆåŽçš„å…¨å±€åŽŸåž‹
        """
        if not updates:
            raise ValueError("æ²¡æœ‰å®¢æˆ·ç«¯æ›´æ–°å¯èšåˆ")

        self.round_count += 1
        self.total_aggregations += 1

        logger.debug(f"FedProtoèšåˆè½®æ¬¡ {self.round_count} - {len(updates)} ä¸ªå®¢æˆ·ç«¯")

        # 1. è®¡ç®—èšåˆæƒé‡
        weights = self._compute_aggregation_weights(updates)

        # 2. èšåˆæ¨¡åž‹æƒé‡(ä½¿ç”¨FedAvg)
        aggregated_weights = self._aggregate_model_weights(updates, weights)

        # 3. èšåˆåŽŸåž‹
        global_prototypes = self._aggregate_prototypes(updates, weights)

        logger.debug(
            f"âœ… FedProtoèšåˆå®Œæˆ - æ€»æ ·æœ¬: {sum(u.num_samples for u in updates)}, "
            f"å…¨å±€åŽŸåž‹æ•°: {len(global_prototypes)}"
        )

        # è¿”å›žå­—å…¸éœ€è¦åŒ…å«global_prototypeså­—æ®µ
        return {
            "weights": aggregated_weights,  # å…¼å®¹æ€§: è¿”å›žweightså­—æ®µ
            "global_prototypes": global_prototypes  # FedProtoç‰¹æœ‰
        }

    def _compute_aggregation_weights(self, updates: List[ClientUpdate]) -> List[float]:
        """è®¡ç®—èšåˆæƒé‡"""
        if not self._weighted:
            # å‡ç­‰æƒé‡
            num_clients = len(updates)
            return [1.0 / num_clients] * num_clients

        # æŒ‰æ ·æœ¬æ•°é‡åŠ æƒ
        sample_counts = [update.num_samples for update in updates]
        total_samples = sum(sample_counts)

        if total_samples == 0:
            raise ValueError("æ‰€æœ‰å®¢æˆ·ç«¯çš„æ ·æœ¬æ•°éƒ½ä¸º0,æ— æ³•è¿›è¡ŒåŠ æƒèšåˆ")

        weights = [count / total_samples for count in sample_counts]
        return weights

    def _aggregate_model_weights(self, updates: List[ClientUpdate],
                                 weights: List[float]) -> Dict[str, torch.Tensor]:
        """èšåˆæ¨¡åž‹æƒé‡(ä½¿ç”¨FedAvg)"""
        aggregated_weights = {}

        # èŽ·å–å‚æ•°ç»“æž„
        first_update = updates[0]
        model_weights = first_update.weights
        param_names = list(model_weights.keys())

        # åˆå§‹åŒ–èšåˆæƒé‡
        for param_name in param_names:
            param_shape = model_weights[param_name].shape
            aggregated_weights[param_name] = torch.zeros(param_shape, device=self.device)

        # åŠ æƒèšåˆ
        for i, update in enumerate(updates):
            client_weights = update.weights
            client_weight = weights[i]

            for param_name in param_names:
                if param_name not in client_weights:
                    logger.warning(f"å®¢æˆ·ç«¯ {i} ç¼ºå°‘å‚æ•° {param_name}")
                    continue

                # å°†å‚æ•°ç§»åˆ°æ­£ç¡®è®¾å¤‡å¹¶åŠ æƒ
                param_value = client_weights[param_name]
                if isinstance(param_value, torch.Tensor):
                    param_value = param_value.to(self.device)
                    aggregated_weights[param_name] += client_weight * param_value
                else:
                    aggregated_weights[param_name] += client_weight * param_value

        return aggregated_weights

    def _aggregate_prototypes(self, updates: List[ClientUpdate],
                             weights: List[float]) -> Dict[int, torch.Tensor]:
        """
        èšåˆå®¢æˆ·ç«¯åŽŸåž‹

        åŽŸåž‹èšåˆç­–ç•¥:
        - å¯¹äºŽæ¯ä¸ªç±»åˆ«,æ”¶é›†æ‰€æœ‰æ‹¥æœ‰è¯¥ç±»åˆ«çš„å®¢æˆ·ç«¯çš„åŽŸåž‹
        - æŒ‰ç…§å®¢æˆ·ç«¯æƒé‡è¿›è¡ŒåŠ æƒå¹³å‡
        - å¦‚æžœæŸä¸ªå®¢æˆ·ç«¯æ²¡æœ‰æŸä¸ªç±»åˆ«çš„æ ·æœ¬,åˆ™è·³è¿‡è¯¥å®¢æˆ·ç«¯å¯¹è¯¥ç±»åˆ«çš„è´¡çŒ®
        """
        global_prototypes = {}

        # æ”¶é›†æ‰€æœ‰å‡ºçŽ°çš„ç±»åˆ«
        all_classes = set()
        for update in updates:
            if hasattr(update, 'metadata') and update.metadata and "prototypes" in update.metadata:
                prototypes = update.metadata["prototypes"]
                if prototypes:
                    all_classes.update(prototypes.keys())

        if not all_classes:
            logger.warning("æ²¡æœ‰å®¢æˆ·ç«¯æä¾›åŽŸåž‹,è¿”å›žç©ºåŽŸåž‹å­—å…¸")
            return {}

        logger.debug(f"  èšåˆ {len(all_classes)} ä¸ªç±»åˆ«çš„åŽŸåž‹")

        # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œèšåˆ
        for class_id in all_classes:
            class_prototypes = []
            class_weights = []

            # æ”¶é›†è¯¥ç±»åˆ«çš„æ‰€æœ‰å®¢æˆ·ç«¯åŽŸåž‹
            for i, update in enumerate(updates):
                if not (hasattr(update, 'metadata') and update.metadata and "prototypes" in update.metadata):
                    continue

                prototypes = update.metadata["prototypes"]

                # å¦‚æžœè¯¥å®¢æˆ·ç«¯æœ‰è¿™ä¸ªç±»åˆ«çš„åŽŸåž‹
                if class_id in prototypes:
                    proto = prototypes[class_id]

                    # è·³è¿‡é›¶å‘é‡(è¡¨ç¤ºè¯¥å®¢æˆ·ç«¯æ²¡æœ‰è¯¥ç±»åˆ«çš„æ ·æœ¬)
                    if isinstance(proto, torch.Tensor):
                        if proto.sum().item() != 0:
                            class_prototypes.append(proto)
                            class_weights.append(weights[i])
                    else:
                        # å¤„ç†numpyæ•°ç»„
                        proto_tensor = torch.tensor(proto)
                        if proto_tensor.sum().item() != 0:
                            class_prototypes.append(proto_tensor)
                            class_weights.append(weights[i])

            # è®¡ç®—è¯¥ç±»åˆ«çš„å…¨å±€åŽŸåž‹(åŠ æƒå¹³å‡)
            if class_prototypes:
                # å½’ä¸€åŒ–æƒé‡
                total_weight = sum(class_weights)
                if total_weight > 0:
                    normalized_weights = [w / total_weight for w in class_weights]

                    # åŠ æƒå¹³å‡
                    global_proto = torch.zeros_like(class_prototypes[0])
                    for proto, weight in zip(class_prototypes, normalized_weights):
                        global_proto += weight * proto.to(global_proto.device)

                    global_prototypes[class_id] = global_proto
                    logger.debug(
                        f"    ç±»åˆ« {class_id}: {len(class_prototypes)} ä¸ªå®¢æˆ·ç«¯è´¡çŒ®åŽŸåž‹"
                    )
            else:
                logger.warning(f"    ç±»åˆ« {class_id}: æ²¡æœ‰æœ‰æ•ˆçš„å®¢æˆ·ç«¯åŽŸåž‹")

        return global_prototypes

    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–èšåˆå™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "algorithm": "FedProto",
            "total_rounds": self.round_count,
            "total_aggregations": self.total_aggregations,
            "weighted": self._weighted,
            "device": str(self.device)
        }

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.round_count = 0
        self.total_aggregations = 0
        logger.info("ðŸ”„ FedProtoèšåˆå™¨ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")

    def __repr__(self) -> str:
        return f"FedProtoAggregator(weighted={self._weighted}, device={self.device}, rounds={self.round_count})"
