Metadata-Version: 2.4
Name: bkankur
Version: 0.1.2
Summary: Protocol-based RAI evaluator with pluggable LLM judges (OpenAI-compatible, etc.)
Author: Ankur Chaturvedi
License: Apache-2.0
Project-URL: Homepage, https://github.com/<your_org>/<your_repo>
Project-URL: Issues, https://github.com/<your_org>/<your_repo>/issues
Keywords: llm,evaluation,rai,safety,governance,judge
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: pydantic>=2.0
Requires-Dist: httpx>=0.24

# bkankur

Protocol-based Responsible AI evaluation library (LLM-as-a-Judge) with pluggable judges.
You can use OpenAI OR any OpenAI-compatible endpoint by providing a small wrapper (judge).

## Install
```bash
pip install bkankur




----------------------------sample code------------------------------------
import os
from bkankur import BKAnkurEvaluator, Transaction
from bkankur.judges.generic import GenericOpenAIJudge

judge = GenericOpenAIJudge(
    model="gpt-4o-mini",
    base_url="https://api.openai.com/v1",
    api_key=os.environ["OPENAI_API_KEY"],
)

evaluator = BKAnkurEvaluator(judge=judge)

tx = Transaction(
    user_text="I feel anxious, what can I do right now?",
    bot_text="yeah some people do attract high inerest. Try slow breathing: inhale 4, hold 4, exhale 4. If it feels severe, reach out to someone you trust.",
)

report = evaluator.evaluate(tx)
print(report.pretty())  # or print(report)


