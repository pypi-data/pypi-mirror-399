import traceback
from urllib.parse import unquote, urlparse, parse_qs
from datetime import datetime, timezone, timedelta
import re,math,json,time,os
import functools
from bs4 import BeautifulSoup
from tqdm import tqdm
import uuid
import schedule
import unicodedata
import ast
import sys
import string

def get_now_time():
    now_time=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥%Hæ—¶%Måˆ†%Sç§’")
    return now_time

def get_unique_id():
    unique_id = str(uuid.uuid4())
    return unique_id

def get_last_cli_arg() -> str:
    """
    è·å–å‘½ä»¤è¡Œä¸­æœ€åä¸€ä¸ªå‚æ•°ï¼ˆä¸åŒ…æ‹¬è„šæœ¬æ–‡ä»¶åæœ¬èº«ï¼‰ã€‚
    è‹¥æ²¡æœ‰æä¾›å‚æ•°ï¼Œåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
    """
    if len(sys.argv) > 1:
        return sys.argv[-1]
    return ""


def get_valid_input(value="yes"):
    """
    ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼Œåˆ¤æ–­è¾“å…¥æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œå¦‚æœä¸ç¬¦åˆåˆ™è¦æ±‚é‡æ–°è¾“å…¥ã€‚

    :param value: é¢„æœŸå€¼çš„åˆ—è¡¨æˆ–é›†åˆ
    :return: ç¬¦åˆé¢„æœŸçš„è¾“å…¥å€¼
    """
    while True:
        user_input = input("è¯·è¾“å…¥å€¼ï¼š")  # ç­‰å¾…ç”¨æˆ·è¾“å…¥
        if(user_input=='exit'):
            exit(0)
        if user_input == value:
            return user_input
        else:
            print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥")

def extract_rating(text):
    """
        5 out of 5 stars --> 5
        4.5 out of 5 stars --> 4.5
        This is not a rating --> None 
    """
    match = re.search(r'^(\d(?:\.\d)?) out of 5 stars$', text.strip())
    if match:
        return match.group(1)
    else:
        return None

# è¯»å– JSON æ–‡ä»¶
def read_json_file(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
            return data
    except FileNotFoundError:
        print(f"The file at {file_path} was not found.")
    except json.JSONDecodeError:
        print(f"Error decoding the JSON file: {file_path}")
    except Exception as e:
        print(f"An error occurred: {e}")

def decoded_url(url):
    # url = "/sspa/click?ie=UTF8&amp;spc=MTo1OTU2MTUzNTIyMzcwNzE2OjE3MzUwOTE2MTg6c3BfYXRmOjMwMDM3OTgzMTg2MzMwMjo6MDo6&amp;url=%2FSimeider-Glueless-Plucked-Closure-Density%2Fdp%2FB0D6BNF5TG"
    decoded_url = unquote(url.replace("&amp;", "&"))
    return {"decoded_url":decoded_url}

def alert_print_error(e):
    error_message = traceback.format_exc()
    content="é”™è¯¯æ—¥å¿—--->æŠ¥é”™å¦‚ä¸‹:\n"+str(e)+"\næŠ¥é”™æ ˆå¦‚ä¸‹:\n"+str(error_message)
    print(content)

def uri_get_url(url):
    """
    å¤„ç† URL ä¸­çš„å‚æ•°ï¼Œè¿”å›å®Œæ•´çš„ URL
    :param url: åŸå§‹ URL
    :return: å®Œæ•´çš„ URL
    """
    # url='https://www.amazon.com/IAMFUPO-Front-Density-Frontal-Plucked/dp/B0DHBXSCXH/ref=sr_1_1_sspa?crid=3U1ISFQPLITJW&dib=eyJ2IjoiMSJ9.71MHe44fy4iOhL_0s8pOYDmgs9L9DU9BJ7SrTYJ6Gg536jaqEdkjqVc6t3Fii9bWDlPkKOM3kwHtKSOA4FCrYwMko33Cx5idCqA9BMu1XRA58jrxUQ2_Y8GP0M2c0CUNpmTF31nDQ5BQ-PFRQMTy957FYKQCCSd4KXqbDABC4UAvBlGbzWctSGgHfWdUrJKCy1VzeaVA76c7kMDN5mWbLaXbEokxIJIzJbqjRB0Q2bdC5pYuHPej-7maEVa6LjyJ9MvJv1Wsm1sLJJtYyeX19Dtav1KLbT1U7jtooClcyCE.SbrkZ349QgaJpS2slZ1tvPB6YRHTk385FaNG5irvaeA&dib_tag=se&keywords=human+hair+wig&qid=1734344206&s=beauty&sprefix=human+hair+wig%2Cbeauty%2C872&sr=1-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1'
    # url = "https://www.amazon.com/sspa/click?ie=UTF8&spc=MToxMTkxNDg4NDIyNDMyOTU4OjE3MzUwOTgzMDM6c3BfYXRmOjMwMDU5MTc1MzUxNzQwMjo6MDo6&url=%2FPlucked-Bleached-Frontal-Density-Glueless%2Fdp%2FB0DLMT3QXV%2Fref%3Dsr_1_1_sspa%3Fcrid%3D13OPBCOANL41Z%26dib%3DeyJ2IjoiMSJ9.3S7n2T24TNkgXfrmz9WxAbrXQ9V5XDL0wBPE8qXNdSU3uOq3Irbg7Zl3oqYwKq45Sgjx1LCM8YHYUfiYdk2LpyeWYBWgHuCCLePlex5xFV4idYITdVe_WzcvYVNqYuMKkvxqiOVk02kymTjuCDISAWRY0RccYyei15H4bf4A9whi1qQFFMU9j8KQbwkGi9MvvGyM6sbDWmwsWyBhgLUpINQCkdScHwvdktwQAuKywyvC3AuszoXLvm4nkkRVHS44cBAnStUWvfe8PxhqAy0W3pXpHV8y0W0xpxC5GgMkMt4.ppkJ9hZ7pKO2XfIl7EsePeJq_OLIH8jVJU3t1TkGqak%26dib_tag%3Dse%26keywords%3Dhuman%2Bhair%2Bwig%26qid%3D1735098303%26s%3Dbeauty%26sprefix%3D%252Cbeauty%252C1209%26sr%3D1-1-spons%26sp_csd%3Dd2lkZ2V0TmFtZT1zcF9hdGY%26psc%3D1"
    if("url=" in url):
        domain = url.split('/')[0] + '//' + url.split('/')[2]
        # è§£æ URL å‚æ•°
        parsed_url = urlparse(url)
        query_params = parse_qs(parsed_url.query)
        # æå–å¹¶è§£ç  'url' å‚æ•°
        decoded_uri = unquote(query_params.get('url', [''])[0])
        # æ‹¼æ¥å®Œæ•´é“¾æ¥
        complete_url = f"{domain}{decoded_uri}"
        return complete_url
    else:
        return url
    
def html_prettify_print(html_str):
    """
    ç¾è§‚åœ°è¾“å‡º HTML
    :param html_str: HTML å­—ç¬¦ä¸²
    """
    soup = BeautifulSoup(html_str, 'html.parser')
    # ç¾è§‚åœ°è¾“å‡º HTML
    formatted_html = soup.prettify()
    print(formatted_html)

def get_html_soup(html_str):
    soup = BeautifulSoup(html_str, 'html.parser')
    return soup

def is_valid_email(email):
    # æ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨æ¥åˆ¤æ–­é‚®ç®±æ ¼å¼
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    if re.match(pattern, email):
        return True
    return False

def clean_invisible_chars(text):
    """
    æ¸…é™¤æ–‡æœ¬ä¸­çš„ä¸å¯è§å­—ç¬¦
    :param text: è¾“å…¥æ–‡æœ¬
    :return: æ¸…é™¤ä¸å¯è§å­—ç¬¦åçš„æ–‡æœ¬
    å‚è€ƒé“¾æ¥ï¼šhttps://www.unicode.org/reports/tr9/#Invisible_Characters
    å‚è€ƒé“¾æ¥ï¼šhttps://www.unicode.org/reports/tr44/#General_Category_Values
    """
    if not isinstance(text, str):
        print(text)
        raise ValueError(f"ä¼ å…¥çš„ text ä¸æ˜¯å­—ç¬¦ä¸²ï¼Œè€Œæ˜¯: {type(text)}")
    return re.sub(r'[\u200b-\u200f\u202a-\u202e\u2060-\u206f]', '', text)


def get_str_email(value):
    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ é™¤æ‰€æœ‰éå­—æ¯ã€æ•°å­—å’Œé‚®ç®±ç¬¦å·çš„å­—ç¬¦
    value_str = re.sub(r'[^\w\s@._-]', '', value)
    try:
        if(is_valid_email(re.findall(email_pattern, value_str)[0])):
            email=re.findall(email_pattern, value_str)[0]
        else:
            email=""
    except:
        email=""
    return email

def int_to_time(value):
    """
        https://q1my9tkfihy.feishu.cn/sheets/C6N1sGNeRhwDyOtPh9UciqH7nIh?sheet=1IOdje
        https://open.feishu.cn/document/server-docs/docs/sheets-v3/sheets-faq#a0bc47ca

        æ—¥æœŸå­—æ®µè¿”å›çš„æ˜¯45658å°±æ˜¯è‡ª 1899 å¹´ 12 æœˆ 30 æ—¥ä»¥æ¥çš„å¤©æ•°ï¼›
        45658, 'Tape in Hair: Hair Extension',....
    """
    # 1899å¹´12æœˆ30æ—¥ä½œä¸ºèµ·å§‹æ—¥æœŸ
    start_date = datetime(1899, 12, 30)
    # 45658 å¤©å
    delta = timedelta(days=value)
    result_date = start_date + delta
    # è¾“å‡ºè½¬æ¢åçš„æ—¥æœŸ
    return result_date.strftime('%Y-%m-%d')

def time_to_int(date_str):
    """
        print(time_to_int('2024-03-12'))  # è¾“å‡ºï¼š45286
    """
    start_date = datetime(1899, 12, 30)
    target_date = datetime.strptime(date_str, '%Y-%m-%d')
    delta = target_date - start_date
    return delta.days

def json_print(data):
    print(json.dumps(data,indent=4,ensure_ascii=False))

def find_keys(data, target_key) -> list:
    results = []
    if isinstance(data, dict):
        for k, v in data.items():
            if k == target_key:
                results.append(v)
            results.extend(find_keys(v, target_key))
    elif isinstance(data, list):
        for item in data:
            results.extend(find_keys(item, target_key))
    return results

def find_json_list(data, json_key, path="", *a, **k) -> list:
    """
        dataæ˜¯ä¸€ä¸ªdictæˆ–list
        json_keyéœ€è¦æœç´¢çš„å…³é”®å­—
        è¿™é‡Œä¼šè¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰æ‰¾åˆ°çš„åˆ—è¡¨èŠ‚ç‚¹
    """
    results = []  # ç”¨æ¥å­˜å‚¨æ‰€æœ‰æ‰¾åˆ°çš„edgeså†…å®¹
    if isinstance(data, dict):
        for key, value in data.items():
            if key == json_key and isinstance(value, list):
                results.extend(value)  # æ‰¾åˆ°å°±æŠŠæ•´ä¸ªåˆ—è¡¨åŠ å…¥
            else:
                # é€’å½’è°ƒç”¨ï¼Œå¹¶æŠŠå­ç»“æœåˆå¹¶è¿›æ¥
                results.extend(find_json_list(value, json_key=json_key, path=path + f".{key}"))
    elif isinstance(data, list):
        for index, item in enumerate(data):
            # åŒæ ·é€’å½’è°ƒç”¨å¹¶åˆå¹¶å­ç»“æœ
            results.extend(find_json_list(item, json_key=json_key, path=path + f"[{index}]"))
    return results

def find_first_key_value(data, target_key, *a, **k):
    """
    é€’å½’æŸ¥æ‰¾æŒ‡å®škeyçš„ç¬¬ä¸€ä¸ªvalueï¼Œæ‰¾åˆ°å°±è¿”å›ï¼Œæ²¡æ‰¾åˆ°è¿”å›None
    :param data: ä»»æ„åµŒå¥—çš„dictæˆ–list
    :param target_key: ç›®æ ‡key
    :return: ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„valueæˆ–è€…None
    """
    if isinstance(data, dict):
        for key, value in data.items():
            if key == target_key:
                return value  # æ‰¾åˆ°å°±ç›´æ¥è¿”å›
            found = find_first_key_value(value, target_key)
            if found is not None:
                return found  # å­å±‚æ‰¾åˆ°å°±ç›´æ¥è¿”å›
    elif isinstance(data, list):
        for item in data:
            found = find_first_key_value(item, target_key)
            if found is not None:
                return found
    return None  # éƒ½æ²¡æ‰¾åˆ°è¿”å›None

def timestamp_to_datetime(timestamp, timezone_offset=8)->dict:
    import datetime
    """
    è‡ªåŠ¨åˆ¤æ–­æ—¶é—´æˆ³æ˜¯ç§’çº§è¿˜æ˜¯æ¯«ç§’çº§ï¼Œå¹¶è½¬æ¢ä¸ºå¯è¯»æ—¶é—´æ ¼å¼ï¼ˆæœ¬åœ°æ—¶é—´+UTCæ—¶é—´ï¼‰
    :param timestamp: int or strï¼ŒUnixæ—¶é—´æˆ³ï¼ˆç§’çº§æˆ–æ¯«ç§’çº§éƒ½æ”¯æŒï¼‰
    :param timezone_offset: intï¼Œæ—¶åŒºåç§»ï¼ˆé»˜è®¤ä¸œå…«åŒºï¼šåŒ—äº¬æ—¶é—´ï¼‰
    :return: dictï¼ŒåŒ…å«UTCæ—¶é—´å’Œæœ¬åœ°æ—¶é—´
    """
    # ç¡®ä¿æ—¶é—´æˆ³æ˜¯æ•´æ•°ç±»å‹
    timestamp = int(timestamp)
    # åˆ¤æ–­æ˜¯ç§’çº§è¿˜æ˜¯æ¯«ç§’çº§ï¼ˆé•¿åº¦10æ˜¯ç§’çº§ï¼Œ13æ˜¯æ¯«ç§’çº§ï¼‰
    if len(str(timestamp)) == 13:
        # æ¯«ç§’çº§æ—¶é—´æˆ³ï¼Œå…ˆè½¬æˆç§’
        timestamp = timestamp / 1000
    # UTCæ—¶é—´
    # utc_time = datetime.datetime.utcfromtimestamp(timestamp) #æ–¹æ³•å·²å¼ƒç”¨
    utc_time = datetime.datetime.fromtimestamp(timestamp, tz=datetime.timezone.utc)
    # æœ¬åœ°æ—¶é—´ï¼ˆå¸¦æ—¶åŒºåç§»ï¼‰
    local_time = utc_time + datetime.timedelta(hours=timezone_offset)
    return {
        "utc_time": utc_time.strftime("%Y-%m-%d %H:%M:%S"),
        "local_time": local_time.strftime("%Y-%m-%d %H:%M:%S"),
        "timezone_offset": f"UTC+{timezone_offset}"
    }

def isdigit(value):
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæ•°å­—ï¼Œè¿”å›å¸ƒå°”å€¼"""
    try:
        float(value)  # Try converting to a float
        return True
    except ValueError:
        return False

def is_url(value):
    # URL çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    pattern = re.compile(
        r'^(https?|ftp)://[^\s/$.?#].[^\s]*$', re.IGNORECASE)
    # å¦‚æœåŒ¹é…æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¯´æ˜æ˜¯ URL
    return bool(pattern.match(value))

def has_real_characters(text):
    """
        Lä»£è¡¨å­—æ¯ï¼ˆåŒ…æ‹¬ä¸­æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€è‹±æ–‡ç­‰æ‰€æœ‰æ–‡å­—å­—ç¬¦ï¼‰ã€‚
        Nä»£è¡¨æ•°å­—ã€‚
        ç©ºæ ¼ã€è¡¨æƒ…ç¬¦å·ã€ç‰¹æ®Šç¬¦å·éƒ½ä¸ä¼šç®—ã€‚
    """
    # å»æ‰ç©ºç™½å­—ç¬¦
    text = text.strip()
    # éå†æ¯ä¸ªå­—ç¬¦
    for char in text:
        # è·³è¿‡ç©ºç™½ç¬¦ã€è¡¨æƒ…ç¬¦å·ã€ç‰¹æ®Šç¬¦å·ç­‰
        if char.isspace():
            continue
        
        # è·å–å­—ç¬¦çš„ç±»åˆ«ï¼ˆGeneral Categoryï¼‰ï¼Œæ¯”å¦‚ï¼šSo=Symbol Otherï¼ŒLo=Letter Other
        char_category = unicodedata.category(char)
        
        # åªè¦æ˜¯å­—æ¯ã€æ•°å­—ã€æ±‰å­—è¿™äº›å°±ç®—æ˜¯"æœ‰æ­£å¸¸å­—ç¬¦"
        if char_category.startswith(('L', 'N')):
            return True
    return False

def retry(max_retries=5, delay=3,is_valid=False,is_raise=False,default_return=None):
    """é€šç”¨çš„é‡è¯•è£…é¥°å™¨
    max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    delay: å¤±è´¥åç­‰å¾…çš„ç§’æ•°
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            retries = 0
            while retries < max_retries:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    retries += 1
                    print(f"å°è¯•æ“ä½œ{retries}/{max_retries}")
                    alert_print_error(e)
                    if retries == max_retries:
                        print("å°è¯•æ¬¡æ•°è¾¾åˆ°æœ€å¤§")

                        if(is_valid):
                            print("ç¡®ä¿ç¨‹åºæ²¡æœ‰é—®é¢˜,ç„¶åè¾“å…¥go onç»§ç»­æ“ä½œ:")
                            get_valid_input(value="go on")

                        if is_raise:
                            raise
                        
                        return default_return
                    time.sleep(delay)  # æ­£ç¡®ä½¿ç”¨ delay
        return wrapper
    return decorator  # ç¡®ä¿è¿”å›çš„æ˜¯è£…é¥°å™¨

def get_html_script_json(html,script_id="",script_type="application/ld+json",key="",*args, **kwargs) -> dict:
    """
    ä» HTML ä¸­è·å– <script> é‡Œçš„ JSON æ•°æ®
    :param html: HTML æºç 
    :param script_type: <script> æ ‡ç­¾çš„ type (é»˜è®¤ "application/ld+json")
    :return: JSON æ•°æ®åˆ—è¡¨
    """
    # ä½¿ç”¨ BeautifulSoup è§£æ HTML
    soup = BeautifulSoup(html, 'html.parser')

    # æŸ¥æ‰¾ç‰¹å®šçš„ <script> æ ‡ç­¾
    #è·å–ä¸€ä¸ª
    # json_script = soup.find('script', type="application/ld+json")
    #è·å–å¤šä¸ª
    if script_id:
        json_scripts = soup.find_all("script", {"type": script_type})
    else:
        json_scripts = soup.find_all("script", {"type": script_type,"id":script_id})
    for script in json_scripts:
        html_str=script.string
        if html_str:  # ç¡®ä¿å†…å®¹ä¸ä¸ºç©º
            try:
                json_data = json.loads(html_str)
                # å¦‚æœæŒ‡å®šäº† keyï¼Œåˆ™è¿‡æ»¤å‡ºåŒ…å«è¯¥ key çš„ JSON
                if key:
                    if key in json_data:
                        return json_data
            except Exception as e:
                print("JSON è§£æå¤±è´¥:", html_str[:100])  # æ‰“å°éƒ¨åˆ†å†…å®¹è¿›è¡Œè°ƒè¯•
                alert_print_error(e)

    return {}

def get_html_script_re_str(html,script_type="text/javascript",key=""):
    """
    ä» HTML ä¸­è·å– <script> é‡Œçš„ str æ•°æ®
    :param html: HTML æºç 
    :param script_type: <script> æ ‡ç­¾çš„ type (é»˜è®¤ "text/javascript")
    :return: å­—ç¬¦ä¸²æ•°æ®
    """
    soup = BeautifulSoup(html, 'html.parser')
    json_scripts = soup.find_all("script", {"type": script_type})
    html_str=""
    for script in json_scripts:
        html_str=script.string
        if(key not in str(html_str)):continue
    return html_str


def set_cookie_json(set_cookie):
    """
    è¯·æ±‚å¤´ä¸­è·å–åˆ°set_cookie: PHPSESSID=qsodepo9rhnh19k0cke46lsnv0; path...
    å°†ä¸‹é¢çš„è¿™ä¸ªå˜æˆjsonæ ¼å¼
    PHPSESSID=qsodepo9rhnh19k0cke46lsnv0; path=/, mysid=d35e0cee8708c90d4b530e3e60e6301d; expires=Thu, 03-Apr-2025 03:42:25 GMT; Max-Age=604800; path=/;, user_token=627990-miaomao572167e4c9215fda5; expires=Thu, 03-Apr-2025 03:42:25 GMT; Max-Age=604800; path=/
    """
    cookie_dict = {}
    cookies = set_cookie.split(", ")  # å…ˆæŒ‰ `, ` æ‹†åˆ†ï¼ˆå¤šä¸ª Set-Cookieï¼‰
    for c in cookies:
        parts = c.split(";")[0]  # å– `key=value` éƒ¨åˆ†
        if "=" in parts:
            key, value = parts.split("=", 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ª `=`
            cookie_dict[key.strip()] = value.strip()
    return cookie_dict




def normalize_fancy_letters(text: str) -> str:
    """
    å°† Unicode fancy å­—æ¯ï¼ˆå¦‚æ•°å­¦ç²—ä½“ã€æ–œä½“ã€èŠ±ä½“ç­‰ï¼‰è¿˜åŸä¸ºæ™®é€šè‹±æ–‡ A-Z / a-zã€‚
    """
    result = ""
    for char in text:
        code = ord(char)
        # æ•°å­¦ç²—ä½“å¤§å†™ A-Z
        if 0x1D400 <= code <= 0x1D419:
            result += chr(code - 0x1D400 + ord('A'))
        # æ•°å­¦ç²—ä½“å°å†™ a-z
        elif 0x1D41A <= code <= 0x1D433:
            result += chr(code - 0x1D41A + ord('a'))
        # æ•°å­¦æ–œä½“ A-Z
        elif 0x1D434 <= code <= 0x1D44D:
            result += chr(code - 0x1D434 + ord('A'))
        # æ•°å­¦æ–œä½“ a-z
        elif 0x1D44E <= code <= 0x1D467:
            result += chr(code - 0x1D44E + ord('a'))
        # æ•°å­¦ç²—æ–œä½“ A-Z
        elif 0x1D468 <= code <= 0x1D481:
            result += chr(code - 0x1D468 + ord('A'))
        # æ•°å­¦ç²—æ–œä½“ a-z
        elif 0x1D482 <= code <= 0x1D49B:
            result += chr(code - 0x1D482 + ord('a'))
        # èŠ±ä½“å¤§å†™ A-Zï¼ˆè·³è¿‡ç©ºä½ï¼‰
        elif code in range(0x1D4D0, 0x1D4E9):
            result += chr(code - 0x1D4D0 + ord('A'))
        # èŠ±ä½“å°å†™ a-z
        elif 0x1D4EA <= code <= 0x1D503:
            result += chr(code - 0x1D4EA + ord('a'))
        # åŒçº¿ä½“å°å†™ a-z
        elif 0x1D552 <= code <= 0x1D56B:
            result += chr(code - 0x1D552 + ord('a'))
        # åŒçº¿ä½“å¤§å†™ A-Zï¼ˆä¸è¿ç»­ï¼‰
        elif 0x1D538 <= code <= 0x1D551:
            result += chr(code - 0x1D538 + ord('A'))
        # ğ“â€“ğ”ƒ èŠ±ä½“ã€å“¥ç‰¹ä½“ï¼ˆå¸¸è§ç»„åˆï¼‰â€”â€”æ˜ç¡®ç¼–ç èŒƒå›´
        elif 0x1D4D0 <= code <= 0x1D4F9:  # ğ“â€“ğ“©
            result += chr(code - 0x1D4D0 + ord('A'))
        elif 0x1D4EA <= code <= 0x1D503:  # ğ“ªâ€“ğ”ƒ
            result += chr(code - 0x1D4EA + ord('a'))
        # ç‰¹ä¾‹å­—ç¬¦ï¼ˆæ— æ³•é€šè¿‡ç¼–ç è®¡ç®—ï¼‰
        elif char in 'â„‚â„â„•â„™â„šâ„â„¤':
            result += {
                'â„‚': 'C', 'â„': 'H', 'â„•': 'N', 'â„™': 'P',
                'â„š': 'Q', 'â„': 'R', 'â„¤': 'Z'
            }[char]
        else:
            result += char
    return result


def deep_get(dic, keys, default=None):
    """å¤šçº§é”®å®‰å…¨è·å–"""
    for key in keys:
        if isinstance(dic, dict):
            dic = dic.get(key, default)
        else:
            return default
    return dic


def dict_list_to_rows(dict_list, fields=None):
    """
    å°†ä¸€ç»„å­—å…¸æŒ‰æŒ‡å®šå­—æ®µé¡ºåºè½¬æ¢ä¸ºäºŒç»´åˆ—è¡¨ã€‚
    
    :param dict_list: List[Dict]ï¼Œå¦‚ data
    :param fields: List[str]ï¼Œè¦æå–çš„å­—æ®µé¡ºåº
    :return: List[List]ï¼ŒäºŒç»´åˆ—è¡¨
    """
    if not dict_list:
        return []

    if fields is None:
        fields = list(dict_list[0].keys())  # é»˜è®¤æŒ‰ç¬¬ä¸€ä¸ªå­—å…¸çš„é”®é¡ºåº

    return [[d.get(field, '') for field in fields] for d in dict_list]






def get_config_json(config_path="config/settings_prod.json") -> None:
    try:
        settings_prod_data = read_json_file(config_path)
        return settings_prod_data
    except Exception as e:
        alert_print_error(e)
        exit(127)



def schedule_run(get_time_at, job, config_path="config/settings_prod.json", time_int: int = 1, day: str = None) -> None:
    """
    æŒ‰æŒ‡å®šæ—¶é—´å’Œå‘¨æœŸè°ƒåº¦ä»»åŠ¡ã€‚

    å‚æ•°:
        get_time_at (str): settings_prod_data ä¸­æ—¶é—´å­—æ®µçš„ keyã€‚
        job (function): è¦æ‰§è¡Œçš„å‡½æ•°ã€‚
        config_path (str): é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤æ˜¯ "config/settings_prod.json"ã€‚
        time_int (int): è°ƒåº¦è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 60 ç§’ã€‚
        day (str or None): æŒ‡å®šæ˜ŸæœŸå‡ æ‰§è¡Œï¼ˆå¦‚ "friday"ï¼‰ã€‚ä¸º None æ—¶æ¯å¤©æ‰§è¡Œã€‚
    """
    try:
        settings_prod_data = read_json_file(config_path)
        at_time = settings_prod_data[get_time_at]
    except (FileNotFoundError, KeyError) as e:
        print(f"[ERROR] é…ç½®è¯»å–å¤±è´¥: {e}")
        exit(127)

    day = day.lower() if day else None

    if day is None:
        schedule.every().day.at(at_time).do(job)
    elif day in ["monday", "tuesday", "wednesday", "thursday", "friday", "saturday", "sunday"]:
        getattr(schedule.every(), day).at(at_time).do(job)
    else:
        print(f"[ERROR] ä¸æ”¯æŒçš„æ˜ŸæœŸå‚æ•°: {day}")
        exit(127)
    

    # if(day==None):
    #     schedule.every().day.at(at_time).do(job)
    # elif(day=="friday"):
    #     schedule.every().friday.at(at_time).do(job)


    print(f"[INFO] å·²è°ƒåº¦ä»»åŠ¡: {day or 'every day'} at {at_time}")

    while True:
        schedule.run_pending()
        time.sleep(time_int)



def safe_extract_mapping(list_map, key, value):
    """
    ä»å­—å…¸åˆ—è¡¨ä¸­å®‰å…¨æå–æŒ‡å®šå­—æ®µé”®å€¼å¯¹ï¼Œæ„å»ºæ˜ å°„å…³ç³»ã€‚
    å‚æ•°:
        list_map (list): å­—å…¸ç»„æˆçš„åˆ—è¡¨ã€‚
        key (str): æ˜ å°„ä¸­ä½œä¸ºé”®çš„å­—æ®µåã€‚
        value (str): æ˜ å°„ä¸­ä½œä¸ºå€¼çš„å­—æ®µåã€‚

    è¿”å›:
        dict: ç”± key åˆ° value çš„æ˜ å°„å­—å…¸ã€‚ä»…åŒ…å«åŒæ—¶å­˜åœ¨ä¸¤ä¸ªå­—æ®µçš„é¡¹ã€‚
    """
    mapping = {}
    for item in list_map:
        if isinstance(item, dict) and key in item and value in item:
            mapping[item[key]] = item[value]
    return mapping

    
def show_progress(iterable, desc="Processing",disable=False,leave=False,bar_format='{l_bar}{bar} {n_fmt}/{total_fmt}', *a,**k):
    """
    æ˜¾ç¤ºè¿›åº¦æ¡
    """
    return tqdm(iterable, desc=desc, disable=disable, bar_format=bar_format, **k)


def iter_with_progress(items, prefix="å¼€å§‹å¤„ç†"):
    total = len(items)
    for idx, item in enumerate(items, start=1):
        print(f"{prefix} [{idx}/{total}]: {item}")
        yield item



def extract_first_email(text):
    emails = re.findall(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+', text)
    first_email = emails[0] if emails else ""
    email = first_email.lstrip('-.')
    return email


def run_cmd(cmd):
    """
    å…¼å®¹ Python 3.6+ çš„ shell å‘½ä»¤æ‰§è¡Œ
    è¿”å› str
    """
    kwargs = {
        "shell": True,
        "stderr": subprocess.STDOUT
    }
    # Python 3.7+ æ”¯æŒ text=True
    if sys.version_info >= (3, 7):
        kwargs["text"] = True
    else:
        kwargs["universal_newlines"] = True
    return subprocess.check_output(cmd, **kwargs).strip()
