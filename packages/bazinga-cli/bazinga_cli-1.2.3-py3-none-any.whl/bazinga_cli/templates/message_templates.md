# UI Message Templates

These are the standard message formats for displaying orchestration progress to users.

## ğŸ“ Compact Progress Capsule Format (MANDATORY)

**All user-visible updates MUST use the capsule format:**

```
[Emoji] [Action/Phase] | [Key Observation] | [Decision/Outcome] â†’ [Next Step]
```

**Rules:**
1. âœ… One capsule per major state transition
2. âœ… Include intent when spawning agents
3. âœ… Surface problems and solutions (not just status)
4. âœ… Link to artifacts for detail > 3 lines
5. âŒ Never output database operations
6. âŒ Never output role checks
7. âŒ Never output routing mechanics ("forwarding to...", "received from...")

---

## Initialization Messages

### Session Start (Basic - for simple requests)
```
ğŸš€ Starting orchestration | Session: {session_id}
```

### Session Start (Enhanced - for complex requests)

**Use this format when the task involves multiple phases, spec files, or complex requirements:**

```markdown
ğŸš€ **BAZINGA Orchestration Starting**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Session:** {session_id}
**Input:** {source_file_or_description}

**Workflow Overview:**
1. ğŸ“‹ PM analyzes requirements â†’ execution plan
2. ğŸ”¨ Developers implement in parallel
3. âœ… QA validates tests + coverage
4. ğŸ‘” Tech Lead reviews security + architecture
5. ğŸ“‹ PM validates criteria â†’ BAZINGA

Spawning Project Manager for analysis...
```

**Note:** Task count is determined by PM during analysis, not shown at init.

**Example:**
```markdown
ğŸš€ **BAZINGA Orchestration Starting**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Session:** bazinga_20251125_114715
**Input:** tasks2.md

**Workflow Overview:**
1. ğŸ“‹ PM analyzes requirements â†’ execution plan
2. ğŸ”¨ Developers implement in parallel
3. âœ… QA validates tests + coverage
4. ğŸ‘” Tech Lead reviews security + architecture
5. ğŸ“‹ PM validates criteria â†’ BAZINGA

Spawning Project Manager for analysis...
```

---

## Planning Phase Messages

### Execution Plan Ready (After PM Planning)

**Use this format after PM completes planning to show the full execution plan:**

```markdown
ğŸ“‹ **Execution Plan Ready**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Mode:** {mode} ({N} concurrent developers)
**Tasks:** {task_count} across {phase_count} phases

**Phases:**
> Phase 1: {phase_name} - Groups {group_ids}
> Phase 2: {phase_name} - Groups {group_ids}

**Success Criteria:**
â€¢ {criterion_1}
â€¢ {criterion_2}

**Starting:** Phase 1 with Groups {ids}
```

**Note:** Use markdown blockquotes (>) instead of box-drawing characters for terminal compatibility.

**Example:**
```markdown
ğŸ“‹ **Execution Plan Ready**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Mode:** Parallel (3 concurrent developers)
**Tasks:** 12 across 2 phases

**Phases:**
> Phase 1: Foundation Setup - Groups A, B, C
>   â€¢ Group A: Database schema + models
>   â€¢ Group B: Authentication infrastructure
>   â€¢ Group C: Core API structure
>
> Phase 2: Feature Implementation - Groups D, E, F
>   â€¢ Group D: User management endpoints
>   â€¢ Group E: Product catalog service
>   â€¢ Group F: Order processing logic

**Success Criteria:**
â€¢ All tests passing (zero tolerance for failures)
â€¢ Coverage >70% on new code
â€¢ No high/critical security vulnerabilities

**Starting:** Phase 1 with Groups A, B, C
```

### Planning in Progress
```
ğŸ“‹ Analyzing requirements | {brief_context} | Planning execution strategy
```

**Example:**
```
ğŸ“‹ Analyzing requirements | JWT auth + user registration + password reset | Planning execution strategy
```

### Planning Complete - Simple Mode
```
ğŸ“‹ Planning complete | Single-group execution: {task_summary} | Starting development
```

**Example:**
```
ğŸ“‹ Planning complete | Single-group execution: JWT authentication (5 files, 12 tasks) | Starting development
```

### Planning Complete - Parallel Mode
```
ğŸ“‹ Planning complete | {N} parallel groups: {group_summaries} | Starting development â†’ Groups {list}
```

**Example:**
```
ğŸ“‹ Planning complete | 3 parallel groups: JWT auth (5 files), User reg (3 files), Password reset (4 files) | Starting development â†’ Groups A, B, C
```

### PM Needs Clarification
```
âš ï¸ PM needs clarification | {blocker_type}: {question_summary} | Awaiting response (auto-proceed with fallback in 5 min)
```

**Example:**
```
âš ï¸ PM needs clarification | Missing external data: Should we use Stripe test mode or production mode? | Awaiting response (auto-proceed with fallback in 5 min)
```

---

## Development Phase Messages

### Work in Progress
```
ğŸ”¨ Group {id} [{tier}/{model}] implementing | {files_created/modified}, {tests_added} ({coverage}% coverage) | {current_status}
```

**Tier notation:** `[SSE]` for Senior Software Engineer, `[Dev]` for Developer. For backward compatibility, brackets are optional and may be omitted if tier information is unavailable.

**Examples:**
```
ğŸ”¨ Group A [SSE] implementing | auth_middleware.py + jwt_utils.py created, 12 tests added (92% coverage) | Tests passing â†’ QA review

ğŸ”¨ Group B [Dev] implementing | user_service.py in progress (8/12 tests passing) | Fixing validation edge cases

ğŸ”¨ Group C [SSE] implementing | password_reset.py complete, coverage at 78% | Adding missing tests
```

### Developer Work Complete
```
ğŸ”¨ Group {id} [{tier}/{model}] complete | {summary_of_work} | {status} â†’ {next_phase}
```

**Examples:**
```
ğŸ”¨ Group A [SSE] complete | JWT auth implemented in 3 files, 12 tests added (92% coverage) | No blockers â†’ QA review

ğŸ”¨ Group B [Dev] complete | User registration with validation, 15 tests (88% coverage) | Ready â†’ QA testing
```

---

## QA Phase Messages

### QA Testing
```
âœ… Group {id} testing | Running {test_count} tests + coverage analysis | Validating implementation
```

**Example:**
```
âœ… Group A testing | Running 12 tests + coverage analysis | Validating implementation
```

### QA Pass
```
âœ… Group {id} tests passing | {test_results}, {coverage}% coverage, {quality_signals} | Approved â†’ Tech Lead review
```

**Examples:**
```
âœ… Group A tests passing | 12/12 tests passed, 92% coverage, security clear | Approved â†’ Tech Lead review

âœ… Group B tests passing | 15/15 tests passed, 88% coverage, no vulnerabilities | Approved â†’ Code review
```

### QA Fail
```
âš ï¸ Group {id} QA failed | {failure_summary} â†’ See {artifact_path} | Developer fixing
```

**Examples:**
```
âš ï¸ Group B QA failed | 3/15 tests failing (auth edge cases) â†’ See bazinga/artifacts/{SESSION_ID}/qa_failures.md | Developer fixing

âš ï¸ Group C QA failed | 5 tests timeout (performance regression) â†’ See bazinga/artifacts/{SESSION_ID}/qa_failures.md | Investigating
```

---

## Tech Lead Review Messages

### Review in Progress
```
ğŸ‘” Group {id} reviewing | Security scan + lint check + architecture analysis | Evaluating quality
```

**Example:**
```
ğŸ‘” Group A reviewing | Security scan + lint check + architecture analysis | Evaluating quality
```

### Review Approved
```
âœ… Group {id} approved | {quality_summary} | Complete ({completed}/{total} groups)
```

**Examples:**
```
âœ… Group A approved | Security clear, 0 lint issues, architecture solid | Complete (1/3 groups)

âœ… Group B approved | 2 medium security issues fixed, all tests passing, code quality excellent | Complete (2/3 groups)
```

### Review - Changes Requested
```
âš ï¸ Group {id} needs revision | {issue_summary} | Fixes required â†’ Developer
```

**Examples:**
```
âš ï¸ Group C needs revision | 1 high security issue (SQL injection) + 3 lint errors | Fixes required â†’ Developer

âš ï¸ Group A needs revision | Test coverage below 80% (currently 72%) | Add missing tests â†’ Developer
```

### Review - Escalation to Opus
```
ğŸ”¬ Group {id} complexity detected | {reason_for_escalation} | Escalating to Opus â†’ Tech Lead (Rev {N})
```

**Example:**
```
ğŸ”¬ Group C complexity detected | Persistent architecture issues after 2 revisions | Escalating to Opus â†’ Tech Lead (Rev 3)
```

### Review - Spawn Investigator
```
ğŸ”¬ Group {id} investigation needed | {complex_issue_summary} | Spawning Investigator for deep analysis
```

**Example:**
```
ğŸ”¬ Group C investigation needed | Intermittent test failures with unclear root cause | Spawning Investigator for deep analysis
```

### Technical Review Summary (NEW - Multi-group overview)

**Use this format when summarizing Tech Lead reviews for multiple groups:**

```markdown
ğŸ‘” **Technical Review Summary**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Group {id} ({name}):** {status_emoji} {status}
  â€¢ Security: {security_summary}
  â€¢ Architecture: {architecture_assessment}
  â€¢ Tests: {test_summary}

**Group {id} ({name}):** {status_emoji} {status}
  â€¢ Security: {security_summary}
  â€¢ Issue: {issue_if_any}

**Overall:** {completed}/{total} groups approved, {pending} pending
```

**Example:**
```markdown
ğŸ‘” **Technical Review Summary**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Group A (Database Schema):** âœ… Approved
  â€¢ Security: 0 issues
  â€¢ Architecture: Clean migration pattern
  â€¢ Tests: 15/15 passing (89% coverage)

**Group B (Authentication):** âš ï¸ Minor changes needed
  â€¢ Security: 1 medium (add rate limiting)
  â€¢ Will be addressed in next iteration

**Group C (Core API):** âœ… Approved
  â€¢ Security: 0 issues
  â€¢ Architecture: RESTful design, proper error handling
  â€¢ Tests: 22/22 passing (91% coverage)

**Overall:** 2/3 groups approved, 1 pending minor fixes
```

---

## Problem/Error Messages (Context Required)

All error messages must include: WHAT failed, WHY (if known), WHAT'S NEXT

### Security Issues Found
```
âš ï¸ Group {id} security scan | {severity_count} ({issue_types}) | {action} â†’ See {artifact_path}
```

**Examples:**
```
âš ï¸ Group C security scan | 1 high (SQL injection), 2 medium (XSS) | Developer addressing â†’ See bazinga/artifacts/{SESSION_ID}/skills/security_scan.json

âš ï¸ Group A security scan | 3 low severity issues (hardcoded strings) | Quick fixes applied â†’ Re-scanning
```

### Coverage Gaps
```
âš ï¸ Group {id} coverage gaps | {files_below_threshold} â†’ See {artifact_path} | {action}
```

**Example:**
```
âš ï¸ Group C coverage gaps | 2 files below 80% (password_reset: 72%, validators: 75%) â†’ See bazinga/artifacts/{SESSION_ID}/skills/coverage_report.json | Adding tests
```

### Lint Issues
```
âš ï¸ Group {id} linting issues | {count} issues ({severity_breakdown}) â†’ See {artifact_path} | {action}
```

**Example:**
```
âš ï¸ Group B linting issues | 12 issues (5 errors, 7 warnings) â†’ See bazinga/artifacts/{SESSION_ID}/skills/lint_results.json | Auto-fixing
```

### Build Failure
```
âŒ Build failed | {error_type} in {location} | Cannot proceed - fix required â†’ {action}
```

**Example:**
```
âŒ Build failed | Import error in auth_middleware.py:12 | Cannot proceed - fix required â†’ Developer respawning
```

### Test Failure
```
âš ï¸ Tests failed in Group {id} | {failure_summary} | {action} â†’ See {artifact_path}
```

**Example:**
```
âš ï¸ Tests failed in Group B | 3/15 auth edge cases failing | Developer fixing â†’ See bazinga/artifacts/{SESSION_ID}/test_failures.md
```

### Iteration Loop Detected
```
âš ï¸ Group {id} iteration loop detected | {description} | {escalation_action}
```

**Example:**
```
âš ï¸ Group C iteration loop detected | Same review failures 3 times | Escalating to Opus + spawning Investigator
```

---

## Investigation Messages

### Investigator Spawned
```
ğŸ”¬ Spawning Investigator | {problem_summary} | Expected: Root cause analysis + recommendations
```

**Example:**
```
ğŸ”¬ Spawning Investigator | Group C intermittent test failures across 3 revisions | Expected: Root cause analysis + recommendations
```

### Investigation Complete - Root Cause Found
```
ğŸ”¬ Investigation complete | Root cause: {diagnosis} | Solution: {fix_summary} â†’ {next_action}
```

**Example:**
```
ğŸ”¬ Investigation complete | Root cause: Race condition in async auth flow | Solution: Add proper locking mechanism â†’ Developer implementing fix
```

### Investigation Complete - Need More Data
```
ğŸ”¬ Investigation findings | {hypothesis_count} hypotheses identified | Next: {diagnostic_action} â†’ Developer
```

**Example:**
```
ğŸ”¬ Investigation findings | 2 hypotheses (race condition vs memory leak) | Next: Add diagnostic logging â†’ Developer
```

---

## Completion Messages

### Group Complete (with Progress Tracking)
```
âœ… Group {id} complete | {summary} | Progress: {completed}/{total} ({percentage}%) | â†’ {next_step}
```

**Examples:**
```
âœ… Group A complete | JWT auth | Progress: 5/69 (7%) | â†’ QA review
âœ… Group B complete | Database schema | Progress: 12/69 (17%) | â†’ QA review
âœ… Group Z complete | Final cleanup | Progress: 69/69 (100%) | â†’ PM check
```

### Group Approved
```
âœ… Group {id} approved | {quality_summary} | Complete ({completed}/{total} groups)
```

**Example:**
```
âœ… Group A approved | Security clear, coverage 92%, all tests passing | Complete (1/3 groups done)
```

### All Groups Complete
```
âœ… All groups complete | {total_groups}/{total_groups} groups approved, all quality gates passed | Final PM check â†’ BAZINGA
```

**Example:**
```
âœ… All groups complete | 3/3 groups approved, all quality gates passed | Final PM check â†’ BAZINGA
```

### Session Complete
```
âœ… BAZINGA - Orchestration Complete!
```

---

## Progress Summary Messages (Parallel Mode)

### Periodic Status Update
When multiple groups are working in parallel, show compact status table:

```
ğŸ“Š Progress: {completed}/{total} groups complete
   âœ… Group A: Approved
   ğŸ”¨ Group B: QA testing
   âš ï¸ Group C: Fixing security issues (Rev 2)
```

**Example:**
```
ğŸ“Š Progress: 1/3 groups complete
   âœ… Group A: Approved
   ğŸ”¨ Group B: QA testing
   âš ï¸ Group C: Fixing security issues (Rev 2)
```

---

## Summary vs Artifact Separation

**Principle:** Main transcript shows summaries. Details go to artifacts.

### What Goes in Main Transcript (Capsule Format)
- âœ… Phase transitions (planning â†’ development â†’ QA â†’ review)
- âœ… Problems encountered (brief description)
- âœ… Solutions applied (brief description)
- âœ… Quality signals (tests passed, security clear, coverage %)
- âœ… Next actions (what's happening next)

### What Goes to Artifacts (Link Only in Transcript)
- ğŸ“„ Full test failure outputs â†’ `artifacts/{SESSION_ID}/qa_failures.md`
- ğŸ“„ Security scan details â†’ `artifacts/{SESSION_ID}/skills/security_scan.json`
- ğŸ“„ Coverage reports â†’ `artifacts/{SESSION_ID}/skills/coverage_report.json`
- ğŸ“„ Lint results â†’ `artifacts/{SESSION_ID}/skills/lint_results.json`
- ğŸ“„ Investigation reports â†’ `artifacts/{SESSION_ID}/investigation_*.md`
- ğŸ“„ Agent full responses â†’ Database logs (user doesn't see)

### Artifact Linking Pattern

When detail exceeds 3 lines, use summary + link:

```
[Emoji] [Summary] â†’ See [artifact_path]

Examples:
âš ï¸ 12 linting issues found in Group B (5 errors, 7 warnings) â†’ See bazinga/artifacts/{SESSION_ID}/skills/lint_results.json
âš ï¸ Coverage gaps in 2 files (password_reset: 72%, validators: 75%) â†’ See bazinga/artifacts/{SESSION_ID}/skills/coverage_report.json
ğŸ”¬ Investigation findings: 3 hypotheses, 12 diagnostic tests â†’ See bazinga/artifacts/{SESSION_ID}/investigation_group_c.md
```

---

## Agent Report Format (Internal - Orchestrator Parses)

**IMPORTANT:** These structures show the **ideal data points** the orchestrator will attempt to parse from agent responses. Agents output free-form text; the orchestrator uses best-effort pattern matching to extract these fields. These are NOT mandatory output formats - agents can respond naturally and the parsing logic will adapt (see Phase 2 implementation in agents/orchestrator.md for parsing details).

Agents return structured data. Orchestrator extracts key info and transforms to capsule for user.

### Developer Report Structure
```yaml
status: READY_FOR_QA | BLOCKED | PARTIAL
summary: One sentence summary of work completed
problems_found: List of issues encountered and how resolved
files_modified: [file1.py, file2.js, ...]
files_created: [new_file1.py, ...]
tests_added: count
coverage: percentage
blockers: null | Description of any blocking issue
```

**Orchestrator transforms to:**
```
ğŸ”¨ Group {id} complete | {summary}, {files} modified/created, {tests} tests added ({coverage}% coverage) | {status} â†’ {next_phase}
```

### QA Report Structure
```yaml
status: PASS | FAIL | PARTIAL
tests_run: count
tests_passed: count
tests_failed: count
coverage: percentage
critical_failures: [test_name: reason, ...] | null
recommendation: APPROVE_FOR_REVIEW | REQUEST_CHANGES
```

**Orchestrator transforms to:**

If PASS:
```
âœ… Group {id} tests passing | {passed}/{run} tests passed, {coverage}% coverage, {quality_signals} | Approved â†’ Tech Lead review
```

If FAIL:
```
âš ï¸ Group {id} QA failed | {failed}/{run} tests failing ({failure_summary}) | Developer fixing â†’ See bazinga/artifacts/{session}/qa_failures.md
```

### Tech Lead Report Structure
```yaml
status: APPROVED | CHANGES_REQUESTED | NEEDS_INVESTIGATION | ESCALATE_TO_OPUS | SPAWN_INVESTIGATOR
security_issues: {critical: N, high: N, medium: N, low: N}
lint_issues: {error: N, warning: N, info: N}
coverage: percentage
architecture_concerns: null | Brief description
decision: APPROVED | REQUEST_CHANGES | ESCALATE_TO_OPUS | SPAWN_INVESTIGATOR
reason: One sentence explanation
skill_results_summary: Brief summary of security/coverage/lint findings
escalation_reason: null | Why escalating/investigating
```

**Orchestrator transforms to:**

If APPROVED:
```
âœ… Group {id} approved | {quality_summary} | Complete ({completed}/{total})
```

If CHANGES_REQUESTED:
```
âš ï¸ Group {id} needs revision | {issue_summary} | Fixes required â†’ Developer
```

If ESCALATE_TO_OPUS:
```
ğŸ”¬ Group {id} complexity detected | {escalation_reason} | Escalating to Opus â†’ Tech Lead (Rev {N})
```

If SPAWN_INVESTIGATOR:
```
ğŸ”¬ Group {id} investigation needed | {complex_issue} | Spawning Investigator for deep analysis
```

### PM Report Structure
```yaml
status: BAZINGA | CONTINUE | NEEDS_CLARIFICATION
decision: Final decision
assessment: Evaluation of completion
feedback: null | Specific feedback for next iteration
```

**Orchestrator transforms to:**

If BAZINGA:
```
âœ… BAZINGA - Orchestration Complete!
[Shows final report]
```

If CONTINUE:
```
ğŸ“‹ PM check | {assessment} | {feedback} â†’ {next_action}
```

If NEEDS_CLARIFICATION:
```
âš ï¸ PM needs clarification | {blocker_type}: {question} | Awaiting response
```

---

## Emoji Legend

- ğŸš€ - Session start
- ğŸ“‹ - Planning / PM activity
- ğŸ”¨ - Development work
- âœ… - Success / approval / tests passing
- âš ï¸ - Warning / issue detected / needs attention
- âŒ - Critical failure / blocker
- ğŸ‘” - Tech Lead review
- ğŸ”¬ - Investigation / deep analysis / escalation
- ğŸ“Š - Status summary / metrics

---

## Template Usage Examples

### Full Orchestration Flow Example

```
ğŸš€ Starting orchestration | Session: bazinga_20251117_143530

ğŸ“‹ Planning complete | 3 parallel groups: JWT auth (5 files), User reg (3 files), Password reset (4 files) | Starting development â†’ Groups A, B, C

ğŸ”¨ Group A implementing | auth_middleware.py + jwt_utils.py + token_validator.py created, 12 tests added (92% coverage) | Tests passing â†’ QA review
ğŸ”¨ Group B implementing | user_service.py + validators.py created, 15 tests added (88% coverage) | Tests passing â†’ QA review
ğŸ”¨ Group C implementing | password_reset.py + email_service.py created, 9 tests added (78% coverage) | Tests passing â†’ QA review

âœ… Group A tests passing | 12/12 tests passed, 92% coverage, security clear | Approved â†’ Tech Lead review
âœ… Group B tests passing | 15/15 tests passed, 88% coverage, security clear | Approved â†’ Tech Lead review
âš ï¸ Group C QA failed | Coverage below threshold (78% vs 80% target) | Adding edge case tests

âœ… Group A approved | Security clear, 0 lint issues, architecture solid | Complete (1/3 groups)
âœ… Group B approved | 2 medium security issues fixed, all tests passing, code quality excellent | Complete (2/3 groups)

ğŸ”¨ Group C complete | Added 4 edge case tests, coverage now 85% | Ready â†’ QA re-test

âœ… Group C tests passing | 13/13 tests passed, 85% coverage, security clear | Approved â†’ Tech Lead review

âš ï¸ Group C security scan | 1 high (SQL injection in password_reset.py:45) | Fixing with parameterized queries â†’ See bazinga/artifacts/{SESSION_ID}/skills/security_scan.json

ğŸ”¨ Group C complete | SQL injection fixed, re-scanned clean | Ready â†’ Tech Lead re-review

âœ… Group C approved | Security clear, coverage 85%, all quality gates passed | Complete (3/3 groups)

âœ… All groups complete | 3/3 groups approved, all quality gates passed | Final PM check â†’ BAZINGA

âœ… BAZINGA - Orchestration Complete!
```

---

**Last Updated:** 2025-11-17
**Version:** 2.0 (Compact Capsule Format)
