//! Logistic regression implementation for binary outcomes.
//!
//! This module implements logistic regression using Maximum Likelihood Estimation (MLE)
//! with Newton-Raphson optimization. It provides:
//!
//! - Newton-Raphson/IRLS optimization with step halving for numerical stability
//! - HC3 robust standard errors adapted for logistic regression
//! - Score bootstrap for clustered inference (Kline & Santos, 2012)
//! - Perfect separation detection
//! - McFadden's pseudo R² and log-likelihood computation
//!
//! # Performance Optimizations
//! - Uses faer for efficient X'WX and X'r computation (BLAS-like performance)
//! - Uses Cholesky solve instead of explicit matrix inversion (O(p²) vs O(p³))
//! - Caches likelihood before step halving to avoid redundant computation
//! - Batch leverage computation using faer matrix operations
//!
//! # References
//! - Kline, P., & Santos, A. (2012). "A Score Based Approach to Wild Bootstrap Inference."
//! - MacKinnon, J. G., & White, H. (1985). "Some heteroskedasticity-consistent
//!   covariance matrix estimators with improved finite sample properties."

use crate::linalg::{
    cholesky_solve, compute_hc3_logistic_vcov, compute_residuals_inplace,
    compute_weighted_leverages_batch, compute_weights_inplace, compute_xtr_inplace,
    compute_xtwx_inplace, invert_xtx, mat_to_vec, mat_vec_mul, mat_vec_mul_inplace,
    matrix_vector_multiply, vec_to_mat, LinalgError,
};
use faer::{Col, Mat};
use pyo3::prelude::*;

// Re-export vec_to_mat for external use (tests, lib.rs)
#[allow(unused_imports)]
pub use crate::linalg::vec_to_mat as linalg_vec_to_mat;

/// Result of a logistic regression computation.
///
/// Contains coefficient estimates, robust standard errors, and diagnostic
/// information about the optimization process.
#[pyclass]
#[derive(Debug, Clone)]
pub struct LogisticRegressionResult {
    /// Coefficient estimates for x variables (log-odds scale)
    #[pyo3(get)]
    pub coefficients: Vec<f64>,

    /// Intercept term (None if include_intercept=False)
    #[pyo3(get)]
    pub intercept: Option<f64>,

    /// Robust standard errors for each coefficient
    #[pyo3(get)]
    pub standard_errors: Vec<f64>,

    /// Robust standard error for intercept (None if include_intercept=False)
    #[pyo3(get)]
    pub intercept_se: Option<f64>,

    /// Number of observations used
    #[pyo3(get)]
    pub n_samples: usize,

    /// Number of unique clusters (None if not clustered)
    #[pyo3(get)]
    pub n_clusters: Option<usize>,

    /// Type of clustered SE: "analytical" or "bootstrap" (None if not clustered)
    #[pyo3(get)]
    pub cluster_se_type: Option<String>,

    /// Number of bootstrap iterations used (None if not bootstrap)
    #[pyo3(get)]
    pub bootstrap_iterations_used: Option<usize>,

    /// Whether the optimization converged
    #[pyo3(get)]
    pub converged: bool,

    /// Number of iterations used by the optimizer
    #[pyo3(get)]
    pub iterations: usize,

    /// Log-likelihood at the MLE solution
    #[pyo3(get)]
    pub log_likelihood: f64,

    /// McFadden's pseudo R² = 1 - (LL_model / LL_null)
    #[pyo3(get)]
    pub pseudo_r_squared: f64,

    /// Number of unique groups per FE dimension (e.g., [100, 20] for 100 entities, 20 time periods)
    /// None when fixed_effects is not used.
    #[pyo3(get)]
    pub fixed_effects_absorbed: Option<Vec<usize>>,

    /// Column names of absorbed fixed effects (e.g., ["entity", "time"])
    /// None when fixed_effects is not used.
    #[pyo3(get)]
    pub fixed_effects_names: Option<Vec<String>>,

    /// Pseudo R² computed on the Mundlak-augmented model (within-pseudo R²)
    /// None when fixed_effects is not used.
    #[pyo3(get)]
    pub within_pseudo_r_squared: Option<f64>,
}

#[pymethods]
impl LogisticRegressionResult {
    /// Full technical representation of the result object.
    fn __repr__(&self) -> String {
        let intercept_str = match self.intercept {
            Some(i) => format!("{:.6}", i),
            None => "None".to_string(),
        };
        let intercept_se_str = match self.intercept_se {
            Some(se) => format!("{:.6}", se),
            None => "None".to_string(),
        };
        let n_clusters_str = match self.n_clusters {
            Some(n) => n.to_string(),
            None => "None".to_string(),
        };
        let cluster_se_type_str = match &self.cluster_se_type {
            Some(s) => format!("\"{}\"", s),
            None => "None".to_string(),
        };
        let bootstrap_iter_str = match self.bootstrap_iterations_used {
            Some(b) => b.to_string(),
            None => "None".to_string(),
        };
        let fe_absorbed_str = match &self.fixed_effects_absorbed {
            Some(v) => format!("{:?}", v),
            None => "None".to_string(),
        };
        let fe_names_str = match &self.fixed_effects_names {
            Some(v) => format!("{:?}", v),
            None => "None".to_string(),
        };
        let within_r2_str = match self.within_pseudo_r_squared {
            Some(r) => format!("{:.6}", r),
            None => "None".to_string(),
        };
        format!(
            "LogisticRegressionResult(coefficients={:?}, intercept={}, standard_errors={:?}, intercept_se={}, n_samples={}, n_clusters={}, cluster_se_type={}, bootstrap_iterations_used={}, converged={}, iterations={}, log_likelihood={:.6}, pseudo_r_squared={:.6}, fixed_effects_absorbed={}, fixed_effects_names={}, within_pseudo_r_squared={})",
            self.coefficients,
            intercept_str,
            self.standard_errors,
            intercept_se_str,
            self.n_samples,
            n_clusters_str,
            cluster_se_type_str,
            bootstrap_iter_str,
            self.converged,
            self.iterations,
            self.log_likelihood,
            self.pseudo_r_squared,
            fe_absorbed_str,
            fe_names_str,
            within_r2_str
        )
    }

    /// Human-readable summary of the logistic regression result.
    fn __str__(&self) -> String {
        let convergence_str = if self.converged {
            format!("converged in {} iterations", self.iterations)
        } else {
            format!("FAILED to converge after {} iterations", self.iterations)
        };

        let mut output = format!(
            "Logistic Regression: n={}, {}\n",
            self.n_samples, convergence_str
        );

        // Print intercept if present
        if let Some(intercept) = self.intercept {
            let se_str = match self.intercept_se {
                Some(se) => format!(" ± {:.4}", se),
                None => String::new(),
            };
            output.push_str(&format!("  β₀ = {:.4}{} (intercept)\n", intercept, se_str));
        }

        // Print coefficients
        for (i, (&coef, &se)) in self
            .coefficients
            .iter()
            .zip(&self.standard_errors)
            .enumerate()
        {
            output.push_str(&format!("  β{} = {:.4} ± {:.4}\n", i + 1, coef, se));
        }

        // Print fit statistics
        output.push_str(&format!(
            "  Log-likelihood: {:.2}, McFadden R²: {:.3}",
            self.log_likelihood, self.pseudo_r_squared
        ));

        // Add clustering info if present
        if let Some(n_clusters) = self.n_clusters {
            let method = self.cluster_se_type.as_deref().unwrap_or("unknown");
            output.push_str(&format!(
                "\n  Clustered SE ({}): {} clusters",
                method, n_clusters
            ));
        }

        // Add fixed effects info if present
        if let Some(ref fe_names) = self.fixed_effects_names {
            if let Some(ref fe_absorbed) = self.fixed_effects_absorbed {
                let fe_info: Vec<String> = fe_names
                    .iter()
                    .zip(fe_absorbed.iter())
                    .map(|(name, count)| format!("{} ({} groups)", name, count))
                    .collect();
                output.push_str(&format!("\n  Fixed Effects: {}", fe_info.join(", ")));
            }
            if let Some(within_r2) = self.within_pseudo_r_squared {
                output.push_str(&format!("\n  Within Pseudo R²: {:.3}", within_r2));
            }
        }

        output
    }
}

/// Error types for logistic regression operations.
#[derive(Debug, Clone)]
pub enum LogisticError {
    /// Perfect separation detected (coefficients diverging)
    PerfectSeparation,
    /// Optimization failed to converge within max iterations
    ConvergenceFailure { iterations: usize },
    /// Hessian matrix is singular (collinearity)
    SingularHessian,
    /// Numerical instability detected (condition number too high, NaN/Inf values)
    NumericalInstability { message: String },
}

impl std::fmt::Display for LogisticError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            LogisticError::PerfectSeparation => {
                write!(
                    f,
                    "Perfect separation detected; logistic regression cannot converge"
                )
            }
            LogisticError::ConvergenceFailure { iterations } => {
                write!(f, "Convergence failed after {} iterations", iterations)
            }
            LogisticError::SingularHessian => {
                write!(f, "Hessian matrix is singular; check for collinearity")
            }
            LogisticError::NumericalInstability { message } => {
                write!(f, "{}", message)
            }
        }
    }
}

impl std::error::Error for LogisticError {}

/// Internal result from MLE optimization.
///
/// This structure contains all intermediate results from the Newton-Raphson
/// optimization process, including coefficient estimates, convergence status,
/// and diagnostic information needed for computing standard errors.
pub struct MleResult {
    /// Estimated coefficients (including intercept if applicable)
    pub beta: Vec<f64>,
    /// Whether the optimization converged
    pub converged: bool,
    /// Number of iterations used
    pub iterations: usize,
    /// Log-likelihood at the MLE solution
    pub log_likelihood: f64,
    /// Information matrix inverse (X'WX)^-1 for SE computation
    pub info_inv: Vec<Vec<f64>>,
    /// Predicted probabilities at convergence
    pub pi: Vec<f64>,
}

// ============================================================================
// Core mathematical functions
// ============================================================================

/// Logistic (sigmoid) function: σ(x) = 1 / (1 + exp(-x))
///
/// Handles numerical stability for extreme values of x.
#[inline]
pub fn sigmoid(x: f64) -> f64 {
    if x >= 0.0 {
        1.0 / (1.0 + (-x).exp())
    } else {
        let exp_x = x.exp();
        exp_x / (1.0 + exp_x)
    }
}

/// Dot product of two vectors.
#[inline]
pub fn dot(a: &[f64], b: &[f64]) -> f64 {
    a.iter().zip(b.iter()).map(|(&ai, &bi)| ai * bi).sum()
}

/// Compute X' × v (X transpose times vector).
///
/// X is (n × p), v is (n,), result is (p,).
///
/// Note: This is a legacy Vec<Vec> implementation kept for compatibility.
/// New code should use faer-based operations from the linalg module.
#[allow(dead_code)]
pub fn xt_vector_multiply(x: &[Vec<f64>], v: &[f64]) -> Vec<f64> {
    if x.is_empty() {
        return vec![];
    }
    let p = x[0].len();
    let mut result = vec![0.0; p];

    for (xi, &vi) in x.iter().zip(v.iter()) {
        for (j, &xij) in xi.iter().enumerate() {
            result[j] += xij * vi;
        }
    }

    result
}

/// Compute X' W X where W is a diagonal matrix represented as a vector.
///
/// X is (n × p), W is diagonal (n,), result is (p × p).
///
/// Note: This is a legacy Vec<Vec> implementation kept for compatibility.
/// New code should use faer-based operations from the linalg module.
#[allow(dead_code)]
pub fn xt_w_x(x: &[Vec<f64>], w: &[f64]) -> Vec<Vec<f64>> {
    if x.is_empty() {
        return vec![];
    }
    let p = x[0].len();
    let mut result = vec![vec![0.0; p]; p];

    for (xi, &wi) in x.iter().zip(w.iter()) {
        for j in 0..p {
            for k in 0..p {
                result[j][k] += xi[j] * wi * xi[k];
            }
        }
    }

    result
}

// ============================================================================
// Log-likelihood computation
// ============================================================================

/// Compute log-likelihood for logistic regression.
///
/// L(β) = Σᵢ [yᵢ log(πᵢ) + (1-yᵢ) log(1-πᵢ)]
///
/// Handles numerical stability by clipping probabilities to [1e-15, 1-1e-15].
///
/// Note: This is a legacy Vec<Vec> implementation kept for compatibility.
/// New code should use [`compute_log_likelihood_faer`] for better performance.
#[allow(dead_code)]
pub fn compute_log_likelihood(x: &[Vec<f64>], y: &[f64], beta: &[f64]) -> f64 {
    let mut ll = 0.0;
    let epsilon = 1e-15;

    for (xi, &yi) in x.iter().zip(y.iter()) {
        let linear_pred = dot(xi, beta);
        let pi = sigmoid(linear_pred);
        // Clip for numerical stability
        let pi_clipped = pi.max(epsilon).min(1.0 - epsilon);

        ll += yi * pi_clipped.ln() + (1.0 - yi) * (1.0 - pi_clipped).ln();
    }

    ll
}

/// Compute log-likelihood using faer matrix for batch linear predictions.
///
/// This is an optimized version that uses faer's mat_vec_mul for computing
/// all linear predictions X×β at once, avoiding O(n) individual dot products.
///
/// L(β) = Σᵢ [yᵢ log(πᵢ) + (1-yᵢ) log(1-πᵢ)]
#[inline]
pub fn compute_log_likelihood_faer(x_mat: &Mat<f64>, y: &[f64], beta: &[f64]) -> f64 {
    let epsilon = 1e-15;

    // Compute all linear predictions at once: Xβ
    let linear_preds = mat_vec_mul(x_mat, beta);

    // Compute log-likelihood
    let mut ll = 0.0;
    for (&lp, &yi) in linear_preds.iter().zip(y.iter()) {
        let pi = sigmoid(lp);
        let pi_clipped = pi.max(epsilon).min(1.0 - epsilon);
        ll += yi * pi_clipped.ln() + (1.0 - yi) * (1.0 - pi_clipped).ln();
    }

    ll
}

/// Compute null model log-likelihood (intercept-only model).
///
/// For the null model, π = mean(y) for all observations.
pub fn compute_null_log_likelihood(y: &[f64]) -> f64 {
    let n = y.len() as f64;
    let mean_y = y.iter().sum::<f64>() / n;

    let epsilon = 1e-15;
    let mean_clipped = mean_y.max(epsilon).min(1.0 - epsilon);

    let ll_null = y
        .iter()
        .map(|&yi| yi * mean_clipped.ln() + (1.0 - yi) * (1.0 - mean_clipped).ln())
        .sum();

    ll_null
}

/// Compute McFadden's pseudo R².
///
/// R² = 1 - (LL_model / LL_null)
pub fn compute_pseudo_r_squared(ll_model: f64, ll_null: f64) -> f64 {
    if ll_null == 0.0 {
        0.0
    } else {
        1.0 - (ll_model / ll_null)
    }
}

// ============================================================================
// Newton-Raphson MLE solver
// ============================================================================

/// Maximum number of Newton-Raphson iterations
const MAX_ITERATIONS: usize = 35;

/// Convergence tolerance for gradient norm
const CONVERGENCE_TOL: f64 = 1e-8;

/// Minimum weight floor to prevent numerical issues
const WEIGHT_FLOOR: f64 = 1e-10;

/// Threshold for detecting perfect separation (|β| > threshold)
const SEPARATION_THRESHOLD: f64 = 20.0;

/// Maximum step halvings per iteration
const MAX_STEP_HALVINGS: i32 = 10;

/// Detect perfect separation by checking for coefficient divergence.
///
/// Returns true if separation is detected.
fn detect_separation(beta: &[f64], pi: &[f64]) -> bool {
    // Check if any coefficient is too large
    if beta.iter().any(|&b| b.abs() > SEPARATION_THRESHOLD) {
        return true;
    }

    // Check if all predictions are near 0 or 1
    let all_extreme = pi.iter().all(|&p| !(1e-7..=(1.0 - 1e-7)).contains(&p));
    if all_extreme && !pi.is_empty() {
        return true;
    }

    false
}

/// Check for NaN or Inf in a vector.
fn has_invalid_values(v: &[f64]) -> bool {
    v.iter().any(|&x| x.is_nan() || x.is_infinite())
}

/// Compute logistic regression MLE using Newton-Raphson algorithm.
///
/// # Performance Optimizations
/// - Uses faer for X'WX computation (BLAS-like performance)
/// - Uses Cholesky solve instead of explicit matrix inversion
/// - Caches likelihood before step halving
/// - Accepts faer::Mat directly to avoid Vec<Vec<f64>> conversion overhead
///
/// # Arguments
/// * `x_mat` - Design matrix as faer::Mat (n × p), including intercept column if applicable
/// * `y` - Binary outcome vector (n,), values must be 0 or 1
///
/// # Returns
/// * `Result<MleResult, LogisticError>` - MLE result or error
pub fn compute_logistic_mle(x_mat: &Mat<f64>, y: &[f64]) -> Result<MleResult, LogisticError> {
    let n = x_mat.nrows();
    if n == 0 {
        return Err(LogisticError::NumericalInstability {
            message: "Cannot perform regression on empty data".to_string(),
        });
    }

    let p = x_mat.ncols();
    if p == 0 {
        return Err(LogisticError::NumericalInstability {
            message: "Design matrix must have at least one column".to_string(),
        });
    }

    // x_mat is already a faer matrix - no conversion needed

    // Initialize β = 0
    let mut beta = vec![0.0; p];
    let mut converged = false;
    let mut iterations = 0;
    let mut info_inv_mat: Mat<f64> = Mat::zeros(p, p);

    // Pre-allocate all buffers ONCE (reuse across iterations)
    // This eliminates ~n×6 allocations per iteration
    let mut linear_pred = vec![0.0; n];
    let mut pi = vec![0.0; n];
    let mut weights = vec![0.0; n];
    let mut residuals = vec![0.0; n];
    let mut gradient = vec![0.0; p];
    let mut x_weighted = Mat::<f64>::zeros(n, p);
    let mut hessian_mat = Mat::<f64>::zeros(p, p);

    // Pre-allocate faer::Col buffers for SIMD matmul operations
    let mut linear_pred_col = Col::<f64>::zeros(n);
    let mut gradient_col = Col::<f64>::zeros(p);

    // Cache log-likelihood for step halving optimization
    // Use faer for initial LL computation
    let mut current_ll = compute_log_likelihood_faer(x_mat, y, &beta);

    for iter in 0..MAX_ITERATIONS {
        iterations = iter + 1;

        // Compute π = sigmoid(Xβ) using pre-allocated buffers and faer SIMD
        // Step 1: Compute linear predictions Xβ in-place with reusable Col buffer
        mat_vec_mul_inplace(x_mat, &beta, &mut linear_pred, &mut linear_pred_col);

        // Step 2: Apply sigmoid in-place, storing results in pi
        for (p_i, &lp) in pi.iter_mut().zip(linear_pred.iter()) {
            *p_i = sigmoid(lp);
        }

        // Check for perfect separation
        if detect_separation(&beta, &pi) {
            return Err(LogisticError::PerfectSeparation);
        }

        // Compute weights W = diag(π(1-π)) with floor for stability (in-place)
        compute_weights_inplace(&pi, &mut weights, WEIGHT_FLOOR);

        // Compute residuals (y - π) in-place
        compute_residuals_inplace(y, &pi, &mut residuals);

        // Compute gradient: X'(y - π) in-place with reusable Col buffer
        compute_xtr_inplace(x_mat, &residuals, &mut gradient, &mut gradient_col);

        // Check for NaN in gradient
        if has_invalid_values(&gradient) {
            return Err(LogisticError::NumericalInstability {
                message: "NaN detected in gradient computation".to_string(),
            });
        }

        // Compute Hessian X'WX in-place (reuses x_weighted and hessian_mat buffers)
        compute_xtwx_inplace(x_mat, &weights, &mut x_weighted, &mut hessian_mat);

        // Check convergence: ||∇L|| < tol
        let grad_norm = gradient.iter().map(|g| g.powi(2)).sum::<f64>().sqrt();
        if grad_norm < CONVERGENCE_TOL {
            converged = true;
            // Compute final info_inv using faer Cholesky (reuse hessian_mat computed above)
            info_inv_mat = invert_xtx(&hessian_mat).map_err(|e| match e {
                LinalgError::SingularMatrix => LogisticError::SingularHessian,
                LinalgError::NumericalInstability => LogisticError::NumericalInstability {
                    message: "Numerical instability in final Hessian inversion".to_string(),
                },
                LinalgError::DimensionMismatch { expected, got } => {
                    LogisticError::NumericalInstability {
                        message: format!("Dimension mismatch: expected {}, got {}", expected, got),
                    }
                }
            })?;
            break;
        }

        // Check condition number (simple estimate using diagonal ratio)
        let diag: Vec<f64> = (0..p).map(|i| hessian_mat.read(i, i)).collect();
        let max_diag = diag.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
        let min_diag = diag.iter().cloned().fold(f64::INFINITY, f64::min);
        if min_diag <= 0.0 || max_diag / min_diag > 1e10 {
            return Err(LogisticError::NumericalInstability {
                message: "Numerical instability detected; check for extreme values or collinearity"
                    .to_string(),
            });
        }

        // Compute Newton direction: δ = H⁻¹ × g using Cholesky solve
        // This avoids explicit O(p³) matrix inversion
        let delta = cholesky_solve(&hessian_mat, &gradient).map_err(|e| match e {
            LinalgError::SingularMatrix => LogisticError::SingularHessian,
            LinalgError::NumericalInstability => LogisticError::NumericalInstability {
                message: "Numerical instability in Cholesky solve".to_string(),
            },
            LinalgError::DimensionMismatch { expected, got } => {
                LogisticError::NumericalInstability {
                    message: format!("Dimension mismatch: expected {}, got {}", expected, got),
                }
            }
        })?;

        // Apply Newton step with step halving using faer SIMD
        // Returns (success, new_ll) to avoid redundant LL recomputation
        let (step_success, new_ll) =
            newton_step_with_halving_faer(&mut beta, &delta, x_mat, y, current_ll);

        if !step_success {
            // Could not improve - check if we're close to optimum
            if grad_norm < CONVERGENCE_TOL * 100.0 {
                converged = true;
                // Need to compute info_inv for final result
                info_inv_mat = invert_xtx(&hessian_mat).map_err(|e| match e {
                    LinalgError::SingularMatrix => LogisticError::SingularHessian,
                    LinalgError::NumericalInstability => LogisticError::NumericalInstability {
                        message: "Numerical instability in Hessian inversion".to_string(),
                    },
                    LinalgError::DimensionMismatch { expected, got } => {
                        LogisticError::NumericalInstability {
                            message: format!(
                                "Dimension mismatch: expected {}, got {}",
                                expected, got
                            ),
                        }
                    }
                })?;
            }
            break;
        }

        // Use LL from step halving (no redundant recomputation)
        current_ll = new_ll;

        // Check for NaN/Inf in beta
        if has_invalid_values(&beta) {
            return Err(LogisticError::NumericalInstability {
                message: "NaN/Inf detected in coefficient estimates".to_string(),
            });
        }
    }

    if !converged {
        return Err(LogisticError::ConvergenceFailure { iterations });
    }

    // Compute final log-likelihood using faer SIMD
    let log_likelihood = compute_log_likelihood_faer(x_mat, y, &beta);

    // Verify no NaN/Inf in final values
    if log_likelihood.is_nan() || log_likelihood.is_infinite() {
        return Err(LogisticError::NumericalInstability {
            message: "Invalid log-likelihood at convergence".to_string(),
        });
    }

    // Convert faer matrix back to Vec<Vec<f64>> for API compatibility
    let info_inv = mat_to_vec(&info_inv_mat);

    Ok(MleResult {
        beta,
        converged,
        iterations,
        log_likelihood,
        info_inv,
        pi,
    })
}

/// Compute Newton step with step halving using faer matrix for batch predictions.
///
/// This is the optimized version that uses faer's mat_vec_mul for computing
/// likelihood during step halving, avoiding conversion overhead.
///
/// Returns (success, new_ll) - the new log-likelihood is returned to avoid recomputation.
fn newton_step_with_halving_faer(
    beta: &mut [f64],
    delta: &[f64],
    x_mat: &Mat<f64>,
    y: &[f64],
    old_ll: f64,
) -> (bool, f64) {
    let p = beta.len();

    for halving in 0..MAX_STEP_HALVINGS {
        let step_size = 0.5_f64.powi(halving);

        // Compute new beta
        let beta_new: Vec<f64> = beta
            .iter()
            .zip(delta.iter())
            .map(|(&b, &d)| b + step_size * d)
            .collect();

        // Check for invalid values
        if has_invalid_values(&beta_new) {
            continue;
        }

        // Use faer-based likelihood for batch linear predictions
        let new_ll = compute_log_likelihood_faer(x_mat, y, &beta_new);

        // Accept step if log-likelihood improves (or is close enough)
        if new_ll >= old_ll - 1e-8 || (halving == MAX_STEP_HALVINGS - 1 && !new_ll.is_nan()) {
            beta[..p].copy_from_slice(&beta_new[..p]);
            return (true, new_ll);
        }
    }

    (false, old_ll)
}

// ============================================================================
// HC3 Standard Errors for Logistic Regression
// ============================================================================

/// Compute weighted leverages for logistic regression (legacy, kept for compatibility).
///
/// h_ii = w_i × x_i' (X'WX)⁻¹ x_i
#[allow(dead_code)]
#[deprecated(
    since = "0.5.0",
    note = "Legacy Vec<Vec> implementation. Use faer-based compute_leverages_faer instead."
)]
fn compute_weighted_leverages(
    x: &[Vec<f64>],
    weights: &[f64],
    info_inv: &[Vec<f64>],
) -> Result<Vec<f64>, LogisticError> {
    let n = x.len();
    let mut leverages = Vec::with_capacity(n);

    for (i, (xi, &wi)) in x.iter().zip(weights.iter()).enumerate() {
        // Compute temp = (X'WX)⁻¹ × x_i
        let temp = matrix_vector_multiply(info_inv, xi);

        // Compute h_ii = w_i × x_i · temp
        let h_ii = wi * dot(xi, &temp);

        if h_ii >= 0.99 {
            return Err(LogisticError::NumericalInstability {
                message: format!(
                    "Observation {} has leverage ≥ 0.99; HC3 standard errors may be unreliable",
                    i
                ),
            });
        }

        leverages.push(h_ii);
    }

    Ok(leverages)
}

/// Compute HC3 standard errors for logistic regression.
///
/// # Performance Optimizations
/// - Uses faer for batch weighted leverage computation
/// - Uses faer for meat matrix and sandwich formula computation
///
/// Uses the sandwich formula with weighted leverages:
/// V = I⁻¹ M I⁻¹ where M = Σᵢ xᵢ xᵢ' × (yᵢ - πᵢ)² / (1 - hᵢᵢ)²
///
/// # Arguments
/// * `x` - Design matrix (n × p)
/// * `y` - Binary outcome (n,)
/// * `pi` - Predicted probabilities (n,)
/// * `info_inv` - Inverse information matrix (X'WX)⁻¹ (p × p)
///
/// # Returns
/// * `Result<Vec<f64>, LogisticError>` - Standard errors (p,)
///
/// Note: This is a legacy Vec<Vec> implementation kept for compatibility.
/// New code should use [`compute_hc3_logistic_faer`] for better performance.
#[allow(dead_code)]
pub fn compute_hc3_logistic(
    x: &[Vec<f64>],
    y: &[f64],
    pi: &[f64],
    info_inv: &[Vec<f64>],
) -> Result<Vec<f64>, LogisticError> {
    let p = info_inv.len();

    // Convert to faer matrices for efficient operations
    let x_mat = vec_to_mat(x);
    let info_inv_mat = vec_to_mat(info_inv);

    // Compute weights: W = diag(π(1-π))
    let weights: Vec<f64> = pi.iter().map(|&p| p * (1.0 - p)).collect();

    // Compute residuals (y - π)
    let residuals: Vec<f64> = y.iter().zip(pi).map(|(&yi, &pi)| yi - pi).collect();

    // Compute weighted leverages using faer batch operation
    let leverages =
        compute_weighted_leverages_batch(&x_mat, &weights, &info_inv_mat).map_err(|e| match e {
            LinalgError::NumericalInstability => LogisticError::NumericalInstability {
                message: "Extreme leverage detected; HC3 standard errors may be unreliable"
                    .to_string(),
            },
            _ => LogisticError::NumericalInstability {
                message: "Error in leverage computation".to_string(),
            },
        })?;

    // Compute HC3 variance-covariance using faer
    let vcov_mat = compute_hc3_logistic_vcov(&x_mat, &residuals, &leverages, &info_inv_mat);

    // Extract diagonal and compute SE
    let se: Vec<f64> = (0..p).map(|i| vcov_mat.read(i, i).sqrt()).collect();

    // Check for invalid values
    if se.iter().any(|&s| s.is_nan() || s.is_infinite() || s < 0.0) {
        return Err(LogisticError::NumericalInstability {
            message: "HC3 standard error computation produced invalid values".to_string(),
        });
    }

    Ok(se)
}

/// Compute HC3 standard errors for logistic regression using faer matrices directly.
///
/// This is the optimized version that avoids Vec<Vec<f64>> conversions.
///
/// Uses the sandwich formula with weighted leverages:
/// V = I⁻¹ M I⁻¹ where M = Σᵢ xᵢ xᵢ' × (yᵢ - πᵢ)² / (1 - hᵢᵢ)²
///
/// # Arguments
/// * `x_mat` - Design matrix as faer::Mat (n × p)
/// * `y` - Binary outcome (n,)
/// * `pi` - Predicted probabilities (n,)
/// * `info_inv_mat` - Inverse information matrix (X'WX)⁻¹ as faer::Mat (p × p)
///
/// # Returns
/// * `Result<Vec<f64>, LogisticError>` - Standard errors (p,)
pub fn compute_hc3_logistic_faer(
    x_mat: &Mat<f64>,
    y: &[f64],
    pi: &[f64],
    info_inv_mat: &Mat<f64>,
) -> Result<Vec<f64>, LogisticError> {
    let p = info_inv_mat.ncols();

    // Compute weights: W = diag(π(1-π))
    let weights: Vec<f64> = pi.iter().map(|&p| p * (1.0 - p)).collect();

    // Compute residuals (y - π)
    let residuals: Vec<f64> = y.iter().zip(pi).map(|(&yi, &pi)| yi - pi).collect();

    // Compute weighted leverages using faer batch operation
    let leverages =
        compute_weighted_leverages_batch(x_mat, &weights, info_inv_mat).map_err(|e| match e {
            LinalgError::NumericalInstability => LogisticError::NumericalInstability {
                message: "Extreme leverage detected; HC3 standard errors may be unreliable"
                    .to_string(),
            },
            _ => LogisticError::NumericalInstability {
                message: "Error in leverage computation".to_string(),
            },
        })?;

    // Compute HC3 variance-covariance using faer
    let vcov_mat = compute_hc3_logistic_vcov(x_mat, &residuals, &leverages, info_inv_mat);

    // Extract diagonal and compute SE
    let se: Vec<f64> = (0..p).map(|i| vcov_mat.read(i, i).sqrt()).collect();

    // Check for invalid values
    if se.iter().any(|&s| s.is_nan() || s.is_infinite() || s < 0.0) {
        return Err(LogisticError::NumericalInstability {
            message: "HC3 standard error computation produced invalid values".to_string(),
        });
    }

    Ok(se)
}

// ============================================================================
// Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;
    use approx::assert_relative_eq;

    #[test]
    fn test_sigmoid() {
        assert_relative_eq!(sigmoid(0.0), 0.5, epsilon = 1e-10);
        assert!(sigmoid(100.0) > 0.99);
        assert!(sigmoid(-100.0) < 0.01);
    }

    #[test]
    fn test_dot() {
        let a = vec![1.0, 2.0, 3.0];
        let b = vec![4.0, 5.0, 6.0];
        assert_relative_eq!(dot(&a, &b), 32.0, epsilon = 1e-10);
    }

    #[test]
    fn test_log_likelihood_bounds() {
        // Log-likelihood should always be negative (or zero for perfect fit)
        let x = vec![vec![1.0, 0.0], vec![1.0, 1.0]];
        let y = vec![0.0, 1.0];
        let beta = vec![0.0, 1.0];

        let ll = compute_log_likelihood(&x, &y, &beta);
        assert!(ll <= 0.0);
    }

    #[test]
    fn test_null_log_likelihood() {
        let y = vec![0.0, 0.0, 1.0, 1.0];
        let ll_null = compute_null_log_likelihood(&y);
        // For 50/50 split, null LL should be n * ln(0.5) = 4 * (-0.693) ≈ -2.77
        assert!(ll_null < 0.0);
        assert_relative_eq!(ll_null, 4.0 * 0.5_f64.ln(), epsilon = 1e-10);
    }

    #[test]
    fn test_pseudo_r_squared_bounds() {
        // Pseudo R² should be in [0, 1] for reasonable models
        let ll_model = -10.0;
        let ll_null = -20.0;
        let r2 = compute_pseudo_r_squared(ll_model, ll_null);
        assert!(r2 >= 0.0 && r2 <= 1.0);
        assert_relative_eq!(r2, 0.5, epsilon = 1e-10);
    }

    #[test]
    fn test_mle_simple_convergence() {
        // Simple test: y perfectly predicted by x
        // Create data where y=0 when x<0.5, y=1 when x>0.5
        let x = vec![
            vec![1.0, 0.0],
            vec![1.0, 0.2],
            vec![1.0, 0.4],
            vec![1.0, 0.6],
            vec![1.0, 0.8],
            vec![1.0, 1.0],
        ];
        let y = vec![0.0, 0.0, 0.0, 1.0, 1.0, 1.0];

        // Convert to faer::Mat
        let x_mat = vec_to_mat(&x);
        let result = compute_logistic_mle(&x_mat, &y);
        assert!(result.is_ok());
        let mle = result.unwrap();
        assert!(mle.converged);
        assert!(mle.iterations <= MAX_ITERATIONS);
    }

    #[test]
    fn test_hc3_produces_positive_se() {
        let x = vec![
            vec![1.0, 0.0],
            vec![1.0, 0.2],
            vec![1.0, 0.4],
            vec![1.0, 0.6],
            vec![1.0, 0.8],
            vec![1.0, 1.0],
        ];
        let y = vec![0.0, 0.0, 0.0, 1.0, 1.0, 1.0];

        // Convert to faer::Mat
        let x_mat = vec_to_mat(&x);
        let mle = compute_logistic_mle(&x_mat, &y).unwrap();
        let se = compute_hc3_logistic(&x, &y, &mle.pi, &mle.info_inv).unwrap();

        assert_eq!(se.len(), 2);
        assert!(se[0] > 0.0);
        assert!(se[1] > 0.0);
    }

    #[test]
    fn test_separation_detection() {
        // Large coefficients should trigger separation detection
        let beta = vec![25.0, -25.0];
        let pi = vec![0.999999, 0.000001];
        assert!(detect_separation(&beta, &pi));

        // Normal coefficients should not
        let beta_normal = vec![1.0, 2.0];
        let pi_normal = vec![0.3, 0.7];
        assert!(!detect_separation(&beta_normal, &pi_normal));
    }
}
