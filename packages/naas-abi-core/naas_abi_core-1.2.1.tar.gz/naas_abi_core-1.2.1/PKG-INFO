Metadata-Version: 2.4
Name: naas-abi-core
Version: 1.2.1
Summary: Abi framework allowing you to build your AI system.
Author-email: Maxime Jublou <maxime@naas.ai>, Florent Ravenel <florent@naas.ai>, Jeremy Ravenel <jeremy@naas.ai>
Requires-Python: <4,>=3.10
Requires-Dist: click<8.2,>=8.1.1
Requires-Dist: docker>=7.1.0
Requires-Dist: dotenv>=0.9.9
Requires-Dist: fastapi<0.116,>=0.115.5
Requires-Dist: fastmcp>=2.13.2
Requires-Dist: langchain-openai<0.4,>=0.3.3
Requires-Dist: langgraph-checkpoint-postgres>=2.0.21
Requires-Dist: langgraph>=0.6.6
Requires-Dist: loguru<0.8,>=0.7.2
Requires-Dist: pandas-stubs>=2.3.2.250926
Requires-Dist: pandas>=2.3.3
Requires-Dist: pillow>=12.0.0
Requires-Dist: pip>=25.1.1
Requires-Dist: psycopg[binary,pool]>=3.0.0
Requires-Dist: pydantic>=2.11.5
Requires-Dist: pydash>=8.0.5
Requires-Dist: pytz>=2025.2
Requires-Dist: pyyaml>=6.0.3
Requires-Dist: rdflib<8,>=7.1.1
Requires-Dist: rich<14,>=13.9.4
Requires-Dist: spacy>=3.8.7
Requires-Dist: sparqlwrapper>=2.0.0
Requires-Dist: sse-starlette<3,>=2.1.3
Requires-Dist: starlette>=0.46.2
Requires-Dist: types-tqdm>=4.67.0.20250809
Provides-Extra: all
Requires-Dist: boto3<2,>=1.38.19; extra == 'all'
Requires-Dist: langchain-openai>=0.3.35; extra == 'all'
Requires-Dist: paramiko<4.0.0,>=3.5.1; extra == 'all'
Requires-Dist: qdrant-client>=1.14.3; extra == 'all'
Requires-Dist: sshtunnel>=0.4.0; extra == 'all'
Provides-Extra: aws
Requires-Dist: boto3<2,>=1.38.19; extra == 'aws'
Provides-Extra: openrouter
Requires-Dist: langchain-openai>=0.3.35; extra == 'openrouter'
Provides-Extra: qdrant
Requires-Dist: qdrant-client>=1.14.3; extra == 'qdrant'
Provides-Extra: ssh
Requires-Dist: paramiko<4.0.0,>=3.5.1; extra == 'ssh'
Requires-Dist: sshtunnel>=0.4.0; extra == 'ssh'
Description-Content-Type: text/markdown

# ABI Library

The ABI Library is the core implementation of ABI's concepts, designed to build a unified AI system. This library provides the fundamental building blocks for connecting, processing, and utilizing data across different AI components.

## Core Concepts

### Integration
Integrations provide standardized connections to third-party services and data sources. They handle:
- Authentication and authorization
- API communication
- Data format standardization
- Error handling and retries

### Pipeline
Pipelines are responsible for data ingestion and transformation into the ontological layer. They:
- Utilize integrations to fetch data
- Transform raw data into semantic representations
- Maintain data consistency and quality
- Map external data models to ABI's ontology

### Workflow
Workflows leverage the ontological layer to implement business logic and provide data to consumers. They can be used by:
- Large Language Models (LLMs)
- Remote APIs and services
- Other automated processes

### Services
Services form the foundational layer of ABI, implementing the Hexagonal Architecture (Ports & Adapters) pattern to provide flexible and system-agnostic interfaces. This architectural approach allows ABI to seamlessly integrate with existing systems while maintaining clean separation of concerns.

Each service defines a primary port (interface) that specifies its capabilities, while multiple secondary adapters can implement this interface for different backend systems. This means you can:

- Easily swap implementations without changing business logic
- Add new integrations by implementing new adapters
- Test components in isolation using mock adapters

For example, the Secret Service could connect to various backend systems through different adapters:
- Hashicorp Vault
- AWS Secrets Manager
- Azure Key Vault
- Environment Variables
- Local File System
- Google Cloud Secret Manager
- Kubernetes Secrets

This modular approach ensures that ABI can be deployed in any environment while maintaining consistent interfaces and behavior across different infrastructure choices.
