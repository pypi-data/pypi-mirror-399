# tests/test_build_engine.py

import time

import pytest

# Assume build_engine and its dependencies are in the python path
from build_engine import BuildPlanner, UpdateCode


# --- Test Fixtures and Test Data ---

@pytest.fixture
def base_config():
    """Provides a basic, valid configuration for tests."""
    return {
        "GENERAL": {
            "VAR1": "general_value"
        }, "PROFILES": {
            "test_profile": {
                "VAR2": "profile_value"
            }
        }, "WORKFLOW": {
            "StepA": {
                "OUTPUT": "output_a.txt", "REQUIRES": [],
                "RULE": {"NAME": "rule_a", "COMMAND": "echo A > {OUTPUT}"}
            }, "StepB": {
                "OUTPUT": "output_b.txt", "REQUIRES": ["StepA"], "INPUTS": ["{REQUIRES[0]}"],
                "RULE": {"NAME": "rule_b", "COMMAND": "cat {INPUTS[0]} > {OUTPUT}"}
            }
        }
    }


@pytest.fixture
def command_map():
    """Provides a sample command map, simulating the output of CommandGenerator."""
    return {
        "StepA": {
            "output": "output_a.txt", "input_files": [], "hashes": {
                "command": "hash_cmd_a", "inputs": "hash_inputs_a", "params": "hash_params_a"
            }
        }, "StepB": {
            "output": "output_b.txt", "input_files": ["output_a.txt"], "hashes": {
                "command": "hash_cmd_b", "inputs": "hash_inputs_b", "params": "hash_params_b"
            }
        }
    }


@pytest.fixture
def execution_graph(base_config):
    """Provides a sample NetworkX graph."""
    # In a real scenario, this would be generated by DependencyGraph
    import networkx as nx
    G = nx.DiGraph()
    G.add_node("StepA", **base_config["WORKFLOW"]["StepA"])
    G.add_node("StepB", **base_config["WORKFLOW"]["StepB"])
    G.add_edge("StepA", "StepB")
    return G


# --- Parameterized Tests for `_is_step_outdated` ---

# Define the test cases for various outdated scenarios
# Each tuple is: (test_id, build_state, expected_code, expected_context)
outdated_test_cases = [pytest.param(
    "up_to_date", {
        "output_a.txt": {
            "mtime": time.time() - 10, "hashes": {
                "command": "hash_cmd_a", "inputs": "hash_inputs_a", "params": "hash_params_a"
            }
        }
    }, UpdateCode.UP_TO_DATE, "", id="up_to_date"
), pytest.param(
    "missing_output", {},  # Build state is empty, so output_a.txt is not tracked
    UpdateCode.MISSING_OUTPUT, "output_a.txt", id="missing_output"
), pytest.param(
    "not_tracked", {"some_other_file.txt": {}},  # output_a.txt is not a key
    UpdateCode.NOT_TRACKED, "output_a.txt", id="not_tracked"
), pytest.param(
    "command_changed", {
        "output_a.txt": {
            "mtime": time.time() - 10, "hashes": {
                "command": "hash_cmd_a_DIFFERENT", "inputs": "hash_inputs_a",
                "params": "hash_params_a"
            }
        }
    }, UpdateCode.COMMAND_CHANGED, "", id="command_changed"
), pytest.param(
    "inputs_changed", {
        "output_a.txt": {
            "mtime": time.time() - 10, "hashes": {
                "command": "hash_cmd_a", "inputs": "hash_inputs_a_DIFFERENT",
                "params": "hash_params_a"
            }
        }
    }, UpdateCode.INPUTS_CHANGED, "", id="inputs_changed"
), pytest.param(
    "params_changed", {
        "output_a.txt": {
            "mtime": time.time() - 10, "hashes": {
                "command": "hash_cmd_a", "inputs": "hash_inputs_a",
                "params": "hash_params_a_DIFFERENT"
            }
        }
    }, UpdateCode.PARAMS_CHANGED, "", id="params_changed"
), ]


@pytest.mark.parametrize(
    "test_id, build_state, expected_code, expected_context", outdated_test_cases
)
def test_is_step_outdated_scenarios(
        mocker, base_config, command_map, test_id, build_state, expected_code, expected_context
):
    """
    Tests the _is_step_outdated method with various states using parameterization.
    We only test StepA here, as it has no file dependencies.
    """
    # Mock os.path.exists to simulate file presence or absence
    if expected_code == UpdateCode.MISSING_OUTPUT:
        mocker.patch("os.path.exists", return_value=False)
    else:
        mocker.patch("os.path.exists", return_value=True)

    # Mock os.path.getmtime to avoid real file system access
    mocker.patch("os.path.getmtime", return_value=time.time() - 20)

    planner = BuildPlanner(base_config, build_state)
    command_a = command_map["StepA"]

    update_code, context = planner._is_step_outdated(command_a)

    assert update_code == expected_code
    assert context == expected_context


def test_is_step_outdated_newer_input(mocker, base_config, command_map):
    """
    Tests the specific case where an input file is newer than the last build.
    We test StepB here, as it depends on StepA.
    """
    # Simulate that both files exist
    mocker.patch("os.path.exists", return_value=True)

    # Simulate that the input (output_a.txt) is NEWER than the last build time
    def mock_getmtime(path):
        if "output_a.txt" in path:
            return time.time()  # Now
        return time.time() - 20  # 20 seconds ago

    mocker.patch("os.path.getmtime", side_effect=mock_getmtime)

    build_state = {
        "output_b.txt": {
            "mtime": time.time() - 10,  # Last build was 10 seconds ago
            "hashes": {
                "command": "hash_cmd_b", "inputs": "hash_inputs_b", "params": "hash_params_b"
            }
        }
    }

    planner = BuildPlanner(base_config, build_state)
    command_b = command_map["StepB"]

    update_code, context = planner._is_step_outdated(command_b)

    assert update_code == UpdateCode.NEWER_INPUT
    assert context == "output_a.txt"


# --- Tests for the overall `plan_build` method ---

def test_plan_build_full_rebuild(mocker, base_config, command_map, execution_graph):
    """
    Tests that a full rebuild is planned when the build state is empty.
    """
    # Mock the command generation and graph creation
    mocker.patch.object(
        BuildPlanner, "_generate_command_map_and_graph", return_value=(command_map, execution_graph)
    )

    # Mock the outdated check to always return MISSING_OUTPUT for simplicity
    mocker.patch.object(
        BuildPlanner, "_is_step_outdated",
        return_value=(UpdateCode.MISSING_OUTPUT, "mock_output.txt")
    )

    planner = BuildPlanner(base_config, build_state={})
    plan = planner.plan_build(profile_name="test_profile")

    assert len(plan.steps_to_run) == 2
    assert len(plan.steps_to_skip) == 0
    assert plan.steps_to_run[0].node_name == "StepA"
    assert plan.steps_to_run[1].node_name == "StepB"


def test_plan_build_partial_rebuild(mocker, base_config, command_map, execution_graph):
    """
    Tests that a partial rebuild is planned when only one step is outdated,
    and the change is correctly propagated to its descendants.
    """
    mocker.patch.object(
        BuildPlanner, "_generate_command_map_and_graph", return_value=(command_map, execution_graph)
    )

    # Mock the outdated check: StepA is outdated, StepB is not (yet).
    def mock_is_outdated(command):
        if command['output'] == "output_a.txt":
            return (UpdateCode.COMMAND_CHANGED, "")
        return (UpdateCode.UP_TO_DATE, "")

    mocker.patch.object(BuildPlanner, "_is_step_outdated", side_effect=mock_is_outdated)

    planner = BuildPlanner(base_config, build_state={"mock": "state"})
    plan = planner.plan_build(profile_name="test_profile")

    # StepA is outdated, and StepB must be rebuilt because its dependency changed.
    assert len(plan.steps_to_run) == 2
    assert len(plan.steps_to_skip) == 0

    # Check the reasons for the rebuild
    step_a_plan = next(s for s in plan.steps_to_run if s.node_name == "StepA")
    step_b_plan = next(s for s in plan.steps_to_run if s.node_name == "StepB")

    assert step_a_plan.update_code == UpdateCode.COMMAND_CHANGED
    assert step_b_plan.update_code == UpdateCode.DEPENDENCY_CHANGED


def test_plan_build_no_rebuild(mocker, base_config, command_map, execution_graph):
    """
    Tests that no steps are planned to run when everything is up-to-date.
    """
    mocker.patch.object(
        BuildPlanner, "_generate_command_map_and_graph", return_value=(command_map, execution_graph)
    )

    # Mock the outdated check to always return UP_TO_DATE
    mocker.patch.object(
        BuildPlanner, "_is_step_outdated", return_value=(UpdateCode.UP_TO_DATE, "")
    )

    planner = BuildPlanner(base_config, build_state={"mock": "state"})
    plan = planner.plan_build(profile_name="test_profile")

    assert len(plan.steps_to_run) == 0
    assert len(plan.steps_to_skip) == 2
